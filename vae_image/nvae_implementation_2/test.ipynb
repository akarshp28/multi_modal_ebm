{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "167dd5c3-a729-416f-8ae7-3ed4d3f3397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from helper_functions2 import get_imgs, load_caps_img, create_image_gen\n",
    "import numpy as np\n",
    "from tensorflow_probability import distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53737732-c2cf-4f36-938e-e7657fed8153",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "comparison = tf.stack([test_data, images], axis=1)\n",
    "b_sz, h, w, c = tf.shape(test_data)\n",
    "\n",
    "# flip width and height\n",
    "comparison = tf.transpose(comparison, perm=[0, 1, 3, 2, 4])\n",
    "comparison = tf.reshape(comparison, [b_sz, 2 * w, h, c])\n",
    "\n",
    "# reset width and height order\n",
    "comparison = tf.transpose(comparison, perm=[0, 2, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4140cde0-4fcd-45b8-b8c4-c168203a8012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/apokkunu/trial/img/annotations/captions_train2014.json /users/apokkunu/trial/img/train2014/\n",
      "\n",
      "dataset size: 82783\n",
      "\n",
      "temp dataset size: 100\n",
      "{'/users/apokkunu/trial/img/train2014/COCO_train2014_000000448139.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000515206.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000363847.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000032093.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000105844.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000083931.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000407369.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000238713.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000005396.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000265330.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000321059.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000581873.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000103166.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000018072.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000161251.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000136394.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000473425.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000332459.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000166920.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000322971.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000278907.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000064602.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000377973.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000556801.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000340095.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000147283.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000275709.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000457774.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000108879.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000258769.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000400734.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000577087.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000341448.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000057699.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000089181.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000351328.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000556512.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000269327.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000198396.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000508548.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000374248.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000003640.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000070508.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000233290.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000287781.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000145718.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000320946.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000144430.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000309267.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000455533.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000451274.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000260677.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000570518.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000516633.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000176938.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000459770.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000166076.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000150838.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000143607.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000452872.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000164655.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000082704.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000334491.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000506011.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000109509.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000378849.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000471837.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000243288.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000434319.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000354326.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000404205.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000098969.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000197854.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000104827.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000310890.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000184884.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000513606.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000362766.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000371138.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000423710.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000574001.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000014967.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000570268.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000031562.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000465507.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000190547.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000485473.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000422020.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000193578.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000427613.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000364959.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000163962.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000232467.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000409443.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000003897.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000481571.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000523524.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000482750.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000286998.jpg', '/users/apokkunu/trial/img/train2014/COCO_train2014_000000222442.jpg'}\n",
      "/users/apokkunu/trial/img/annotations/captions_val2014.json /users/apokkunu/trial/img/val2014/\n",
      "\n",
      "dataset size: 40504\n",
      "\n",
      "temp dataset size: 100\n",
      "/users/apokkunu/trial/img/annotations/image_info_test2014.json /users/apokkunu/trial/img/test2014/\n",
      "\n",
      "dataset size: 40775\n",
      "\n",
      "temp dataset size: 100\n",
      "\n",
      "dataset size: 100\n",
      "\n",
      "dataset size: 100\n",
      "\n",
      "dataset size: 100\n"
     ]
    }
   ],
   "source": [
    "def load_coco(use_all_data, image_shape, batch_size):\n",
    "    dataset_name = 'train'\n",
    "    train_capspath, train_imgspath = get_imgs(dataset_name)\n",
    "    train_caps, train_imgs = load_caps_img(train_capspath, train_imgspath, dataset_name, use_all_data)\n",
    "    \n",
    "    print(set(train_imgs))\n",
    "    \n",
    "    dataset_name = 'val'\n",
    "    val_capspath, val_imgspath = get_imgs(dataset_name)\n",
    "    val_caps, val_imgs = load_caps_img(val_capspath, val_imgspath, dataset_name, use_all_data)\n",
    "    \n",
    "    dataset_name = 'test'\n",
    "    test_capspath, test_imgspath = get_imgs(dataset_name)\n",
    "    test_imgs = load_caps_img(test_capspath, test_imgspath, dataset_name, use_all_data)\n",
    "\n",
    "    train_dataset = create_image_gen(set(train_imgs), batch_size, image_shape)\n",
    "    val_dataset = create_image_gen(val_imgs, batch_size, image_shape)\n",
    "    test_dataset = create_image_gen(test_imgs, batch_size, image_shape)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "image_shape = 128; use_all_data=False\n",
    "train_data_single, val_data_single, test_data_single = load_coco(use_all_data, image_shape, image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80451a19-5861-429f-ba6d-fd6be780bdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "\n",
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print ('\\nNumber of devices: {}'.format(strategy.num_replicas_in_sync), flush=True)\n",
    "\n",
    "GLOBAL_BATCH_SIZE = image_shape * strategy.num_replicas_in_sync\n",
    "\n",
    "train_data = strategy.experimental_distribute_dataset(train_data_single)\n",
    "val_data = strategy.experimental_distribute_dataset(val_data_single)\n",
    "test_data = strategy.experimental_distribute_dataset(test_data_single)\n",
    "\n",
    "n_list = list(train_data_single.as_numpy_iterator())\n",
    "batches_per_epoch = len(n_list)\n",
    "\n",
    "sample_batch = next(train_data_single.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97c6563f-c7f6-4c05-b01c-2477466b1b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_shape(x):\n",
    "    return list(map(int, x.get_shape()))\n",
    "\n",
    "def log_sum_exp(x):\n",
    "    \"\"\" numerically stable log_sum_exp implementation that prevents overflow \"\"\"\n",
    "    axis = len(x.get_shape())-1\n",
    "    m = tf.reduce_max(x, axis)\n",
    "    m2 = tf.reduce_max(x, axis, keepdims=True)\n",
    "    return m + tf.math.log(tf.reduce_sum(tf.exp(x-m2), axis))\n",
    "\n",
    "def log_prob_from_logits(x):\n",
    "    \"\"\" numerically stable log_softmax implementation that prevents overflow \"\"\"\n",
    "    axis = len(x.get_shape())-1\n",
    "    m = tf.reduce_max(x, axis, keepdims=True)\n",
    "    return x - m - tf.math.log(tf.reduce_sum(tf.math.exp(x-m), axis, keepdims=True))\n",
    "\n",
    "def discretized_mix_logistic_loss(x, l, sum_all=True):\n",
    "    \"\"\" log-likelihood for mixture of discretized logistics, assumes the data has been rescaled to [-1,1] interval \"\"\"\n",
    "    xs = int_shape(x) # true image (i.e. labels) to regress to, e.g. (B,32,32,3)\n",
    "    ls = int_shape(l) # predicted distribution, e.g. (B,32,32,100)\n",
    "    nr_mix = int(ls[-1] / 10) # here and below: unpacking the params of the mixture of logistics\n",
    "    logit_probs = l[:, :, :, :nr_mix]\n",
    "    \n",
    "    print(l[:,:,:,nr_mix:].shape, xs + [nr_mix*3])\n",
    "    \n",
    "    l = tf.reshape(l[:,:,:,nr_mix:], xs + [nr_mix*3])\n",
    "    means = l[:,:,:,:,:nr_mix]\n",
    "    log_scales = tf.maximum(l[:,:,:,:,nr_mix:2*nr_mix], -7.)\n",
    "    coeffs = tf.nn.tanh(l[:,:,:,:,2*nr_mix:3*nr_mix])\n",
    "    x = tf.reshape(x, xs + [1]) + tf.zeros(xs + [nr_mix]) # here and below: getting the means and adjusting them based on preceding sub-pixels\n",
    "    m2 = tf.reshape(means[:,:,:,1,:] + coeffs[:, :, :, 0, :] * x[:, :, :, 0, :], [xs[0],xs[1],xs[2],1,nr_mix])\n",
    "    m3 = tf.reshape(means[:, :, :, 2, :] + coeffs[:, :, :, 1, :] * x[:, :, :, 0, :] + coeffs[:, :, :, 2, :] * x[:, :, :, 1, :], [xs[0],xs[1],xs[2],1,nr_mix])\n",
    "    means = tf.concat([tf.reshape(means[:,:,:,0,:], [xs[0],xs[1],xs[2],1,nr_mix]), m2, m3],3)\n",
    "    \n",
    "    centered_x = x - means\n",
    "    inv_stdv = tf.exp(-log_scales)\n",
    "    plus_in = inv_stdv * (centered_x + 1./255.)\n",
    "    cdf_plus = tf.nn.sigmoid(plus_in)\n",
    "    min_in = inv_stdv * (centered_x - 1./255.)\n",
    "    cdf_min = tf.nn.sigmoid(min_in)\n",
    "    log_cdf_plus = plus_in - tf.nn.softplus(plus_in) # log probability for edge case of 0 (before scaling)\n",
    "    log_one_minus_cdf_min = -tf.nn.softplus(min_in) # log probability for edge case of 255 (before scaling)\n",
    "    cdf_delta = cdf_plus - cdf_min # probability for all other cases\n",
    "    mid_in = inv_stdv * centered_x\n",
    "    log_pdf_mid = mid_in - log_scales - 2.*tf.nn.softplus(mid_in) # log probability in the center of the bin, to be used in extreme cases (not actually used in our code)\n",
    "\n",
    "    # now select the right output: left edge case, right edge case, normal case, extremely low prob case (doesn't actually happen for us)\n",
    "\n",
    "    # this is what we are really doing, but using the robust version below for extreme cases in other applications and to avoid NaN issue with tf.select()\n",
    "    # log_probs = tf.select(x < -0.999, log_cdf_plus, tf.select(x > 0.999, log_one_minus_cdf_min, tf.math.log(cdf_delta)))\n",
    "    \n",
    "    # robust version, that still works if probabilities are below 1e-5 (which never happens in our code)\n",
    "    # tensorflow backpropagates through tf.select() by multiplying with zero instead of selecting: this requires use to use some ugly tricks to avoid potential NaNs\n",
    "    # the 1e-12 in tf.maximum(cdf_delta, 1e-12) is never actually used as output, it's purely there to get around the tf.select() gradient issue\n",
    "    # if the probability on a sub-pixel is below 1e-5, we use an approximation based on the assumption that the log-density is constant in the bin of the observed sub-pixel value\n",
    "    log_probs = tf.where(x < -0.999, log_cdf_plus, tf.where(x > 0.999, log_one_minus_cdf_min, \n",
    "                                                            tf.where(cdf_delta > 1e-5, tf.math.log(tf.maximum(cdf_delta, 1e-12)), log_pdf_mid - np.log(127.5))))\n",
    "\n",
    "    log_probs = tf.reduce_sum(log_probs,3) + log_prob_from_logits(logit_probs)\n",
    "    if sum_all:\n",
    "        return -tf.reduce_sum(log_sum_exp(log_probs))\n",
    "    else:\n",
    "        return -tf.reduce_sum(log_sum_exp(log_probs),[1,2])\n",
    "\n",
    "def sample_from_discretized_mix_logistic(l, nr_mix):\n",
    "    ls = int_shape(l)\n",
    "    xs = ls[:-1] + [3]\n",
    "    \n",
    "    # unpack parameters\n",
    "    logit_probs = l[:, :, :, :nr_mix]\n",
    "    l = tf.reshape(l[:, :, :, nr_mix:], xs + [nr_mix*3])\n",
    "    \n",
    "    # sample mixture indicator from softmax\n",
    "    sel = tf.one_hot(tf.argmax(logit_probs - tf.math.log(-tf.math.log(tf.random.uniform(logit_probs.get_shape(), minval=1e-5, maxval=1. - 1e-5))), 3), \n",
    "                     depth=nr_mix, dtype=tf.float32)\n",
    "    sel = tf.reshape(sel, xs[:-1] + [1,nr_mix])\n",
    "    \n",
    "    # select logistic parameters\n",
    "    means = tf.reduce_sum(l[:,:,:,:,:nr_mix]*sel,4)\n",
    "    log_scales = tf.maximum(tf.reduce_sum(l[:,:,:,:,nr_mix:2*nr_mix]*sel,4), -7.)\n",
    "    coeffs = tf.reduce_sum(tf.nn.tanh(l[:,:,:,:,2*nr_mix:3*nr_mix])*sel,4)\n",
    "    \n",
    "    # sample from logistic & clip to interval\n",
    "    # we don't actually round to the nearest 8bit value when sampling\n",
    "    u = tf.random.uniform(means.get_shape(), minval=1e-5, maxval=1. - 1e-5)\n",
    "    x = means + tf.exp(log_scales)*(tf.math.log(u) - tf.math.log(1. - u))\n",
    "    x0 = tf.minimum(tf.maximum(x[:,:,:,0], -1.), 1.)\n",
    "    x1 = tf.minimum(tf.maximum(x[:,:,:,1] + coeffs[:,:,:,0]*x0, -1.), 1.)\n",
    "    x2 = tf.minimum(tf.maximum(x[:,:,:,2] + coeffs[:,:,:,1]*x0 + coeffs[:,:,:,2]*x1, -1.), 1.)\n",
    "    return tf.concat([tf.reshape(x0,xs[:-1]+[1]), tf.reshape(x1,xs[:-1]+[1]), tf.reshape(x2,xs[:-1]+[1])],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a89a31f-4196-4318-80d3-0a8a448f2ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 64, 64, 100] [3, 64, 64, 3]\n",
      "(3, 64, 64, 90)\n",
      "[3, 64, 64, 3, 30]\n",
      "(3, 64, 64, 10) (3, 64, 64, 3, 30)\n"
     ]
    }
   ],
   "source": [
    "l = tf.random.normal([3, 64, 64, 100])\n",
    "ls = int_shape(l)\n",
    "xs = ls[:-1] + [3]\n",
    "print(ls, xs)\n",
    "\n",
    "nr_mix = 10\n",
    "\n",
    "logit_probs = l[:, :, :, :nr_mix]\n",
    "fff = l[:, :, :, nr_mix:]\n",
    "print(fff.shape)\n",
    "\n",
    "print(xs + [nr_mix*3])\n",
    "\n",
    "l = tf.reshape(fff, xs + [nr_mix*3])\n",
    "print(logit_probs.shape, l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d6e5252-6433-43f4-9871-6619d92eb8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 64, 64, 60]\n",
      "6\n",
      "[3, 64, 64, 3] [3, 64, 64, 3, 18] xs\n",
      "(3, 64, 64, 6)\n",
      "(3, 64, 64, 54) ff\n"
     ]
    }
   ],
   "source": [
    "l = tf.random.normal([3, 64, 64, 60])\n",
    "ls = int_shape(l)\n",
    "print(ls)\n",
    "\n",
    "nr_mix = int(ls[-1] / 10)\n",
    "print(nr_mix)\n",
    "\n",
    "xs = ls[:-1] + [3]\n",
    "print(xs, xs + [nr_mix*3], 'xs')\n",
    "\n",
    "# unpack parameters\n",
    "logit_probs = l[:, :, :, :nr_mix]\n",
    "print(logit_probs.shape)\n",
    "\n",
    "ff = l[:, :, :, nr_mix:]\n",
    "print(ff.shape, 'ff')\n",
    "\n",
    "l = tf.reshape(ff, xs + [nr_mix*3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ea4b6f7-969a-4656-ba43-ef720e391c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 128, 128, 40]\n",
      "4\n",
      "(3, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "l = tf.random.normal([3, 128, 128, 40])\n",
    "ls = int_shape(l) # predicted distribution, e.g. (B,32,32,100)\n",
    "print(ls)\n",
    "nr_mix = int(ls[-1] / 10)\n",
    "print(nr_mix)\n",
    "a = sample_from_discretized_mix_logistic(l, nr_mix)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4156c60f-8162-45a6-9171-4dcf6652e32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 64, 64, 54) [100, 64, 64, 3, 18]\n",
      "tf.Tensor(6250638.5, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal([100, 64, 64, 3])\n",
    "l = tf.random.normal([100, 64, 64, 60])\n",
    "a = discretized_mix_logistic_loss(x, l)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ffcd1db-0819-46c4-9a6e-650b9d3089f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "reconstruction = tf.random.normal([3, 128, 128, 3])\n",
    "inputs = tf.random.normal([3, 128, 128, 3]) * 2\n",
    "\n",
    "log_probs = distributions.Bernoulli(logits=reconstruction, dtype=tf.float32, allow_nan_stats=False).log_prob(inputs)\n",
    "print(log_probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52a0d4bd-5e0f-44e4-a756-9214b9a59864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.Categorical 'Categorical' batch_shape=[3, 128, 128, 3] event_shape=[] dtype=float32>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction = tf.expand_dims(tf.random.normal([3, 128, 128, 3]), axis=4)\n",
    "distributions.Categorical(logits=reconstruction, dtype=tf.float32, allow_nan_stats=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e664253-73a9-4628-8305-4e7c5575d484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tfp.distributions.Normal 'Normal' batch_shape=[] event_shape=[] dtype=float32>,\n",
       " <tfp.distributions.Normal 'Normal' batch_shape=[] event_shape=[] dtype=float32>,\n",
       " <tfp.distributions.Normal 'Normal' batch_shape=[] event_shape=[] dtype=float32>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[distributions.Normal(loc=0., scale=1.0)]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8f6f5ce-0e82-4a15-9dc0-f2ef8e5e9a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(tf.ones([1, 1]), [3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e83e15ba-514e-43cd-bc80-7148204f3e47",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "components[0] batch shape must be compatible with cat shape and other component batch shapes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4eee94a53622>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m log_probs = distributions.Mixture(distributions.Categorical(logits=reconstruction, dtype=tf.float32, allow_nan_stats=False), \n\u001b[0;32m----> 5\u001b[0;31m                                                  components=[distributions.Normal(loc=0., scale=1.0)], validate_args=True, allow_nan_stats=False).log_prob(inputs)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-318>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cat, components, validate_args, allow_nan_stats, use_static_graph, name)\u001b[0m\n",
      "\u001b[0;32m~/trial/akarsh/lib/python3.7/site-packages/tensorflow_probability/python/distributions/distribution.py\u001b[0m in \u001b[0;36mwrapped_init\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    330\u001b[0m       \u001b[0;31m# called, here is the place to do it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m       \u001b[0mself_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m       \u001b[0mdefault_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m       \u001b[0;31m# Note: if we ever want to override things set in `self` by subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m       \u001b[0;31m# `__init__`, here is the place to do it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trial/akarsh/lib/python3.7/site-packages/tensorflow_probability/python/distributions/mixture.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cat, components, validate_args, allow_nan_stats, use_static_graph, name)\u001b[0m\n\u001b[1;32m    144\u001b[0m           raise ValueError(\n\u001b[1;32m    145\u001b[0m               \u001b[0;34m'components[{}] batch shape must be compatible with cat '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m               'shape and other component batch shapes'.format(di))\n\u001b[0m\u001b[1;32m    147\u001b[0m         static_event_shape = tensorshape_util.merge_with(\n\u001b[1;32m    148\u001b[0m             static_event_shape, d.event_shape)\n",
      "\u001b[0;31mValueError\u001b[0m: components[0] batch shape must be compatible with cat shape and other component batch shapes"
     ]
    }
   ],
   "source": [
    "reconstruction = tf.expand_dims(tf.random.normal([3, 128, 128, 3]), axis=4)\n",
    "inputs = tf.expand_dims(tf.random.normal([3, 128, 128, 3]), axis=4) * 2\n",
    "\n",
    "log_probs = distributions.Mixture(distributions.Categorical(logits=reconstruction, dtype=tf.float32, allow_nan_stats=False), \n",
    "                                                 components=[distributions.Normal(loc=0., scale=1.0)], validate_args=True, allow_nan_stats=False).log_prob(inputs)\n",
    "print(log_probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62993cbd-e068-42e3-b8c8-04b9970a9988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(batch_size, binary=True):\n",
    "    train_ds, test_ds = tfds.load(\"mnist\", split=[\"train\", \"test\"], shuffle_files=True, batch_size=batch_size, as_supervised=True)\n",
    "\n",
    "    def transform(image, label):\n",
    "        image = tf.image.resize_with_crop_or_pad(image, 32, 32)\n",
    "        image = tf.cast(image, dtype=tf.float32)\n",
    "        if binary:\n",
    "            image = tfp.distributions.Bernoulli(probs=image, dtype=tf.float32).sample()\n",
    "        else:\n",
    "            image /= 255\n",
    "        return image, label\n",
    "\n",
    "    return train_ds.map(transform), test_ds.map(transform)\n",
    "\n",
    "train_data, test_ds = load_mnist(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624eef2a-98ac-45c8-ac46-028edca24e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_mnist(batch_size, binary=True):\n",
    "#     train_ds, test_ds = tfds.load(\"mnist\", split=[\"train\", \"test\"], shuffle_files=True, batch_size=batch_size, as_supervised=True)\n",
    "    \n",
    "#     def transform(image, label):\n",
    "#         image = tf.image.resize_with_crop_or_pad(image, 32, 32)\n",
    "#         image = tf.cast(image, dtype=tf.float32)\n",
    "#         if binary:\n",
    "#             image = tfp.distributions.Bernoulli(probs=image, dtype=tf.float32).sample()\n",
    "#         else:\n",
    "#             image /= 255\n",
    "#         return image, label\n",
    "    \n",
    "#     def extract_raw(tf_ds):\n",
    "#         d = []\n",
    "#         for i in tf_ds:\n",
    "#             i = i[0]\n",
    "#             for j in i.numpy():\n",
    "#                 d.append(j)\n",
    "#         return np.array(d)\n",
    "    \n",
    "#     train_ds = train_ds.map(transform)\n",
    "#     test_ds = test_ds.map(transform)\n",
    "    \n",
    "#     x_train = extract_raw(train_ds)\n",
    "#     x_test = extract_raw(test_ds)\n",
    "#     return x_train, x_test\n",
    "\n",
    "# batch_size = 128\n",
    "# train_data, test_ds = load_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bacd12-022d-4c1b-8659-aa9718bcebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_batch, lb = next(train_data.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a257d-ee28-423d-86cd-bace0fcb1ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch, lb = max(enumerate(train_data.as_numpy_iterator()))[1]\n",
    "\n",
    "sample_batch = next(train_data.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18795e9f-087c-4d62-994d-2ef94a2ad094",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0794a2-7119-4828-bf01-c22c617a0d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coco(use_all_data, image_shape, batch_size):\n",
    "    dataset_name = 'train'\n",
    "    train_capspath, train_imgspath = get_imgs(dataset_name)\n",
    "    train_caps, train_imgs = load_caps_img(train_capspath, train_imgspath, dataset_name, use_all_data)\n",
    "    \n",
    "    dataset_name = 'val'\n",
    "    val_capspath, val_imgspath = get_imgs(dataset_name)\n",
    "    val_caps, val_imgs = load_caps_img(val_capspath, val_imgspath, dataset_name, use_all_data)\n",
    "\n",
    "    dataset_name = 'test'\n",
    "    test_capspath, test_imgspath = get_imgs(dataset_name)\n",
    "    test_imgs = load_caps_img(test_capspath, test_imgspath, dataset_name, use_all_data)\n",
    "\n",
    "    train_dataset = create_image_gen(train_imgs, batch_size, image_shape)\n",
    "    val_dataset = create_image_gen(val_imgs, batch_size, image_shape)\n",
    "    test_dataset = create_image_gen(test_imgs, batch_size, image_shape)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "use_all_data = True\n",
    "image_shape = 128\n",
    "batch_size = 128\n",
    "train_data, val_dataset, test_data = load_coco(use_all_data, image_shape, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71b578e-2aea-41b7-9820-94a236af86b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(train_data.as_numpy_iterator()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
