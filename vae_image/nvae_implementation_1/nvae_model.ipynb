{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ac86e5-cffc-454b-9e23-6db815ee82c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from functools import partial\n",
    "from util import calculate_log_p, softclamp5\n",
    "from common import RescaleType, Rescaler, SqueezeExcitation\n",
    "\n",
    "from enum import Enum, auto\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import activations, Sequential, layers\n",
    "from tensorflow_addons.layers import SpectralNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b613b68-d024-467d-a591-4e05b77999d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (128, 128, 3)\n",
    "n_encoder_channels = 16\n",
    "n_decoder_channels = 16\n",
    "\n",
    "n_preprocess_blocks = 2\n",
    "n_preprocess_cells = 3\n",
    "\n",
    "n_postprocess_blocks = 2\n",
    "n_postprocess_cells = 3\n",
    "\n",
    "mult = 1\n",
    "scale_factor = 2\n",
    "\n",
    "n_latent_per_group = 20\n",
    "res_cells_per_group = 2\n",
    "n_groups_per_scale = [2, 2]\n",
    "n_latent_scales = len(n_groups_per_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9ed777-f168-4cbd-ab34-c6b987f897b3",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa8cccd-d7df-4d44-af99-fe01b6441762",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipScaler(tf.keras.Model):\n",
    "    def __init__(self, n_channels, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # Each convolution handles a quarter of the channels\n",
    "        self.conv1 = SpectralNormalization(layers.Conv2D(n_channels // 4, (1, 1), strides=(2, 2), padding=\"same\"))\n",
    "        self.conv2 = SpectralNormalization(layers.Conv2D(n_channels // 4, (1, 1), strides=(2, 2), padding=\"same\"))\n",
    "        self.conv3 = SpectralNormalization(layers.Conv2D(n_channels // 4, (1, 1), strides=(2, 2), padding=\"same\"))\n",
    "        \n",
    "        # This convolotuion handles the remaining channels\n",
    "        self.conv4 = SpectralNormalization(layers.Conv2D(n_channels - 3 * (n_channels // 4), (1, 1), strides=(2, 2), padding=\"same\"))\n",
    "\n",
    "    def call(self, x):\n",
    "        out = activations.swish(x)\n",
    "        # Indexes are offset as we stride by 2x2, this way we cover all pixels\n",
    "        conv1 = self.conv1(out)\n",
    "        conv2 = self.conv2(out[:, 1:, 1:, :])\n",
    "        conv3 = self.conv3(out[:, :, 1:, :])\n",
    "        conv4 = self.conv4(out[:, 1:, :, :])\n",
    "        \n",
    "        # Combine channels\n",
    "        out = tf.concat((conv1, conv2, conv3, conv4), axis=3)\n",
    "        return out\n",
    "\n",
    "\n",
    "class BNSwishConv(tf.keras.Model):\n",
    "    def __init__(self, n_nodes, n_channels, stride, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.nodes = Sequential()\n",
    "        \n",
    "        if stride == (1, 1):\n",
    "            self.skip = tf.identity\n",
    "        elif stride == (2, 2):\n",
    "            # We have to rescale the input in order to combine it\n",
    "            self.skip = SkipScaler(n_channels)\n",
    "            \n",
    "        for i in range(n_nodes):\n",
    "            self.nodes.add(layers.BatchNormalization(momentum=0.05, epsilon=1e-5))\n",
    "            self.nodes.add(layers.Activation(activations.swish))\n",
    "            \n",
    "            # Only apply rescaling on first node\n",
    "            self.nodes.add(SpectralNormalization(layers.Conv2D(n_channels, (3, 3), stride if i == 0 else (1, 1), padding=\"same\")))\n",
    "            \n",
    "        self.se = SqueezeExcitation()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        skipped = self.skip(inputs)\n",
    "        x = self.nodes(inputs)\n",
    "        x = self.se(x)\n",
    "        return skipped + 0.1 * x\n",
    "    \n",
    "def pre_process_block(image_shape, n_encoder_channels, n_preprocess_blocks, n_preprocess_cells, scale_factor, mult=1):\n",
    "    # input is expected to be in [-1, 1] range\n",
    "    in_put = layers.Input(shape=image_shape, name='image')\n",
    "    x = SpectralNormalization(layers.Conv2D(n_encoder_channels, (3, 3), padding=\"same\"))(in_put)\n",
    "    \n",
    "    for block in range(n_preprocess_blocks):\n",
    "        for cell in range(n_preprocess_cells - 1):\n",
    "            n_channels = mult * n_encoder_channels\n",
    "            x = BNSwishConv(2, n_channels, stride=(1, 1))(x)\n",
    "        \n",
    "        # Rescale channels on final cell\n",
    "        n_channels = mult * n_encoder_channels * scale_factor\n",
    "        x = BNSwishConv(2, n_channels, stride=(2, 2))(x)\n",
    "        mult *= scale_factor\n",
    "    \n",
    "    model = tf.keras.models.Model(in_put, x, name='preprocess')\n",
    "    model.summary()\n",
    "    \n",
    "    get_out_shape = x.shape[1:]\n",
    "    print(mult, get_out_shape)\n",
    "    return model, mult, get_out_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7864b50-f75b-464f-bca0-698c8a231672",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f0363df-65da-4f9f-b217-969520134753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder_layers(pp_mult, n_latent_scales, n_groups_per_scale, res_cells_per_group, n_encoder_channels, scale_factor):\n",
    "    # create encoder layers as a list\n",
    "    mult = pp_mult\n",
    "    enc_layers = []\n",
    "    for scale in range(n_latent_scales):\n",
    "        n_groups = n_groups_per_scale[scale]\n",
    "        print('\\nGroup: ', scale)\n",
    "\n",
    "        for group_idx in range(n_groups):\n",
    "            output_channels = n_encoder_channels * mult\n",
    "            print('Output_channels: ', output_channels)\n",
    "            \n",
    "            for rb in range(res_cells_per_group):\n",
    "                enc_layers.append(EncodingResidualCell(output_channels, name='res_block_' + str(scale) + '_' + str(group_idx) + '_' + str(rb)))\n",
    "                print('res block')\n",
    "\n",
    "            if not (scale == n_latent_scales - 1 and group_idx == n_groups - 1):\n",
    "                print('combiner')\n",
    "                enc_layers.append(EncoderDecoderCombiner(output_channels))\n",
    "        \n",
    "        # We downsample in the end of each scale except last\n",
    "        if scale < n_latent_scales - 1:\n",
    "            output_channels = n_encoder_channels * mult * scale_factor\n",
    "            enc_layers.append(Rescaler(output_channels, scale_factor=scale_factor, rescale_type=RescaleType.DOWN))\n",
    "            print('Rescaler')\n",
    "            print('New output_channels: ', output_channels)\n",
    "            mult *= scale_factor\n",
    "\n",
    "    enc_layers.append(layers.ELU())\n",
    "    enc_layers.append(SpectralNormalization(layers.Conv2D(n_encoder_channels * mult, (1, 1), padding=\"same\")))\n",
    "    enc_layers.append(layers.ELU())\n",
    "    \n",
    "    return enc_layers, mult\n",
    "\n",
    "\n",
    "class EncodingResidualCell(tf.keras.Model):\n",
    "    \"\"\"Encoding network residual cell in NVAE architecture\"\"\"\n",
    "    def __init__(self, output_channels, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.batch_norm1 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "        self.conv1 = SpectralNormalization(layers.Conv2D(output_channels, (3, 3), padding=\"same\"))\n",
    "        self.batch_norm2 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "        self.conv2 = SpectralNormalization(layers.Conv2D(output_channels, (3, 3), padding=\"same\"))\n",
    "        self.se = SqueezeExcitation()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = activations.swish(self.batch_norm1(inputs))\n",
    "        x = self.conv1(x)\n",
    "        x = activations.swish(self.batch_norm2(x))\n",
    "        x = self.conv2(x)\n",
    "        x = self.se(x)\n",
    "        return 0.1 * inputs + x\n",
    "    \n",
    "\n",
    "class EncoderDecoderCombiner(tf.keras.Model):\n",
    "    def __init__(self, n_channels, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.decoder_conv = SpectralNormalization(layers.Conv2D(n_channels, (1, 1)))\n",
    "\n",
    "    def call(self, encoder_x, decoder_x):\n",
    "        x = self.decoder_conv(decoder_x)\n",
    "        return encoder_x + x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56908364-c119-48b0-8897-88d56049395a",
   "metadata": {},
   "source": [
    "# Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0dc3d7e-d0e5-4e5f-b10f-8a9e286d368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    def call(self, z_mean, z_log_var):\n",
    "        epsilon = tf.random.normal(shape=tf.shape(z_mean), dtype=tf.float32)\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "class Sampler(tf.keras.Model):\n",
    "    def __init__(self, n_latent_scales, n_groups_per_scale, n_latent_per_group, scale_factor, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # Initialize sampler\n",
    "        self.enc_sampler = []\n",
    "        self.dec_sampler = []\n",
    "        self.n_latent_scales = n_latent_scales\n",
    "        self.n_groups_per_scale = n_groups_per_scale\n",
    "        self.n_latent_per_group = n_latent_per_group\n",
    "        \n",
    "        for scale in range(self.n_latent_scales):\n",
    "            n_groups = self.n_groups_per_scale[scale]\n",
    "            \n",
    "            for group in range(n_groups):\n",
    "                # NVLabs use padding 1 here?\n",
    "                self.enc_sampler.append(SpectralNormalization(layers.Conv2D(2 * self.n_latent_per_group, kernel_size=(3, 3), padding=\"same\")))\n",
    "                \n",
    "                if scale == 0 and group == 0:\n",
    "                    # Dummy value to maintain indexing\n",
    "                    self.dec_sampler.append(None)\n",
    "                else:\n",
    "                    sampler = Sequential()\n",
    "                    sampler.add(layers.ELU())\n",
    "                    \n",
    "                    # NVLabs use padding 0 here?\n",
    "                    sampler.add(SpectralNormalization(layers.Conv2D(2 * self.n_latent_per_group, kernel_size=(1, 1))))\n",
    "                    self.dec_sampler.append(sampler)\n",
    "    \n",
    "    def sample(self, mu, sigma):\n",
    "        # reparametrization trick\n",
    "        return Sampling()(mu, sigma)\n",
    "\n",
    "    def get_params(self, sampler, z_idx, prior):\n",
    "        params = sampler[z_idx](prior)\n",
    "        mu, log_sigma = tf.split(params, 2, axis=-1)\n",
    "        return mu, log_sigma\n",
    "    \n",
    "    def call(self, prior, z_idx, enc_prior=None):\n",
    "        # Get encoder offsets\n",
    "        if enc_prior is None:\n",
    "            enc_prior = prior\n",
    "        enc_mu_offset, enc_log_sigma_offset = self.get_params(self.enc_sampler, z_idx, enc_prior)\n",
    "        \n",
    "        if z_idx == 0:\n",
    "            # Prior is standard normal distribution\n",
    "            enc_mu = softclamp5(enc_mu_offset)\n",
    "            enc_sigma = tf.math.exp(softclamp5(enc_log_sigma_offset)) + 1e-2\n",
    "            z = self.sample(enc_mu, enc_sigma)\n",
    "            params = [enc_mu, enc_sigma, tf.zeros_like(enc_mu), tf.ones_like(enc_sigma)]\n",
    "            return z, params\n",
    "        \n",
    "        # Get decoder parameters\n",
    "        raw_dec_mu, raw_dec_log_sigma = self.get_params(self.dec_sampler, z_idx, prior)\n",
    "        \n",
    "        dec_mu = softclamp5(raw_dec_mu)\n",
    "        dec_sigma = tf.math.exp(softclamp5(raw_dec_log_sigma)) + 1e-2\n",
    "        \n",
    "        enc_mu = softclamp5(enc_mu_offset + raw_dec_mu)\n",
    "        enc_sigma = (tf.math.exp(softclamp5(raw_dec_log_sigma + enc_log_sigma_offset)) + 1e-2)\n",
    "        \n",
    "        params = [enc_mu, enc_sigma, dec_mu, dec_sigma]\n",
    "        z = self.sample(enc_mu, enc_sigma)\n",
    "        return z, params\n",
    "\n",
    "\n",
    "class RescaleType(Enum):\n",
    "    UP = auto()\n",
    "    DOWN = auto()\n",
    "\n",
    "\n",
    "class SqueezeExcitation(tf.keras.Model):\n",
    "    \"\"\"Squeeze and Excitation block as defined by Hu, et al. (2019)\n",
    "    See Also\n",
    "    ========\n",
    "    Source paper https://arxiv.org/pdf/1709.01507.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, ratio=16, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        batch_size, h, w, c = input_shape\n",
    "        self.gap = layers.GlobalAveragePooling2D(data_format=\"channels_last\")\n",
    "        num_hidden = max(c / self.ratio, 4)\n",
    "        self.dense1 = layers.Dense(units=num_hidden)\n",
    "        self.dense2 = layers.Dense(units=c)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.gap(inputs)\n",
    "        x = self.dense1(x)\n",
    "        x = activations.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = activations.sigmoid(x)\n",
    "        x = tf.expand_dims(x, 1)\n",
    "        x = tf.expand_dims(x, 2)\n",
    "        return x * inputs\n",
    "\n",
    "\n",
    "class Rescaler(tf.keras.Model):\n",
    "    def __init__(self, n_channels, scale_factor, rescale_type, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.bn = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "        self.mode = rescale_type\n",
    "        self.factor = scale_factor\n",
    "        \n",
    "        if rescale_type == RescaleType.UP:\n",
    "            self.conv = SpectralNormalization(layers.Conv2D(n_channels, (3, 3), strides=(1, 1), padding=\"same\"))\n",
    "            \n",
    "        elif rescale_type == RescaleType.DOWN:\n",
    "            self.conv = SpectralNormalization(layers.Conv2D(n_channels, (3, 3), strides=(self.factor, self.factor), padding=\"same\"))\n",
    "\n",
    "    def call(self, input):\n",
    "        x = self.bn(input)\n",
    "        x = activations.swish(x)\n",
    "        \n",
    "        if self.mode == RescaleType.UP:\n",
    "            _, height, width, _ = x.get_shape()\n",
    "            x = tf.image.resize(x, size=(self.factor * height, self.factor * width), method=\"nearest\")\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276fba98-1b7d-423a-bba7-5f1df76bcf2f",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6223022-6336-4bea-8ebf-a348c8b196de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decoder_layers(encoder_mult, n_latent_scales, n_groups_per_scale, res_cells_per_group, n_decoder_channels, scale_factor):\n",
    "    m = encoder_mult\n",
    "    dec_layers = []\n",
    "    \n",
    "    for scale in range(n_latent_scales):\n",
    "        print('\\nGroup: ', scale)\n",
    "        n_groups = n_groups_per_scale[scale]\n",
    "\n",
    "        for group in range(n_groups):\n",
    "            if scale == group == 0:\n",
    "                output_channels = int(n_decoder_channels * m)\n",
    "            print('Output channels', output_channels)\n",
    "\n",
    "            if not (scale == 0 and group == 0):\n",
    "                for res in range(res_cells_per_group):\n",
    "                    dec_layers.append(GenerativeResidualCell(output_channels))\n",
    "                    print('Gen Res block', flush=True)\n",
    "\n",
    "            dec_layers.append(DecoderSampleCombiner(output_channels))\n",
    "            print('Decoder Combiner', flush=True)\n",
    "\n",
    "        if scale < n_latent_scales - 1:\n",
    "            output_channels = int(n_decoder_channels * m / scale_factor)\n",
    "\n",
    "            dec_layers.append(Rescaler(output_channels, scale_factor=scale_factor, rescale_type=RescaleType.UP))\n",
    "            print('Rescaler', flush=True)\n",
    "\n",
    "            m /= scale_factor\n",
    "    return dec_layers, m\n",
    "\n",
    "\n",
    "class DecoderSampleCombiner(tf.keras.Model):\n",
    "    def __init__(self, output_channels, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.conv = SpectralNormalization(layers.Conv2D(output_channels, (1, 1), strides=(1, 1), padding=\"same\"))\n",
    "    \n",
    "    def call(self, x, z):\n",
    "        output = tf.concat((x, z), axis=3)\n",
    "        output = self.conv(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class GenerativeResidualCell(tf.keras.Model):\n",
    "    \"\"\"Generative network residual cell in NVAE architecture\"\"\"\n",
    "    def __init__(self, output_channels, expansion_ratio=6, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.batch_norm1 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "        self.conv1 = SpectralNormalization(layers.Conv2D(expansion_ratio * output_channels, (1, 1), padding=\"same\"))\n",
    "        self.batch_norm2 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "        self.depth_conv = layers.DepthwiseConv2D((5, 5), padding=\"same\")\n",
    "        self.batch_norm3 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "        self.conv2 = SpectralNormalization(layers.Conv2D(output_channels, (1, 1), padding=\"same\"))\n",
    "        self.batch_norm4 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "        self.se = SqueezeExcitation()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.batch_norm1(inputs)\n",
    "        x = self.conv1(x)\n",
    "        x = activations.swish(self.batch_norm2(x))\n",
    "        x = self.depth_conv(x)\n",
    "        x = activations.swish(self.batch_norm3(x))\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.se(x)\n",
    "        return 0.1 * inputs + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d126824-8a79-474c-935c-3941145fa924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_enc_dec_model(pp_mult, pp_output_shape, n_latent_per_group, n_latent_scales, n_groups_per_scale, res_cells_per_group, \n",
    "                         n_encoder_channels, n_decoder_channels, scale_factor, nll=False):\n",
    "    \n",
    "    # create tensorflow encoder/decoder end-to-end model\n",
    "    x_in = layers.Input(shape=pp_output_shape, name='encoder_input')\n",
    "\n",
    "    #############################################################\n",
    "    # Encoder\n",
    "    print('\\nENCODER')\n",
    "    #############################################################\n",
    "    \n",
    "    enc_layers, mult = create_encoder_layers(pp_mult, n_latent_scales, n_groups_per_scale, res_cells_per_group, n_encoder_channels, scale_factor)\n",
    "    x = enc_layers[0](x_in)\n",
    "    enc_dec_combiners = []\n",
    "    for group in enc_layers[1:]:\n",
    "        if isinstance(group, EncoderDecoderCombiner):\n",
    "            # We are stepping between groups, need to save results\n",
    "            enc_dec_combiners.append(partial(group, x))\n",
    "        else:\n",
    "            x = group(x)\n",
    "    enc_dec_combiners.reverse()\n",
    "    en_out_shape = x.shape[1:]\n",
    "    \n",
    "    #############################################################\n",
    "    # Decoder\n",
    "    print('\\nDECODER')\n",
    "    #############################################################\n",
    "    \n",
    "    # call latent sapce sampler class\n",
    "    sampler = Sampler(n_latent_scales=n_latent_scales, \n",
    "                      n_groups_per_scale=n_groups_per_scale, \n",
    "                      n_latent_per_group=n_latent_per_group, \n",
    "                      scale_factor=scale_factor)\n",
    "    \n",
    "    # create decoder layers\n",
    "    dec_layers, decoder_mult = create_decoder_layers(mult, n_latent_scales, n_groups_per_scale, res_cells_per_group, n_decoder_channels, scale_factor)\n",
    "    \n",
    "    z_params = []\n",
    "    \n",
    "    if nll:\n",
    "        all_log_p = []\n",
    "        all_log_q = []\n",
    "    \n",
    "    z0, params = sampler(x, z_idx=0)\n",
    "    z_params.append(params)\n",
    "    \n",
    "    if nll:\n",
    "        all_log_q.append(calculate_log_p(z0, params.enc_mu, params.enc_sigma))\n",
    "        all_log_p.append(calculate_log_p(z0, params.dec_mu, params.dec_sigma))\n",
    "    \n",
    "    z0_shape = tf.convert_to_tensor([en_out_shape[0], en_out_shape[1], n_latent_per_group], dtype=tf.int32)\n",
    "    \n",
    "    h_var = tf.Variable(tf.random.uniform([en_out_shape[0], en_out_shape[1], n_decoder_channels], minval=0, maxval=1), trainable=True)\n",
    "    h = tf.expand_dims(h_var, 0)\n",
    "    h = tf.tile(h, [tf.shape(z0)[0], 1, 1, 1])\n",
    "    \n",
    "    x = dec_layers[0](h, z0)\n",
    "    \n",
    "    combine_idx = 0\n",
    "    for group in dec_layers[1:]:\n",
    "        if isinstance(group, DecoderSampleCombiner):\n",
    "            enc_prior = enc_dec_combiners[combine_idx](x)\n",
    "            z_sample, params = sampler(x, z_idx=combine_idx + 1, enc_prior=enc_prior)\n",
    "            \n",
    "            if nll:\n",
    "                all_log_q.append(calculate_log_p(z_sample, params.enc_mu, params.enc_sigma))\n",
    "                all_log_p.append(calculate_log_p(z_sample, params.dec_mu, params.dec_sigma))\n",
    "            \n",
    "            z_params.append(params)\n",
    "            x = group(x, z_sample)\n",
    "            combine_idx += 1\n",
    "        else:\n",
    "            x = group(x)\n",
    "    \n",
    "    if nll:\n",
    "        log_p = tf.zeros((tf.shape(x)[0]))\n",
    "        log_q = tf.zeros((tf.shape(x)[0]))\n",
    "        \n",
    "        for p, q in zip(all_log_p, all_log_q):\n",
    "            log_p += tf.reduce_sum(p, axis=[1, 2, 3])\n",
    "            log_q += tf.reduce_sum(q, axis=[1, 2, 3])\n",
    "        \n",
    "        model_decoder = tf.keras.models.Model(x_in, [x, z_params, log_p, log_q], name='decoder')\n",
    "        model_decoder.summary()\n",
    "    else:\n",
    "        model_decoder = tf.keras.models.Model(x_in, [x, z_params], name='decoder')\n",
    "        model_decoder.summary()\n",
    "    \n",
    "    return model_decoder, int(decoder_mult), x.shape[1:], z0_shape, sampler, h_var, dec_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3e962e-4f77-4ca0-9076-439f6006fc5a",
   "metadata": {},
   "source": [
    "# Post process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57717d60-b445-4f43-9d27-dbcbd8da4e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostprocessCell(tf.keras.Model):\n",
    "    def __init__(self, n_channels, n_nodes, scale_factor, upscale=False, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.sequence = Sequential()\n",
    "        \n",
    "        if upscale:\n",
    "            self.skip = Rescaler(n_channels, scale_factor=scale_factor, rescale_type=RescaleType.UP)\n",
    "        else:\n",
    "            self.skip = tf.identity\n",
    "            \n",
    "        for _ in range(n_nodes):\n",
    "            self.sequence.add(PostprocessNode(n_channels, upscale=upscale, scale_factor=scale_factor))\n",
    "            \n",
    "            if upscale:\n",
    "                # Only scale once in each cells\n",
    "                upscale = False\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.skip(inputs) + 0.1 * self.sequence(inputs)\n",
    "\n",
    "class PostprocessNode(tf.keras.Model):\n",
    "    def __init__(self, n_channels, scale_factor, upscale=False, expansion_ratio=6, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.sequence = Sequential()\n",
    "        \n",
    "        if upscale:\n",
    "            self.sequence.add(Rescaler(n_channels, scale_factor, rescale_type=RescaleType.UP))\n",
    "            \n",
    "        self.sequence.add(layers.BatchNormalization(momentum=0.05, epsilon=1e-5))\n",
    "        hidden_dim = n_channels * expansion_ratio\n",
    "        self.sequence.add(ConvBNSwish(hidden_dim, kernel_size=(1, 1), stride=(1, 1)))\n",
    "        self.sequence.add(ConvBNSwish(hidden_dim, kernel_size=(5, 5), stride=(1, 1)))\n",
    "        self.sequence.add(SpectralNormalization(layers.Conv2D(n_channels, kernel_size=(1, 1), strides=(1, 1), use_bias=False)))\n",
    "        self.sequence.add(layers.BatchNormalization(momentum=0.05, epsilon=1e-5))\n",
    "        self.sequence.add(SqueezeExcitation())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.sequence(inputs)\n",
    "\n",
    "\n",
    "class ConvBNSwish(tf.keras.Model):\n",
    "    def __init__(self, n_channels, kernel_size, stride, groups=1, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.sequence = Sequential()\n",
    "        self.sequence.add(SpectralNormalization(layers.Conv2D(n_channels, kernel_size=kernel_size, strides=stride, use_bias=False, padding=\"same\")))\n",
    "        self.sequence.add(layers.BatchNormalization(momentum=0.05, epsilon=1e-5))\n",
    "        self.sequence.add(layers.Activation(activations.swish))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.sequence(inputs)\n",
    "    \n",
    "    \n",
    "def create_post_process_layers(mult, n_decoder_channels, n_postprocess_blocks, n_postprocess_cells, scale_factor, dataset_option='coco'):\n",
    "    print('\\nPost-process')\n",
    "    sequence = []\n",
    "    for block in range(n_postprocess_blocks):\n",
    "        # First cell rescales\n",
    "        mult /= scale_factor\n",
    "        output_channels = n_decoder_channels * mult\n",
    "\n",
    "        for cell_idx in range(n_postprocess_cells):\n",
    "            print('add post process cell')\n",
    "            sequence.append(PostprocessCell(output_channels, n_nodes=1, upscale=cell_idx == 0, scale_factor=scale_factor))\n",
    "\n",
    "    sequence.append(layers.Activation(activations.elu))\n",
    "    if dataset_option == 'mnist':\n",
    "        sequence.append(SpectralNormalization(layers.Conv2D(1, kernel_size=(3, 3), padding=\"same\")))\n",
    "    else:\n",
    "        sequence.append(SpectralNormalization(layers.Conv2D(100, kernel_size=(3, 3), padding=\"same\"))) # 10 logistic distributions\n",
    "    print('add elu-conv')\n",
    "    \n",
    "    sequence.append(layers.Activation(activations.elu))\n",
    "    sequence.append(SpectralNormalization(layers.Conv2D(100, kernel_size=(3, 3), padding=\"same\")))\n",
    "    print('add elu-conv')\n",
    "    \n",
    "    return sequence\n",
    "\n",
    "def post_process(input_shapes, n_postprocess_blocks, n_postprocess_cells, n_decoder_channels, scale_factor, mult):\n",
    "    # input_shapes and mult output comes from decoder output\n",
    "    post_layers = create_post_process_layers(mult, n_decoder_channels, n_postprocess_blocks, n_postprocess_cells, scale_factor)\n",
    "    \n",
    "    in_put = layers.Input(shape=input_shapes, name='post_process')\n",
    "    x = post_layers[0](in_put)\n",
    "    \n",
    "    for layer in post_layers[1:]:\n",
    "        x = layer(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(in_put, x, name='post_process')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73b9f07e-617a-4a87-bfa7-f3a383e054de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_(image_shape, n_preprocess_blocks, n_preprocess_cells, n_postprocess_blocks, n_postprocess_cells, \n",
    "          n_encoder_channels, n_decoder_channels, n_latent_per_group, n_latent_scales, n_groups_per_scale, res_cells_per_group, scale_factor):\n",
    "\n",
    "    # preprocess\n",
    "    model_preprocess, pp_mult, pp_output_shape = pre_process_block(image_shape, \n",
    "                                                                   n_encoder_channels, \n",
    "                                                                   n_preprocess_blocks, \n",
    "                                                                   n_preprocess_cells, \n",
    "                                                                   scale_factor)\n",
    "    \n",
    "    \n",
    "    # encoder / decoder\n",
    "    model_decoder, decoder_mult, decoder_out_shape, z0_shape, sampler, h_var, dec_layers = create_enc_dec_model(pp_mult, \n",
    "                                                                                                                pp_output_shape, \n",
    "                                                                                                                n_latent_per_group, \n",
    "                                                                                                                n_latent_scales, \n",
    "                                                                                                                n_groups_per_scale, \n",
    "                                                                                                                res_cells_per_group,\n",
    "                                                                                                                n_encoder_channels, \n",
    "                                                                                                                n_decoder_channels, \n",
    "                                                                                                                scale_factor)\n",
    "    \n",
    "    \n",
    "    # post process\n",
    "    model_postprocess = post_process(decoder_out_shape, \n",
    "                                     n_postprocess_blocks, \n",
    "                                     n_postprocess_cells, \n",
    "                                     n_decoder_channels, \n",
    "                                     scale_factor, \n",
    "                                     decoder_mult)\n",
    "    \n",
    "    return model_preprocess, model_decoder, model_postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d6cccdd-5b5d-4db9-a1d9-08ffb9fceae5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"preprocess\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image (InputLayer)           [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "spectral_normalization (Spec (None, 128, 128, 16)      464       \n",
      "_________________________________________________________________\n",
      "bn_swish_conv (BNSwishConv)  (None, 128, 128, 16)      4948      \n",
      "_________________________________________________________________\n",
      "bn_swish_conv_1 (BNSwishConv (None, 128, 128, 16)      4948      \n",
      "_________________________________________________________________\n",
      "bn_swish_conv_2 (BNSwishConv (None, 64, 64, 32)        15012     \n",
      "_________________________________________________________________\n",
      "bn_swish_conv_3 (BNSwishConv (None, 64, 64, 32)        19108     \n",
      "_________________________________________________________________\n",
      "bn_swish_conv_4 (BNSwishConv (None, 64, 64, 32)        19108     \n",
      "_________________________________________________________________\n",
      "bn_swish_conv_5 (BNSwishConv (None, 32, 32, 64)        58692     \n",
      "=================================================================\n",
      "Total params: 122,280\n",
      "Trainable params: 121,112\n",
      "Non-trainable params: 1,168\n",
      "_________________________________________________________________\n",
      "4 (32, 32, 64)\n",
      "\n",
      "ENCODER\n",
      "\n",
      "Group:  0\n",
      "Output_channels:  64\n",
      "res block\n",
      "res block\n",
      "combiner\n",
      "Output_channels:  64\n",
      "res block\n",
      "res block\n",
      "combiner\n",
      "Rescaler\n",
      "New output_channels:  128\n",
      "\n",
      "Group:  1\n",
      "Output_channels:  128\n",
      "res block\n",
      "res block\n",
      "combiner\n",
      "Output_channels:  128\n",
      "res block\n",
      "res block\n",
      "\n",
      "DECODER\n",
      "\n",
      "Group:  0\n",
      "Output channels 128\n",
      "Decoder Combiner\n",
      "Output channels 128\n",
      "Gen Res block\n",
      "Gen Res block\n",
      "Decoder Combiner\n",
      "Rescaler\n",
      "\n",
      "Group:  1\n",
      "Output channels 64\n",
      "Gen Res block\n",
      "Gen Res block\n",
      "Decoder Combiner\n",
      "Output channels 64\n",
      "Gen Res block\n",
      "Gen Res block\n",
      "Decoder Combiner\n",
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 32, 32, 64)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_0_0_0 (EncodingResidu (None, 32, 32, 64)   75076       encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res_block_0_0_1 (EncodingResidu (None, 32, 32, 64)   75076       res_block_0_0_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_0_1_0 (EncodingResidu (None, 32, 32, 64)   75076       res_block_0_0_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_0_1_1 (EncodingResidu (None, 32, 32, 64)   75076       res_block_0_1_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "rescaler (Rescaler)             (None, 16, 16, 128)  74240       res_block_0_1_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_1_0_0 (EncodingResidu (None, 16, 16, 128)  298632      rescaler[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res_block_1_0_1 (EncodingResidu (None, 16, 16, 128)  298632      res_block_1_0_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_1_1_0 (EncodingResidu (None, 16, 16, 128)  298632      res_block_1_0_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_1_1_1 (EncodingResidu (None, 16, 16, 128)  298632      res_block_1_1_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "elu (ELU)                       (None, 16, 16, 128)  0           res_block_1_1_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spectral_normalization_41 (Spec (None, 16, 16, 128)  16640       elu[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "elu_1 (ELU)                     (None, 16, 16, 128)  0           spectral_normalization_41[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "sampler (Sampler)               multiple             149040      elu_1[0][0]                      \n",
      "                                                                 generative_residual_cell_1[0][0] \n",
      "                                                                 generative_residual_cell_3[0][0] \n",
      "                                                                 generative_residual_cell_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(4,)]               0           sampler[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile/multiples (Ten [(4,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile (TensorFlowOpL [(None, 16, 16, 16)] 0           tf_op_layer_Tile/multiples[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_sample_combiner (Decode (None, 16, 16, 128)  4864        tf_op_layer_Tile[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell (Gener (None, 16, 16, 128)  227720      decoder_sample_combiner[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_1 (Gen (None, 16, 16, 128)  227720      generative_residual_cell[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_decoder_combiner_2 (Enc (None, 16, 16, 128)  16640       res_block_1_0_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_sample_combiner_1 (Deco (None, 16, 16, 128)  19200       generative_residual_cell_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "rescaler_1 (Rescaler)           (None, 32, 32, 64)   74368       decoder_sample_combiner_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_2 (Gen (None, 32, 32, 64)   64196       rescaler_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_3 (Gen (None, 32, 32, 64)   64196       generative_residual_cell_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "encoder_decoder_combiner_1 (Enc (None, 32, 32, 64)   4224        res_block_0_1_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_sample_combiner_2 (Deco (None, 32, 32, 64)   5504        generative_residual_cell_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_4 (Gen (None, 32, 32, 64)   64196       decoder_sample_combiner_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_5 (Gen (None, 32, 32, 64)   64196       generative_residual_cell_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "encoder_decoder_combiner (Encod (None, 32, 32, 64)   4224        res_block_0_0_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_sample_combiner_3 (Deco (None, 32, 32, 64)   5504        generative_residual_cell_5[0][0] \n",
      "==================================================================================================\n",
      "Total params: 2,581,504\n",
      "Trainable params: 2,557,352\n",
      "Non-trainable params: 24,152\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Post-process\n",
      "add post process cell\n",
      "add post process cell\n",
      "add post process cell\n",
      "add post process cell\n",
      "add post process cell\n",
      "add post process cell\n",
      "add elu-conv\n",
      "add elu-conv\n",
      "Model: \"post_process\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "post_process (InputLayer)    [(None, 32, 32, 64)]      0         \n",
      "_________________________________________________________________\n",
      "postprocess_cell (Postproces (None, 64, 64, 32)        973892    \n",
      "_________________________________________________________________\n",
      "postprocess_cell_1 (Postproc (None, 64, 64, 32)        936388    \n",
      "_________________________________________________________________\n",
      "postprocess_cell_2 (Postproc (None, 64, 64, 32)        936388    \n",
      "_________________________________________________________________\n",
      "postprocess_cell_3 (Postproc (None, 128, 128, 16)      244260    \n",
      "_________________________________________________________________\n",
      "postprocess_cell_4 (Postproc (None, 128, 128, 16)      234724    \n",
      "_________________________________________________________________\n",
      "postprocess_cell_5 (Postproc (None, 128, 128, 16)      234724    \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "spectral_normalization_88 (S (None, 128, 128, 100)     14600     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 128, 128, 100)     0         \n",
      "_________________________________________________________________\n",
      "spectral_normalization_89 (S (None, 128, 128, 100)     90200     \n",
      "=================================================================\n",
      "Total params: 3,665,176\n",
      "Trainable params: 3,658,592\n",
      "Non-trainable params: 6,584\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_preprocess, model_decoder, model_postprocess = main_(image_shape, \n",
    "                                                           n_preprocess_blocks, \n",
    "                                                           n_preprocess_cells, \n",
    "                                                           n_postprocess_blocks, \n",
    "                                                           n_postprocess_cells, \n",
    "                                                           n_encoder_channels, \n",
    "                                                           n_decoder_channels, \n",
    "                                                           n_latent_per_group,\n",
    "                                                           n_latent_scales, \n",
    "                                                           n_groups_per_scale, \n",
    "                                                           res_cells_per_group, \n",
    "                                                           scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd79c89f-060b-4981-a0f1-bd5b3aeda266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class NVAE(tf.keras.Model):\n",
    "#     def __init__(self,\n",
    "#                  n_encoder_channels,\n",
    "#                  n_decoder_channels,\n",
    "#                  res_cells_per_group,\n",
    "#                  n_preprocess_blocks,\n",
    "#                  n_preprocess_cells,\n",
    "#                  n_postprocess_blocks,\n",
    "#                  n_post_process_cells,\n",
    "#                  n_latent_per_group,\n",
    "#                  n_latent_scales,\n",
    "#                  n_groups_per_scale,\n",
    "#                  sr_lambda,\n",
    "#                  scale_factor,\n",
    "#                  n_total_iterations,\n",
    "#                  step_based_warmup,\n",
    "#                  input_shape,\n",
    "#                  dataset_option,\n",
    "#                  use_multigpu,\n",
    "#                  GLOBAL_BATCH_SIZE,\n",
    "#                  optimizer,\n",
    "#                  **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "        \n",
    "#         # multi gpu params\n",
    "#         self.use_multigpu = use_multigpu\n",
    "#         self.GLOBAL_BATCH_SIZE = GLOBAL_BATCH_SIZE\n",
    "        \n",
    "#         # Updated for each gradient pass, training step\n",
    "#         self.sr_lambda = sr_lambda\n",
    "#         self.step_based_warmup = step_based_warmup\n",
    "        \n",
    "#         self.optimizer = optimizer\n",
    "        \n",
    "#         self.n_latent_per_group = n_latent_per_group\n",
    "#         self.n_latent_scales = n_latent_scales\n",
    "#         self.n_groups_per_scale = n_groups_per_scale\n",
    "#         self.n_total_iterations = n_total_iterations\n",
    "#         self.dataset_option = dataset_option\n",
    "        \n",
    "#         self.elbo = Mean(name=\"elbo\")\n",
    "#         self.bce = Mean(name=\"reconstruction_loss\")\n",
    "#         self.kld = Mean(name=\"kl_loss\")\n",
    "#         self.bnloss = Mean(name=\"bn_loss\")\n",
    "        \n",
    "#         self.elbo_val = Mean(name=\"elbo_test\")\n",
    "#         self.bce_val = Mean(name=\"reconstruction_loss_val\")\n",
    "#         self.kld_val = Mean(name=\"kl_loss_val\")\n",
    "#         self.bnloss_val = Mean(name=\"bn_loss_val\")\n",
    "        \n",
    "#         self.elbo_test = Mean(name=\"elbo_test\")\n",
    "#         self.bce_test = Mean(name=\"reconstruction_loss_test\")\n",
    "#         self.kld_test = Mean(name=\"kl_loss_test\")\n",
    "#         self.bnloss_test = Mean(name=\"bn_loss_test\")\n",
    "        \n",
    "#         self.mse_train = Mean(name=\"mse_train\")\n",
    "#         self.mse_val = Mean(name=\"mse_val\")\n",
    "#         self.mse_test = Mean(name=\"mse_test\")\n",
    "        \n",
    "#         # preprocess\n",
    "#         model_preprocess, pp_mult, pp_output_shape = pre_process_block(input_shape, \n",
    "#                                                                        n_encoder_channels, \n",
    "#                                                                        n_preprocess_blocks, \n",
    "#                                                                        n_preprocess_cells, \n",
    "#                                                                        scale_factor)\n",
    "\n",
    "#         # encoder / decoder\n",
    "#         model_decoder, decoder_mult, decoder_out_shape, z0_shape, sampler, h_var, dec_layers = create_enc_dec_model(pp_mult, \n",
    "#                                                                                                                     pp_output_shape, \n",
    "#                                                                                                                     n_latent_per_group, \n",
    "#                                                                                                                     n_latent_scales, \n",
    "#                                                                                                                     n_groups_per_scale, \n",
    "#                                                                                                                     n_encoder_channels, \n",
    "#                                                                                                                     n_decoder_channels, \n",
    "#                                                                                                                     scale_factor)\n",
    "#         # post process\n",
    "#         model_postprocess = post_process(decoder_out_shape, \n",
    "#                                          n_postprocess_blocks, \n",
    "#                                          n_post_process_cells, \n",
    "#                                          n_decoder_channels, \n",
    "#                                          scale_factor, \n",
    "#                                          decoder_mult)\n",
    "        \n",
    "#         self.model_preprocess = model_preprocess\n",
    "#         self.model_postprocess = model_decoder\n",
    "#         self.model_postprocess = model_postprocess\n",
    "#         self.z0_shape = z0_shape\n",
    "#         self.sampler = sampler\n",
    "#         self.h_var = h_var\n",
    "#         self.dec_layers = dec_layers\n",
    "        \n",
    "#     # main method\n",
    "#     def call(self, inputs):\n",
    "#         x = self.model_preprocess(inputs)\n",
    "#         x, z_params = self.model_decoder(x)\n",
    "#         reconstruction = self.model_postprocess(x)\n",
    "#         return reconstruction, z_params\n",
    "    \n",
    "#     def train_step(self, data, steps, epoch):\n",
    "#         if self.dataset_option =='mnist':\n",
    "#             if isinstance(data, tuple):\n",
    "#                 data = data[0] #Remove the label.\n",
    "        \n",
    "#         with tf.GradientTape() as tape:\n",
    "#             reconstruction_logits, z_params = self(data)\n",
    "            \n",
    "#             recon_loss = self.calculate_recon_loss(data, reconstruction_logits)\n",
    "#             bn_loss = self.calculate_bn_loss()\n",
    "            \n",
    "#             # warming up KL term for first 30% of training\n",
    "#             warmup_metric = steps if self.step_based_warmup else epoch\n",
    "#             beta = min(warmup_metric / (0.3 * self.n_total_iterations), 1)\n",
    "#             activate_balancing = beta < 1\n",
    "#             kl_loss = beta * self.calculate_kl_loss(z_params, activate_balancing)\n",
    "            \n",
    "#             if self.use_multigpu:\n",
    "#                 loss = tf.nn.compute_average_loss(recon_loss + kl_loss, global_batch_size=self.GLOBAL_BATCH_SIZE)\n",
    "#             else:\n",
    "#                 loss = tf.math.reduce_mean(recon_loss + kl_loss)\n",
    "#             total_loss = loss + bn_loss\n",
    "#         gradients = tape.gradient(total_loss, self.trainable_weights)\n",
    "#         self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        \n",
    "#         self.elbo.update_state(total_loss)\n",
    "#         self.bce.update_state(recon_loss)\n",
    "#         self.kld.update_state(kl_loss)\n",
    "#         self.bnloss.update_state(bn_loss)\n",
    "        \n",
    "#         reconstruction = self.sample_from_discretized_mix_logistic(reconstruction_logits)\n",
    "#         mse = tf.reduce_sum(tf.keras.losses.mean_squared_error(data, reconstruction), axis=(1, 2))\n",
    "#         if self.use_multigpu:\n",
    "#             self.mse_train.update_state(tf.nn.compute_average_loss(mse, global_batch_size=self.GLOBAL_BATCH_SIZE))\n",
    "#         else:\n",
    "#             self.mse_train.update_state(tf.reduce_mean(mse))\n",
    "            \n",
    "    \n",
    "#     def val_step(self, data, steps, epoch):\n",
    "#         reconstruction_logits, z_params, *_ = self(data)\n",
    "#         recon_loss = self.calculate_recon_loss(data, reconstruction_logits)\n",
    "#         bn_loss = self.calculate_bn_loss()\n",
    "        \n",
    "#         # warming up KL term for first 30% of training\n",
    "#         warmup_metric = steps if self.step_based_warmup else epoch\n",
    "#         beta = min(warmup_metric / (0.3 * self.n_total_iterations), 1)\n",
    "#         activate_balancing = beta < 1\n",
    "#         kl_loss = beta * self.calculate_kl_loss(z_params, activate_balancing)\n",
    "        \n",
    "#         if self.use_multigpu:\n",
    "#             loss = tf.nn.compute_average_loss(recon_loss + kl_loss, global_batch_size=self.GLOBAL_BATCH_SIZE)\n",
    "#         else:\n",
    "#             loss = tf.math.reduce_mean(recon_loss + kl_loss)\n",
    "#         total_loss = loss + bn_loss\n",
    "        \n",
    "#         reconstruction = self.sample_from_discretized_mix_logistic(reconstruction_logits)       \n",
    "            \n",
    "#         self.elbo_val.update_state(total_loss)\n",
    "#         self.bce_val.update_state(recon_loss)\n",
    "#         self.kld_val.update_state(kl_loss)\n",
    "#         self.bnloss_val.update_state(bn_loss)\n",
    "#         mse = tf.reduce_sum(tf.keras.losses.mean_squared_error(data, reconstruction), axis=(1, 2))\n",
    "#         if self.use_multigpu:\n",
    "#             self.mse_val.update_state(tf.nn.compute_average_loss(mse, global_batch_size=self.GLOBAL_BATCH_SIZE))\n",
    "#         else:\n",
    "#             self.mse_val.update_state(tf.reduce_mean(mse))\n",
    "        \n",
    "#     def test_step(self, data, steps, epoch):\n",
    "#         reconstruction_logits, z_params, *_ = self(data)\n",
    "#         recon_loss = self.calculate_recon_loss(data, reconstruction_logits)\n",
    "#         bn_loss = self.calculate_bn_loss()\n",
    "        \n",
    "#         # warming up KL term for first 30% of training\n",
    "#         warmup_metric = steps if self.step_based_warmup else epoch\n",
    "#         beta = min(warmup_metric / (0.3 * self.n_total_iterations), 1)\n",
    "#         activate_balancing = beta < 1\n",
    "#         kl_loss = beta * self.calculate_kl_loss(z_params, activate_balancing)\n",
    "        \n",
    "#         if self.use_multigpu:\n",
    "#             loss = tf.nn.compute_average_loss(recon_loss + kl_loss, global_batch_size=self.GLOBAL_BATCH_SIZE)\n",
    "#         else:\n",
    "#             loss = tf.math.reduce_mean(recon_loss + kl_loss)\n",
    "#         total_loss = loss + bn_loss\n",
    "        \n",
    "#         reconstruction = self.sample_from_discretized_mix_logistic(reconstruction_logits)\n",
    "        \n",
    "#         self.elbo_test.update_state(total_loss)\n",
    "#         self.bce_test.update_state(recon_loss)\n",
    "#         self.kld_test.update_state(kl_loss)\n",
    "#         self.bnloss_test.update_state(bn_loss)\n",
    "#         mse = tf.reduce_sum(tf.keras.losses.mean_squared_error(data, reconstruction), axis=(1, 2))\n",
    "#         if self.use_multigpu:\n",
    "#             self.mse_test.update_state(tf.nn.compute_average_loss(mse, global_batch_size=self.GLOBAL_BATCH_SIZE))\n",
    "#         else:\n",
    "#             self.mse_test.update_state(tf.reduce_mean(mse))\n",
    "            \n",
    "    \n",
    "#     def sample(self, n_samples, temperature=1.0):\n",
    "#         s = tf.expand_dims(self.h_var, 0)\n",
    "#         s = tf.tile(s, [n_samples, 1, 1, 1])\n",
    "        \n",
    "#         z0_shape = tf.concat([[n_samples], self.z0_shape], axis=0)\n",
    "#         mu = softclamp5(tf.zeros(z0_shape))\n",
    "#         sigma = tf.math.exp(softclamp5(tf.zeros(z0_shape))) + 1e-2\n",
    "        \n",
    "#         if temperature != 1.0:\n",
    "#             sigma *= temperature\n",
    "#         z = self.sampler.sample(mu, sigma)\n",
    "\n",
    "#         decoder_index = 0\n",
    "#         last_s = None\n",
    "        \n",
    "#         for layer in self.dec_layers:\n",
    "#             if isinstance(layer, DecoderSampleCombiner):\n",
    "#                 if decoder_index > 0:\n",
    "#                     mu, log_sigma = self.sampler.get_params(self.decoder.sampler.dec_sampler, decoder_index, s)\n",
    "#                     mu = softclamp5(mu)\n",
    "#                     sigma = tf.math.exp(softclamp5(log_sigma)) + 1e-2\n",
    "#                     z = self.sampler.sample(mu, sigma)\n",
    "#                 last_s = s\n",
    "#                 s = layer(s, z)\n",
    "#                 decoder_index += 1\n",
    "#             else:\n",
    "#                 s = layer(s)\n",
    "        \n",
    "#         reconstruction = self.model_postprocess(s)\n",
    "        \n",
    "#         if self.dataset_option == 'mnist':\n",
    "#             distribution = distributions.Bernoulli(logits=reconstruction, dtype=tf.float32, allow_nan_stats=False)\n",
    "#             images = distribution.probs_parameter()\n",
    "#         else:\n",
    "#             images = self.sample_from_discretized_mix_logistic(reconstruction)\n",
    "        \n",
    "#         z1 = self.sampler.sample(mu, sigma)\n",
    "#         z2 = self.sampler.sample(mu, sigma)\n",
    "#         # return images and mu, sigma, s used for sampling last hierarchical z in turn enabling sampling of images\n",
    "#         return images, last_s, z1, z2\n",
    "\n",
    "    \n",
    "#     # As sample(), but starts from a fixed last hierarchical z given by mu, sigma and s. See sample() for details.\n",
    "#     def sample_with_z(self, z, s):\n",
    "#         last_gen_layer = self.dec_layers[-1]\n",
    "#         s = last_gen_layer(s, z)\n",
    "        \n",
    "#         if self.dataset_option == 'mnist':\n",
    "#             reconstruction = self.postprocess(s)\n",
    "#             distribution = distributions.Bernoulli(logits=reconstruction, dtype=tf.float32, allow_nan_stats=False)\n",
    "#             images = distribution.mean()\n",
    "#         else:\n",
    "#             images = self.sample_from_discretized_mix_logistic(reconstruction)\n",
    "#         return images\n",
    "    \n",
    "    \n",
    "#     def calculate_kl_loss(self, z_params: List, balancing):\n",
    "#         # -KL(q(z1|x)||p(z1)) - sum[ KL(q(zl|x,z<l) || p(z|z<l))]\n",
    "#         kl_per_group = []\n",
    "        \n",
    "#         # n_groups x batch_size x 4\n",
    "#         loss = 0\n",
    "#         for g in z_params:\n",
    "#             # [enc_mu, enc_sigma, dec_mu, dec_sigma]\n",
    "#             # term1 = (g.enc_mu - g.dec_mu) / g.dec_sigma\n",
    "#             # term2 = g.enc_sigma / g.dec_sigma\n",
    "            \n",
    "#             term1 = (g[0] - g[2]) / g[3]\n",
    "#             term2 = g[1] / g[3]\n",
    "#             kl = 0.5 * (term1 * term1 + term2 * term2) - 0.5 - tf.math.log(term2)\n",
    "#             kl_per_group.append(tf.math.reduce_sum(kl, axis=[1, 2, 3]))\n",
    "        \n",
    "#         # balance kl\n",
    "#         if balancing:\n",
    "            \n",
    "#             # Requires different treatment for encoder and decoder?\n",
    "#             kl_alphas = self.calculate_kl_alphas(self.n_latent_scales, self.n_groups_per_scale)\n",
    "            \n",
    "#             kl_all = tf.stack(kl_per_group, 0)\n",
    "#             kl_coeff_i = tf.reduce_mean(tf.math.abs(kl_all), 1) + 0.01\n",
    "#             total_kl = tf.reduce_sum(kl_coeff_i)\n",
    "#             kl_coeff_i = kl_coeff_i / kl_alphas * total_kl\n",
    "#             kl_coeff_i = kl_coeff_i / tf.reduce_mean(kl_coeff_i, 0, keepdims=True)\n",
    "#             temp = tf.stack(kl_per_group, 1)\n",
    "            \n",
    "#             # We stop gradient through kl_coeff_i because we are only interested\n",
    "#             # in changing the magnitude of the loss, not the direction of the\n",
    "#             # gradient.\n",
    "#             loss = tf.reduce_sum(temp * tf.stop_gradient(kl_coeff_i), axis=[1])\n",
    "#         else:\n",
    "#             loss = tf.math.reduce_sum(tf.convert_to_tensor(kl_per_group, dtype=tf.float32), axis=[0])\n",
    "#         return loss\n",
    "    \n",
    "#     # Calculates the balancer coefficients alphas. The coefficient decay for later groups,\n",
    "#     # for which original paper offer several functions. Here, a square function is used.\n",
    "#     def calculate_kl_alphas(self, num_scales, groups_per_scale):\n",
    "#         coeffs = []\n",
    "#         for i in range(num_scales):\n",
    "#             aa = np.square(2 ** i)\n",
    "#             bb = groups_per_scale[num_scales - i - 1]\n",
    "#             cc = tf.ones([groups_per_scale[num_scales - i - 1]], tf.float32)\n",
    "#             coeffs.append(aa / bb  * cc)\n",
    "#         coeffs = tf.concat(coeffs, 0)\n",
    "#         coeffs /= tf.reduce_min(coeffs)\n",
    "#         return coeffs\n",
    "    \n",
    "#     def calculate_recon_loss(self, inputs, reconstruction, crop_output=False):\n",
    "#         if self.dataset_option == 'mnist':\n",
    "#             if crop_output:\n",
    "#                 inputs = inputs[:, 2:30, 2:30, :]\n",
    "#                 reconstruction = reconstruction[:, 2:30, 2:30, :]\n",
    "#             log_probs = distributions.Bernoulli(logits=reconstruction, dtype=tf.float32, allow_nan_stats=False).log_prob(inputs)\n",
    "#             recons_loss = -tf.math.reduce_sum(log_probs, axis=[1, 2, 3])\n",
    "#         else:\n",
    "#             recons_loss = self.discretized_mix_logistic_loss(inputs, reconstruction)\n",
    "#         return recons_loss\n",
    "    \n",
    "#     def calculate_bn_loss(self):\n",
    "#         bn_loss = 0.0\n",
    "#         for ind, model in enumerate(model_decoder.layers):\n",
    "#             if isinstance(model, layers.InputLayer) or isinstance(model, layers.ELU) or isinstance(model, SpectralNormalization) or isinstance(model, tf.python.keras.engine.base_layer.TensorFlowOpLayer):\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 for layer in model.layers:\n",
    "#                     if isinstance(layer, layers.BatchNormalization):\n",
    "#                         bn_loss += tf.math.reduce_max(tf.math.abs(layer.weights[0]))\n",
    "#                     elif hasattr(layer, \"layers\"):\n",
    "#                         for inner_layer in layer.layers:\n",
    "#                             if isinstance(inner_layer, layers.BatchNormalization):\n",
    "#                                 bn_loss += tf.math.reduce_max(tf.math.abs(inner_layer.weights[0]))\n",
    "#         return self.sr_lambda * bn_loss\n",
    "    \n",
    "#     def int_shape(self, x):\n",
    "#         return list(map(int, x.get_shape()))\n",
    "    \n",
    "#     def log_sum_exp(self, x):\n",
    "#         \"\"\" numerically stable log_sum_exp implementation that prevents overflow \"\"\"\n",
    "#         axis = len(x.get_shape())-1\n",
    "#         m = tf.reduce_max(x, axis)\n",
    "#         m2 = tf.reduce_max(x, axis, keepdims=True)\n",
    "#         return m + tf.math.log(tf.reduce_sum(tf.exp(x-m2), axis))\n",
    "\n",
    "#     def log_prob_from_logits(self, x):\n",
    "#         \"\"\" numerically stable log_softmax implementation that prevents overflow \"\"\"\n",
    "#         axis = len(x.get_shape()) - 1\n",
    "#         m = tf.reduce_max(x, axis, keepdims=True)\n",
    "#         return x - m - tf.math.log(tf.reduce_sum(tf.math.exp(x-m), axis, keepdims=True))\n",
    "    \n",
    "#     def discretized_mix_logistic_loss(self, x, l, sum_all=True):\n",
    "#         x = 2.0 * x - 1.0\n",
    "        \n",
    "#         \"\"\" log-likelihood for mixture of discretized logistics, assumes the data has been rescaled to [-1,1] interval \"\"\"\n",
    "#         xs = self.int_shape(x) # true image (i.e. labels) to regress to, e.g. (B,32,32,3)\n",
    "#         ls = self.int_shape(l) # predicted distribution, e.g. (B,32,32,100)\n",
    "#         nr_mix = int(ls[-1] / 10) # here and below: unpacking the params of the mixture of logistics 10 groups\n",
    "#         logit_probs = l[:, :, :, :nr_mix]\n",
    "        \n",
    "#         l = tf.reshape(l[:,:,:,nr_mix:], xs + [nr_mix*3])\n",
    "#         means = l[:,:,:,:,:nr_mix]\n",
    "#         log_scales = tf.maximum(l[:,:,:,:,nr_mix:2*nr_mix], -7.)\n",
    "#         coeffs = tf.nn.tanh(l[:,:,:,:,2*nr_mix:3*nr_mix])\n",
    "#         x = tf.reshape(x, xs + [1]) + tf.zeros(xs + [nr_mix]) # here and below: getting the means and adjusting them based on preceding sub-pixels\n",
    "#         m2 = tf.reshape(means[:,:,:,1,:] + coeffs[:, :, :, 0, :] * x[:, :, :, 0, :], [xs[0],xs[1],xs[2],1,nr_mix])\n",
    "#         m3 = tf.reshape(means[:, :, :, 2, :] + coeffs[:, :, :, 1, :] * x[:, :, :, 0, :] + coeffs[:, :, :, 2, :] * x[:, :, :, 1, :], [xs[0],xs[1],xs[2],1,nr_mix])\n",
    "        \n",
    "#         # reshaping final image\n",
    "#         means = tf.concat([tf.reshape(means[:,:,:,0,:], [xs[0],xs[1],xs[2],1,nr_mix]), m2, m3],3)\n",
    "\n",
    "#         centered_x = x - means\n",
    "#         inv_stdv = tf.exp(-log_scales)\n",
    "#         plus_in = inv_stdv * (centered_x + 1./255.)\n",
    "#         cdf_plus = tf.nn.sigmoid(plus_in)\n",
    "#         min_in = inv_stdv * (centered_x - 1./255.)\n",
    "#         cdf_min = tf.nn.sigmoid(min_in)\n",
    "#         log_cdf_plus = plus_in - tf.nn.softplus(plus_in) # log probability for edge case of 0 (before scaling)\n",
    "#         log_one_minus_cdf_min = -tf.nn.softplus(min_in) # log probability for edge case of 255 (before scaling)\n",
    "#         cdf_delta = cdf_plus - cdf_min # probability for all other cases\n",
    "#         mid_in = inv_stdv * centered_x\n",
    "#         log_pdf_mid = mid_in - log_scales - 2.*tf.nn.softplus(mid_in) # log probability in the center of the bin, to be used in extreme cases (not actually used in our code)\n",
    "        \n",
    "#         # now select the right output: left edge case, right edge case, normal case, extremely low prob case (doesn't actually happen for us)\n",
    "        \n",
    "#         # this is what we are really doing, but using the robust version below for extreme cases in other applications and to avoid NaN issue with tf.select()\n",
    "#         # log_probs = tf.select(x < -0.999, log_cdf_plus, tf.select(x > 0.999, log_one_minus_cdf_min, tf.math.log(cdf_delta)))\n",
    "        \n",
    "#         # robust version, that still works if probabilities are below 1e-5 (which never happens in our code)\n",
    "#         # tensorflow backpropagates through tf.select() by multiplying with zero instead of selecting: this requires use to use some ugly tricks to avoid potential NaNs\n",
    "#         # the 1e-12 in tf.maximum(cdf_delta, 1e-12) is never actually used as output, it's purely there to get around the tf.select() gradient issue\n",
    "#         # if the probability on a sub-pixel is below 1e-5, \n",
    "#         # we use an approximation based on the assumption that the log-density is constant in the bin of the observed sub-pixel value\n",
    "        \n",
    "#         log_probs = tf.where(x < -0.999, log_cdf_plus, tf.where(x > 0.999, log_one_minus_cdf_min, \n",
    "#                                                                 tf.where(cdf_delta > 1e-5, tf.math.log(tf.maximum(cdf_delta, 1e-12)), log_pdf_mid - np.log(127.5))))\n",
    "        \n",
    "#         log_probs = tf.reduce_sum(log_probs,3) + self.log_prob_from_logits(logit_probs)\n",
    "        \n",
    "#         if sum_all:\n",
    "#             return -tf.reduce_sum(self.log_sum_exp(log_probs)), \n",
    "#         else:\n",
    "#             return -tf.reduce_sum(self.log_sum_exp(log_probs),[1,2])\n",
    "\n",
    "#     def sample_from_discretized_mix_logistic(self, l, nr_mix=10):\n",
    "#         # l is the reconstruction vector before processing\n",
    "#         ls = self.int_shape(l)\n",
    "#         xs = ls[:-1] + [3]\n",
    "        \n",
    "#         # unpack parameters\n",
    "#         logit_probs = l[:, :, :, :nr_mix]\n",
    "#         l = tf.reshape(l[:, :, :, nr_mix:], xs + [nr_mix*3])\n",
    "\n",
    "#         # sample mixture indicator from softmax\n",
    "#         sel = tf.one_hot(tf.argmax(logit_probs - tf.math.log(-tf.math.log(tf.random.uniform(logit_probs.get_shape(), minval=1e-5, maxval=1. - 1e-5))), 3), \n",
    "#                          depth=nr_mix, dtype=tf.float32)\n",
    "#         sel = tf.reshape(sel, xs[:-1] + [1,nr_mix])\n",
    "\n",
    "#         # select logistic parameters\n",
    "#         means = tf.reduce_sum(l[:,:,:,:,:nr_mix]*sel,4)\n",
    "#         log_scales = tf.maximum(tf.reduce_sum(l[:,:,:,:,nr_mix:2*nr_mix]*sel,4), -7.)\n",
    "#         coeffs = tf.reduce_sum(tf.nn.tanh(l[:,:,:,:,2*nr_mix:3*nr_mix])*sel,4)\n",
    "        \n",
    "#         # sample from logistic & clip to interval\n",
    "#         # we don't actually round to the nearest 8bit value when sampling\n",
    "#         u = tf.random.uniform(means.get_shape(), minval=1e-5, maxval=1. - 1e-5)\n",
    "#         x = means + tf.exp(log_scales)*(tf.math.log(u) - tf.math.log(1. - u))\n",
    "#         x0 = tf.minimum(tf.maximum(x[:,:,:,0], -1.), 1.)\n",
    "#         x1 = tf.minimum(tf.maximum(x[:,:,:,1] + coeffs[:,:,:,0]*x0, -1.), 1.)\n",
    "#         x2 = tf.minimum(tf.maximum(x[:,:,:,2] + coeffs[:,:,:,1]*x0 + coeffs[:,:,:,2]*x1, -1.), 1.)\n",
    "#         return tf.concat([tf.reshape(x0,xs[:-1]+[1]), tf.reshape(x1,xs[:-1]+[1]), tf.reshape(x2,xs[:-1]+[1])],3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
