{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ac86e5-cffc-454b-9e23-6db815ee82c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from functools import partial\n",
    "from util import calculate_log_p, softclamp5\n",
    "from common import RescaleType, Rescaler, SqueezeExcitation\n",
    "\n",
    "from enum import Enum, auto\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import activations, Sequential, layers\n",
    "from tensorflow_addons.layers import SpectralNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b613b68-d024-467d-a591-4e05b77999d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (128, 128, 3)\n",
    "n_encoder_channels = 16\n",
    "n_decoder_channels = 16\n",
    "\n",
    "n_preprocess_blocks = 2\n",
    "n_preprocess_cells = 3\n",
    "\n",
    "n_postprocess_blocks = 2\n",
    "n_postprocess_cells = 3\n",
    "\n",
    "mult = 1\n",
    "scale_factor = 2\n",
    "\n",
    "n_latent_per_group = 20\n",
    "res_cells_per_group = 2\n",
    "n_groups_per_scale = [5, 5]\n",
    "n_latent_scales = len(n_groups_per_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9ed777-f168-4cbd-ab34-c6b987f897b3",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa8cccd-d7df-4d44-af99-fe01b6441762",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipScaler(tf.keras.Model):\n",
    "    def __init__(self, n_channels, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.n_channels = n_channels\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        batch_size, h, w, c = input_shape\n",
    "        \n",
    "        # Each convolution handles a quarter of the channels\n",
    "        self.act_layer = layers.Activation(activations.swish, input_shape=(h, w, c))\n",
    "        self.conv1 = SpectralNormalization(layers.Conv2D(self.n_channels // 4, (1, 1), strides=(2, 2), padding=\"same\"))\n",
    "        self.conv2 = SpectralNormalization(layers.Conv2D(self.n_channels // 4, (1, 1), strides=(2, 2), padding=\"same\"))\n",
    "        self.conv3 = SpectralNormalization(layers.Conv2D(self.n_channels // 4, (1, 1), strides=(2, 2), padding=\"same\"))\n",
    "        \n",
    "        # This convolotuion handles the remaining channels\n",
    "        self.conv4 = SpectralNormalization(layers.Conv2D(self.n_channels - 3 * (self.n_channels // 4), (1, 1), strides=(2, 2), padding=\"same\"))\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.act_layer(x)\n",
    "        # Indexes are offset as we stride by 2x2, this way we cover all pixels\n",
    "        conv1 = self.conv1(out)\n",
    "        conv2 = self.conv2(out[:, 1:, 1:, :])\n",
    "        conv3 = self.conv3(out[:, :, 1:, :])\n",
    "        conv4 = self.conv4(out[:, 1:, :, :])\n",
    "        \n",
    "        # Combine channels\n",
    "        out = tf.concat((conv1, conv2, conv3, conv4), axis=3)\n",
    "        return out\n",
    "\n",
    "\n",
    "class BNSwishConv(tf.keras.Model):\n",
    "    def __init__(self, n_nodes, n_channels, stride, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.n_nodes = n_nodes\n",
    "        self.n_channels = n_channels\n",
    "        self.stride = stride\n",
    "        self.se = SqueezeExcitation()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        batch_size, h, w, c = input_shape\n",
    "        \n",
    "        self.nodes = Sequential()\n",
    "        self.nodes.add(layers.Input(shape=(h, w, c)))\n",
    "        \n",
    "        if self.stride == (1, 1):\n",
    "            self.skip = tf.identity\n",
    "        elif self.stride == (2, 2):\n",
    "            # We have to rescale the input in order to combine it\n",
    "            self.skip = SkipScaler(self.n_channels)\n",
    "        \n",
    "        for i in range(self.n_nodes):\n",
    "            self.nodes.add(layers.BatchNormalization(momentum=0.05, epsilon=1e-5))\n",
    "            self.nodes.add(layers.Activation(activations.swish))\n",
    "            \n",
    "            # Only apply rescaling on first node\n",
    "            self.nodes.add(SpectralNormalization(layers.Conv2D(self.n_channels, (3, 3), self.stride if i == 0 else (1, 1), padding=\"same\")))\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        skipped = self.skip(inputs)\n",
    "        x = self.nodes(inputs)\n",
    "        x = self.se(x)\n",
    "        return skipped + 0.1 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7864b50-f75b-464f-bca0-698c8a231672",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f0363df-65da-4f9f-b217-969520134753",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodingResidualCell(tf.keras.Model):\n",
    "    \"\"\"Encoding network residual cell in NVAE architecture\"\"\"\n",
    "    def __init__(self, output_channels, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.output_channels = output_channels\n",
    "        self.se = SqueezeExcitation()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        batch_size, h, w, c = input_shape\n",
    "        \n",
    "        self.act_layers = layers.Activation(activations.swish, input_shape=(h, w, c))\n",
    "        self.batch_norm1 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "        self.conv1 = SpectralNormalization(layers.Conv2D(self.output_channels, (3, 3), padding=\"same\"))\n",
    "        self.batch_norm2 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "        self.conv2 = SpectralNormalization(layers.Conv2D(self.output_channels, (3, 3), padding=\"same\"))\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.act_layers(inputs)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = activations.swish(self.batch_norm2(x))\n",
    "        x = self.conv2(x)\n",
    "        x = self.se(x)\n",
    "        return 0.1 * inputs + x\n",
    "    \n",
    "\n",
    "class EncoderDecoderCombiner(tf.keras.Model):\n",
    "    def __init__(self, n_channels, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.n_channels = n_channels\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        batch_size, h, w, c = input_shape\n",
    "        self.decoder_conv = SpectralNormalization(layers.Conv2D(self.n_channels, (1, 1), input_shape=(h, w, c)))\n",
    "\n",
    "    def call(self, encoder_x, decoder_x):\n",
    "        x = self.decoder_conv(decoder_x)\n",
    "        return encoder_x + x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56908364-c119-48b0-8897-88d56049395a",
   "metadata": {},
   "source": [
    "# Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0dc3d7e-d0e5-4e5f-b10f-8a9e286d368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    def call(self, z_mean, z_log_var):\n",
    "        epsilon = tf.random.normal(shape=tf.shape(z_mean), dtype=tf.float32)\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class Sampler(tf.keras.Model):\n",
    "    def __init__(self, n_latent_scales, n_groups_per_scale, n_latent_per_group, scale_factor, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # Initialize sampler\n",
    "        self.enc_sampler = []\n",
    "        self.dec_sampler = []\n",
    "        self.n_latent_scales = n_latent_scales\n",
    "        self.n_groups_per_scale = n_groups_per_scale\n",
    "        self.n_latent_per_group = n_latent_per_group\n",
    "        \n",
    "        for scale in range(self.n_latent_scales):\n",
    "            n_groups = self.n_groups_per_scale[scale]\n",
    "            \n",
    "            for group in range(n_groups):\n",
    "                # NVLabs use padding 1 here?\n",
    "                self.enc_sampler.append(SpectralNormalization(layers.Conv2D(2 * self.n_latent_per_group, kernel_size=(3, 3), padding=\"same\")))\n",
    "                \n",
    "                if scale == 0 and group == 0:\n",
    "                    # Dummy value to maintain indexing\n",
    "                    self.dec_sampler.append(None)\n",
    "                else:\n",
    "                    sampler = Sequential()\n",
    "                    sampler.add(layers.ELU())\n",
    "                    \n",
    "                    # NVLabs use padding 0 here?\n",
    "                    sampler.add(SpectralNormalization(layers.Conv2D(2 * self.n_latent_per_group, kernel_size=(1, 1))))\n",
    "                    self.dec_sampler.append(sampler)\n",
    "    \n",
    "    def sample(self, mu, sigma):\n",
    "        # reparametrization trick\n",
    "        return Sampling()(mu, sigma)\n",
    "    \n",
    "    def get_params(self, sampler, z_idx, prior):\n",
    "        params = sampler[z_idx](prior)\n",
    "        mu, log_sigma = tf.split(params, 2, axis=-1)\n",
    "        return mu, log_sigma\n",
    "    \n",
    "    def call(self, prior, z_idx, enc_prior=None):\n",
    "        # Get encoder offsets\n",
    "        if enc_prior is None:\n",
    "            enc_prior = prior\n",
    "        enc_mu_offset, enc_log_sigma_offset = self.get_params(self.enc_sampler, z_idx, enc_prior)\n",
    "        \n",
    "        if z_idx == 0:\n",
    "            # Prior is standard normal distribution\n",
    "            enc_mu = softclamp5(enc_mu_offset)\n",
    "            enc_sigma = tf.math.exp(softclamp5(enc_log_sigma_offset)) + 1e-2\n",
    "            z = self.sample(enc_mu, enc_sigma)\n",
    "            params = [enc_mu, enc_sigma, tf.zeros_like(enc_mu), tf.ones_like(enc_sigma)]\n",
    "            return z, params\n",
    "        \n",
    "        # Get decoder parameters\n",
    "        raw_dec_mu, raw_dec_log_sigma = self.get_params(self.dec_sampler, z_idx, prior)\n",
    "        \n",
    "        dec_mu = softclamp5(raw_dec_mu)\n",
    "        dec_sigma = tf.math.exp(softclamp5(raw_dec_log_sigma)) + 1e-2\n",
    "        \n",
    "        enc_mu = softclamp5(enc_mu_offset + raw_dec_mu)\n",
    "        enc_sigma = (tf.math.exp(softclamp5(raw_dec_log_sigma + enc_log_sigma_offset)) + 1e-2)\n",
    "        \n",
    "        params = [enc_mu, enc_sigma, dec_mu, dec_sigma]\n",
    "        z = self.sample(enc_mu, enc_sigma)\n",
    "        return z, params\n",
    "\n",
    "\n",
    "class RescaleType(Enum):\n",
    "    UP = auto()\n",
    "    DOWN = auto()\n",
    "\n",
    "\n",
    "class SqueezeExcitation(tf.keras.Model):\n",
    "    \"\"\"Squeeze and Excitation block as defined by Hu, et al. (2019)\n",
    "    See Also\n",
    "    ========\n",
    "    Source paper https://arxiv.org/pdf/1709.01507.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, ratio=16, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.ratio = ratio\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        batch_size, h, w, c = input_shape\n",
    "        self.gap = layers.GlobalAveragePooling2D(data_format=\"channels_last\")\n",
    "        num_hidden = max(c / self.ratio, 4)\n",
    "        self.dense1 = layers.Dense(units=num_hidden)\n",
    "        self.dense2 = layers.Dense(units=c)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.gap(inputs)\n",
    "        x = self.dense1(x)\n",
    "        x = activations.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = activations.sigmoid(x)\n",
    "        x = tf.expand_dims(x, 1)\n",
    "        x = tf.expand_dims(x, 2)\n",
    "        return x * inputs\n",
    "\n",
    "\n",
    "class Rescaler(tf.keras.Model):\n",
    "    def __init__(self, n_channels, scale_factor, rescale_type, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.n_channels = n_channels\n",
    "        self.mode = rescale_type\n",
    "        self.factor = scale_factor\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        batch_size, h, w, c = input_shape\n",
    "        \n",
    "        self.bn = layers.BatchNormalization(momentum=0.05, epsilon=1e-5, input_shape=(h, w, c))\n",
    "        \n",
    "        if self.mode == RescaleType.UP:\n",
    "            self.conv = SpectralNormalization(layers.Conv2D(self.n_channels, (3, 3), strides=(1, 1), padding=\"same\"))\n",
    "            \n",
    "        elif self.mode == RescaleType.DOWN:\n",
    "            self.conv = SpectralNormalization(layers.Conv2D(self.n_channels, (3, 3), strides=(self.factor, self.factor), padding=\"same\"))\n",
    "\n",
    "    def call(self, input):\n",
    "        x = self.bn(input)\n",
    "        x = activations.swish(x)\n",
    "        \n",
    "        if self.mode == RescaleType.UP:\n",
    "            _, height, width, _ = x.get_shape()\n",
    "            x = tf.image.resize(x, size=(self.factor * height, self.factor * width), method=\"nearest\")\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276fba98-1b7d-423a-bba7-5f1df76bcf2f",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6223022-6336-4bea-8ebf-a348c8b196de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderSampleCombiner(tf.keras.Model):\n",
    "    def __init__(self, output_channels, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.output_channels = output_channels\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        batch_size, h, w, c = input_shape\n",
    "        self.conv = SpectralNormalization(layers.Conv2D(self.output_channels, (1, 1), strides=(1, 1), padding=\"same\", input_shape=(h, w, c)))\n",
    "    \n",
    "    def call(self, x, z):\n",
    "        output = tf.concat([x, z], axis=3)\n",
    "        output = self.conv(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class GenerativeResidualCell(tf.keras.Model):\n",
    "    \"\"\"Generative network residual cell in NVAE architecture\"\"\"\n",
    "    def __init__(self, output_channels, expansion_ratio=6, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.expansion_ratio = expansion_ratio\n",
    "        self.output_channels = output_channels\n",
    "        self.se = SqueezeExcitation()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        batch_size, h, w, c = input_shape\n",
    "        self.batch_norm1 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5, input_shape=(h, w, c))\n",
    "        self.conv1 = SpectralNormalization(layers.Conv2D(self.expansion_ratio * self.output_channels, (1, 1), padding=\"same\"))\n",
    "        self.batch_norm2 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "        self.depth_conv = layers.DepthwiseConv2D((5, 5), padding=\"same\")\n",
    "        self.batch_norm3 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "        self.conv2 = SpectralNormalization(layers.Conv2D(self.output_channels, (1, 1), padding=\"same\"))\n",
    "        self.batch_norm4 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.batch_norm1(inputs)\n",
    "        x = self.conv1(x)\n",
    "        x = activations.swish(self.batch_norm2(x))\n",
    "        x = self.depth_conv(x)\n",
    "        x = activations.swish(self.batch_norm3(x))\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.se(x)\n",
    "        return 0.1 * inputs + x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3e962e-4f77-4ca0-9076-439f6006fc5a",
   "metadata": {},
   "source": [
    "# Post process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57717d60-b445-4f43-9d27-dbcbd8da4e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostprocessCell(tf.keras.Model):\n",
    "    def __init__(self, n_channels, n_nodes, scale_factor, upscale=False, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.n_channels = n_channels\n",
    "        self.n_nodes = n_nodes\n",
    "        self.scale_factor = scale_factor\n",
    "        self.upscale = upscale\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        batch_size, h, w, c = input_shape\n",
    "        \n",
    "        self.sequence = Sequential()\n",
    "        self.sequence.add(layers.Input(shape=(h, w, c)))\n",
    "        \n",
    "        if self.upscale:\n",
    "            self.skip = Rescaler(self.n_channels, scale_factor=self.scale_factor, rescale_type=RescaleType.UP)\n",
    "        else:\n",
    "            self.skip = tf.identity\n",
    "            \n",
    "        for _ in range(self.n_nodes):\n",
    "            self.sequence.add(PostprocessNode(self.n_channels, upscale=self.upscale, scale_factor=self.scale_factor))\n",
    "            \n",
    "            if self.upscale:\n",
    "                # Only scale once in each cells\n",
    "                self.upscale = False\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.skip(inputs) + 0.1 * self.sequence(inputs)\n",
    "\n",
    "class PostprocessNode(tf.keras.Model):\n",
    "    def __init__(self, n_channels, scale_factor, upscale=False, expansion_ratio=6, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.n_channels = n_channels\n",
    "        self.expansion_ratio = expansion_ratio\n",
    "        self.scale_factor = scale_factor\n",
    "        self.upscale = upscale\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        batch_size, h, w, c = input_shape\n",
    "        \n",
    "        self.sequence = Sequential()\n",
    "        self.sequence.add(layers.Input(shape=(h, w, c)))\n",
    "        \n",
    "        if self.upscale:\n",
    "            self.sequence.add(Rescaler(self.n_channels, self.scale_factor, rescale_type=RescaleType.UP))\n",
    "            \n",
    "        self.sequence.add(layers.BatchNormalization(momentum=0.05, epsilon=1e-5))\n",
    "        hidden_dim = self.n_channels * self.expansion_ratio\n",
    "        self.sequence.add(ConvBNSwish(hidden_dim, kernel_size=(1, 1), stride=(1, 1)))\n",
    "        self.sequence.add(ConvBNSwish(hidden_dim, kernel_size=(5, 5), stride=(1, 1)))\n",
    "        self.sequence.add(SpectralNormalization(layers.Conv2D(self.n_channels, kernel_size=(1, 1), strides=(1, 1), use_bias=False)))\n",
    "        self.sequence.add(layers.BatchNormalization(momentum=0.05, epsilon=1e-5))\n",
    "        self.sequence.add(SqueezeExcitation())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.sequence(inputs)\n",
    "\n",
    "\n",
    "class ConvBNSwish(tf.keras.Model):\n",
    "    def __init__(self, n_channels, kernel_size, stride, groups=1, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.n_channels = n_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        batch_size, h, w, c = input_shape\n",
    "        self.sequence = Sequential()\n",
    "        self.sequence.add(SpectralNormalization(layers.Conv2D(self.n_channels, kernel_size=self.kernel_size, strides=self.stride, use_bias=False, \n",
    "                                                              padding=\"same\", input_shape=(h, w, c))))\n",
    "        self.sequence.add(layers.BatchNormalization(momentum=0.05, epsilon=1e-5))\n",
    "        self.sequence.add(layers.Activation(activations.swish))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.sequence(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b507f1b-d36d-4c1b-a4ab-44de1b577dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(image_shape, n_encoder_channels, n_decoder_channels, n_preprocess_blocks, n_preprocess_cells, n_postprocess_blocks, n_postprocess_cells,\n",
    "                 n_latent_per_group, n_latent_scales, n_groups_per_scale, res_cells_per_group, scale_factor, mult=1, nll=False, dataset_option='coco'):\n",
    "    \n",
    "    # input is expected to be in [-1, 1] range\n",
    "    in_put = layers.Input(shape=image_shape, name='image')\n",
    "    x = SpectralNormalization(layers.Conv2D(n_encoder_channels, (3, 3), padding=\"same\"))(in_put)\n",
    "    \n",
    "    for block in range(n_preprocess_blocks):\n",
    "        for cell in range(n_preprocess_cells - 1):\n",
    "            n_channels = mult * n_encoder_channels\n",
    "            x = BNSwishConv(2, n_channels, stride=(1, 1))(x)\n",
    "        \n",
    "        # Rescale channels on final cell\n",
    "        n_channels = mult * n_encoder_channels * scale_factor\n",
    "        x = BNSwishConv(2, n_channels, stride=(2, 2))(x)\n",
    "        mult *= scale_factor\n",
    "    \n",
    "    ###############################################################################################################\n",
    "    \n",
    "    enc_layers = []\n",
    "    for scale in range(n_latent_scales):\n",
    "        n_groups = n_groups_per_scale[scale]\n",
    "        print('\\nGroup: ', scale)\n",
    "\n",
    "        for group_idx in range(n_groups):\n",
    "            output_channels = n_encoder_channels * mult\n",
    "            print('Output_channels: ', output_channels)\n",
    "            \n",
    "            for rb in range(res_cells_per_group):\n",
    "                enc_layers.append(EncodingResidualCell(output_channels, name='res_block_' + str(scale) + '_' + str(group_idx) + '_' + str(rb)))\n",
    "                print('res block')\n",
    "\n",
    "            if not (scale == n_latent_scales - 1 and group_idx == n_groups - 1):\n",
    "                print('combiner')\n",
    "                enc_layers.append(EncoderDecoderCombiner(output_channels))\n",
    "        \n",
    "        # We downsample in the end of each scale except last\n",
    "        if scale < n_latent_scales - 1:\n",
    "            output_channels = n_encoder_channels * mult * scale_factor\n",
    "            enc_layers.append(Rescaler(output_channels, scale_factor=scale_factor, rescale_type=RescaleType.DOWN))\n",
    "            print('Rescaler')\n",
    "            print('New output_channels: ', output_channels)\n",
    "            mult *= scale_factor\n",
    "    \n",
    "    enc_layers.append(layers.ELU())\n",
    "    enc_layers.append(SpectralNormalization(layers.Conv2D(n_encoder_channels * mult, (1, 1), padding=\"same\")))\n",
    "    enc_layers.append(layers.ELU())\n",
    "    \n",
    "    # Encoder\n",
    "    x = enc_layers[0](x)\n",
    "    enc_dec_combiners = []\n",
    "    for group in enc_layers[1:]:\n",
    "        if isinstance(group, EncoderDecoderCombiner):\n",
    "            # We are stepping between groups, need to save results\n",
    "            enc_dec_combiners.append(partial(group, x))\n",
    "        else:\n",
    "            x = group(x)\n",
    "    enc_dec_combiners.reverse()\n",
    "    en_out_shape = x.shape[1:]\n",
    "    \n",
    "    ###############################################################################################################\n",
    "    \n",
    "    dec_layers = []\n",
    "    for scale in range(n_latent_scales):\n",
    "        print('\\nGroup: ', scale)\n",
    "        n_groups = n_groups_per_scale[scale]\n",
    "\n",
    "        for group in range(n_groups):\n",
    "            output_channels = int(n_decoder_channels * mult)\n",
    "            print('Output channels', output_channels)\n",
    "\n",
    "            if not (scale == 0 and group == 0):\n",
    "                for res in range(res_cells_per_group):\n",
    "                    dec_layers.append(GenerativeResidualCell(output_channels))\n",
    "                    print('Gen Res block', flush=True)\n",
    "\n",
    "            dec_layers.append(DecoderSampleCombiner(output_channels))\n",
    "            print('Decoder Combiner', flush=True)\n",
    "\n",
    "        if scale < n_latent_scales - 1:\n",
    "            output_channels = int(n_decoder_channels * mult / scale_factor)\n",
    "\n",
    "            dec_layers.append(Rescaler(output_channels, scale_factor=scale_factor, rescale_type=RescaleType.UP))\n",
    "            print('Rescaler', flush=True)\n",
    "\n",
    "            mult /= scale_factor\n",
    "    \n",
    "    #######################################################################################################################\n",
    "    \n",
    "    # call latent sapce sampler class\n",
    "    sampler = Sampler(n_latent_scales=n_latent_scales, \n",
    "                      n_groups_per_scale=n_groups_per_scale, \n",
    "                      n_latent_per_group=n_latent_per_group, \n",
    "                      scale_factor=scale_factor)\n",
    "    \n",
    "    z_params = []\n",
    "    \n",
    "    if nll:\n",
    "        all_log_p = []\n",
    "        all_log_q = []\n",
    "    \n",
    "    z0, params = sampler(x, z_idx=0)\n",
    "    z_params.append(params)\n",
    "    \n",
    "    if nll:\n",
    "        all_log_q.append(calculate_log_p(z0, params.enc_mu, params.enc_sigma))\n",
    "        all_log_p.append(calculate_log_p(z0, params.dec_mu, params.dec_sigma))\n",
    "    \n",
    "    z0_shape = tf.convert_to_tensor([en_out_shape[0], en_out_shape[1], n_latent_per_group], dtype=tf.int32)\n",
    "    \n",
    "    h_var = tf.Variable(tf.random.uniform([en_out_shape[0], en_out_shape[1], n_decoder_channels], minval=0, maxval=1), trainable=True)\n",
    "    h = tf.expand_dims(h_var, 0)\n",
    "    h = tf.tile(h, [tf.shape(z0)[0], 1, 1, 1])\n",
    "    \n",
    "    x = dec_layers[0](h, z0)\n",
    "    \n",
    "    combine_idx = 0\n",
    "    for group in dec_layers[1:]:\n",
    "        if isinstance(group, DecoderSampleCombiner):\n",
    "            enc_prior = enc_dec_combiners[combine_idx](x)\n",
    "            z_sample, params = sampler(x, z_idx=combine_idx + 1, enc_prior=enc_prior)\n",
    "            \n",
    "            if nll:\n",
    "                all_log_q.append(calculate_log_p(z_sample, params.enc_mu, params.enc_sigma))\n",
    "                all_log_p.append(calculate_log_p(z_sample, params.dec_mu, params.dec_sigma))\n",
    "            \n",
    "            z_params.append(params)\n",
    "            x = group(x, z_sample)\n",
    "            combine_idx += 1\n",
    "        else:\n",
    "            x = group(x)\n",
    "    \n",
    "    if nll:\n",
    "        log_p = tf.zeros((tf.shape(x)[0]))\n",
    "        log_q = tf.zeros((tf.shape(x)[0]))\n",
    "        \n",
    "        for p, q in zip(all_log_p, all_log_q):\n",
    "            log_p += tf.reduce_sum(p, axis=[1, 2, 3])\n",
    "            log_q += tf.reduce_sum(q, axis=[1, 2, 3])\n",
    "        \n",
    "    #####################################################################################################\n",
    "    \n",
    "    print('\\nPost-process')\n",
    "    sequence = []\n",
    "    for block in range(n_postprocess_blocks):\n",
    "        # First cell rescales\n",
    "        mult /= scale_factor\n",
    "        output_channels = n_decoder_channels * mult\n",
    "\n",
    "        for cell_idx in range(n_postprocess_cells):\n",
    "            print('add post process cell')\n",
    "            sequence.append(PostprocessCell(output_channels, n_nodes=1, upscale=cell_idx == 0, scale_factor=scale_factor))\n",
    "\n",
    "    sequence.append(layers.Activation(activations.elu))\n",
    "    if dataset_option == 'mnist':\n",
    "        sequence.append(SpectralNormalization(layers.Conv2D(1, kernel_size=(3, 3), padding=\"same\")))\n",
    "    else:\n",
    "        sequence.append(SpectralNormalization(layers.Conv2D(100, kernel_size=(3, 3), padding=\"same\"))) # 10 logistic distributions\n",
    "    print('add elu-conv')\n",
    "    \n",
    "    #####################################################################################################\n",
    "    \n",
    "    # input_shapes and mult output comes from decoder output\n",
    "    x = sequence[0](x)\n",
    "    \n",
    "    for layer in sequence[1:]:\n",
    "        x = layer(x)\n",
    "        \n",
    "    if nll:\n",
    "        model = tf.keras.models.Model(in_put, [x, z_params, log_p, log_q], name='decoder')\n",
    "        model.summary()\n",
    "    else:\n",
    "        model = tf.keras.models.Model(in_put, [x, z_params], name='decoder')\n",
    "        model.summary()\n",
    "    \n",
    "    return model, z0_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d6cccdd-5b5d-4db9-a1d9-08ffb9fceae5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group:  0\n",
      "Output_channels:  64\n",
      "res block\n",
      "res block\n",
      "combiner\n",
      "Output_channels:  64\n",
      "res block\n",
      "res block\n",
      "combiner\n",
      "Output_channels:  64\n",
      "res block\n",
      "res block\n",
      "combiner\n",
      "Output_channels:  64\n",
      "res block\n",
      "res block\n",
      "combiner\n",
      "Output_channels:  64\n",
      "res block\n",
      "res block\n",
      "combiner\n",
      "Rescaler\n",
      "New output_channels:  128\n",
      "\n",
      "Group:  1\n",
      "Output_channels:  128\n",
      "res block\n",
      "res block\n",
      "combiner\n",
      "Output_channels:  128\n",
      "res block\n",
      "res block\n",
      "combiner\n",
      "Output_channels:  128\n",
      "res block\n",
      "res block\n",
      "combiner\n",
      "Output_channels:  128\n",
      "res block\n",
      "res block\n",
      "combiner\n",
      "Output_channels:  128\n",
      "res block\n",
      "res block\n",
      "\n",
      "Group:  0\n",
      "Output channels 128\n",
      "Decoder Combiner\n",
      "Output channels 128\n",
      "Gen Res block\n",
      "Gen Res block\n",
      "Decoder Combiner\n",
      "Output channels 128\n",
      "Gen Res block\n",
      "Gen Res block\n",
      "Decoder Combiner\n",
      "Output channels 128\n",
      "Gen Res block\n",
      "Gen Res block\n",
      "Decoder Combiner\n",
      "Output channels 128\n",
      "Gen Res block\n",
      "Gen Res block\n",
      "Decoder Combiner\n",
      "Rescaler\n",
      "\n",
      "Group:  1\n",
      "Output channels 64\n",
      "Gen Res block\n",
      "Gen Res block\n",
      "Decoder Combiner\n",
      "Output channels 64\n",
      "Gen Res block\n",
      "Gen Res block\n",
      "Decoder Combiner\n",
      "Output channels 64\n",
      "Gen Res block\n",
      "Gen Res block\n",
      "Decoder Combiner\n",
      "Output channels 64\n",
      "Gen Res block\n",
      "Gen Res block\n",
      "Decoder Combiner\n",
      "Output channels 64\n",
      "Gen Res block\n",
      "Gen Res block\n",
      "Decoder Combiner\n",
      "\n",
      "Post-process\n",
      "add post process cell\n",
      "add post process cell\n",
      "add post process cell\n",
      "add post process cell\n",
      "add post process cell\n",
      "add post process cell\n",
      "add elu-conv\n",
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image (InputLayer)              [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spectral_normalization (Spectra (None, 128, 128, 16) 464         image[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn_swish_conv (BNSwishConv)     (None, 128, 128, 16) 4948        spectral_normalization[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "bn_swish_conv_1 (BNSwishConv)   (None, 128, 128, 16) 4948        bn_swish_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn_swish_conv_2 (BNSwishConv)   (None, 64, 64, 32)   15012       bn_swish_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn_swish_conv_3 (BNSwishConv)   (None, 64, 64, 32)   19108       bn_swish_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn_swish_conv_4 (BNSwishConv)   (None, 64, 64, 32)   19108       bn_swish_conv_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn_swish_conv_5 (BNSwishConv)   (None, 32, 32, 64)   58692       bn_swish_conv_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_0_0_0 (EncodingResidu (None, 32, 32, 64)   75076       bn_swish_conv_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_0_0_1 (EncodingResidu (None, 32, 32, 64)   75076       res_block_0_0_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_0_1_0 (EncodingResidu (None, 32, 32, 64)   75076       res_block_0_0_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_0_1_1 (EncodingResidu (None, 32, 32, 64)   75076       res_block_0_1_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_0_2_0 (EncodingResidu (None, 32, 32, 64)   75076       res_block_0_1_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_0_2_1 (EncodingResidu (None, 32, 32, 64)   75076       res_block_0_2_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_0_3_0 (EncodingResidu (None, 32, 32, 64)   75076       res_block_0_2_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_0_3_1 (EncodingResidu (None, 32, 32, 64)   75076       res_block_0_3_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_0_4_0 (EncodingResidu (None, 32, 32, 64)   75076       res_block_0_3_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_0_4_1 (EncodingResidu (None, 32, 32, 64)   75076       res_block_0_4_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "rescaler (Rescaler)             (None, 16, 16, 128)  74240       res_block_0_4_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_1_0_0 (EncodingResidu (None, 16, 16, 128)  298632      rescaler[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res_block_1_0_1 (EncodingResidu (None, 16, 16, 128)  298632      res_block_1_0_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_1_1_0 (EncodingResidu (None, 16, 16, 128)  298632      res_block_1_0_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_1_1_1 (EncodingResidu (None, 16, 16, 128)  298632      res_block_1_1_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_1_2_0 (EncodingResidu (None, 16, 16, 128)  298632      res_block_1_1_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_1_2_1 (EncodingResidu (None, 16, 16, 128)  298632      res_block_1_2_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_1_3_0 (EncodingResidu (None, 16, 16, 128)  298632      res_block_1_2_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_1_3_1 (EncodingResidu (None, 16, 16, 128)  298632      res_block_1_3_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_1_4_0 (EncodingResidu (None, 16, 16, 128)  298632      res_block_1_3_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res_block_1_4_1 (EncodingResidu (None, 16, 16, 128)  298632      res_block_1_4_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "elu (ELU)                       (None, 16, 16, 128)  0           res_block_1_4_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spectral_normalization_1 (Spect (None, 16, 16, 128)  16640       elu[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "elu_1 (ELU)                     (None, 16, 16, 128)  0           spectral_normalization_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "sampler (Sampler)               multiple             380400      elu_1[0][0]                      \n",
      "                                                                 generative_residual_cell_1[0][0] \n",
      "                                                                 generative_residual_cell_3[0][0] \n",
      "                                                                 generative_residual_cell_5[0][0] \n",
      "                                                                 generative_residual_cell_7[0][0] \n",
      "                                                                 generative_residual_cell_9[0][0] \n",
      "                                                                 generative_residual_cell_11[0][0]\n",
      "                                                                 generative_residual_cell_13[0][0]\n",
      "                                                                 generative_residual_cell_15[0][0]\n",
      "                                                                 generative_residual_cell_17[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(4,)]               0           sampler[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile/multiples (Ten [(4,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tile (TensorFlowOpL [(None, 16, 16, 16)] 0           tf_op_layer_Tile/multiples[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_sample_combiner (Decode (None, 16, 16, 128)  4864        tf_op_layer_Tile[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell (Gener (None, 16, 16, 128)  227720      decoder_sample_combiner[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_1 (Gen (None, 16, 16, 128)  227720      generative_residual_cell[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_decoder_combiner_8 (Enc (None, 16, 16, 128)  16640       res_block_1_3_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_sample_combiner_1 (Deco (None, 16, 16, 128)  19200       generative_residual_cell_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_2 (Gen (None, 16, 16, 128)  227720      decoder_sample_combiner_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_3 (Gen (None, 16, 16, 128)  227720      generative_residual_cell_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "encoder_decoder_combiner_7 (Enc (None, 16, 16, 128)  16640       res_block_1_2_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_sample_combiner_2 (Deco (None, 16, 16, 128)  19200       generative_residual_cell_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_4 (Gen (None, 16, 16, 128)  227720      decoder_sample_combiner_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_5 (Gen (None, 16, 16, 128)  227720      generative_residual_cell_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "encoder_decoder_combiner_6 (Enc (None, 16, 16, 128)  16640       res_block_1_1_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_sample_combiner_3 (Deco (None, 16, 16, 128)  19200       generative_residual_cell_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_6 (Gen (None, 16, 16, 128)  227720      decoder_sample_combiner_3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_7 (Gen (None, 16, 16, 128)  227720      generative_residual_cell_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "encoder_decoder_combiner_5 (Enc (None, 16, 16, 128)  16640       res_block_1_0_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_sample_combiner_4 (Deco (None, 16, 16, 128)  19200       generative_residual_cell_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "rescaler_1 (Rescaler)           (None, 32, 32, 64)   74368       decoder_sample_combiner_4[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_8 (Gen (None, 32, 32, 64)   64196       rescaler_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_9 (Gen (None, 32, 32, 64)   64196       generative_residual_cell_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "encoder_decoder_combiner_4 (Enc (None, 32, 32, 64)   4224        res_block_0_4_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_sample_combiner_5 (Deco (None, 32, 32, 64)   5504        generative_residual_cell_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_10 (Ge (None, 32, 32, 64)   64196       decoder_sample_combiner_5[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_11 (Ge (None, 32, 32, 64)   64196       generative_residual_cell_10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "encoder_decoder_combiner_3 (Enc (None, 32, 32, 64)   4224        res_block_0_3_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_sample_combiner_6 (Deco (None, 32, 32, 64)   5504        generative_residual_cell_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_12 (Ge (None, 32, 32, 64)   64196       decoder_sample_combiner_6[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_13 (Ge (None, 32, 32, 64)   64196       generative_residual_cell_12[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "encoder_decoder_combiner_2 (Enc (None, 32, 32, 64)   4224        res_block_0_2_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_sample_combiner_7 (Deco (None, 32, 32, 64)   5504        generative_residual_cell_13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_14 (Ge (None, 32, 32, 64)   64196       decoder_sample_combiner_7[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_15 (Ge (None, 32, 32, 64)   64196       generative_residual_cell_14[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "encoder_decoder_combiner_1 (Enc (None, 32, 32, 64)   4224        res_block_0_1_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_sample_combiner_8 (Deco (None, 32, 32, 64)   5504        generative_residual_cell_15[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_16 (Ge (None, 32, 32, 64)   64196       decoder_sample_combiner_8[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "generative_residual_cell_17 (Ge (None, 32, 32, 64)   64196       generative_residual_cell_16[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "encoder_decoder_combiner (Encod (None, 32, 32, 64)   4224        res_block_0_0_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_sample_combiner_9 (Deco (None, 32, 32, 64)   5504        generative_residual_cell_17[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "postprocess_cell (PostprocessCe (None, 64, 64, 32)   973892      decoder_sample_combiner_9[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "postprocess_cell_1 (Postprocess (None, 64, 64, 32)   936388      postprocess_cell[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "postprocess_cell_2 (Postprocess (None, 64, 64, 32)   936388      postprocess_cell_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "postprocess_cell_3 (Postprocess (None, 128, 128, 16) 244260      postprocess_cell_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "postprocess_cell_4 (Postprocess (None, 128, 128, 16) 234724      postprocess_cell_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "postprocess_cell_5 (Postprocess (None, 128, 128, 16) 234724      postprocess_cell_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 128, 128, 16) 0           postprocess_cell_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "spectral_normalization_21 (Spec (None, 128, 128, 100 14600       activation[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 10,640,568\n",
      "Trainable params: 10,559,900\n",
      "Non-trainable params: 80,668\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_nvae = create_model(image_shape, n_encoder_channels, n_decoder_channels, n_preprocess_blocks, n_preprocess_cells, n_postprocess_blocks, n_postprocess_cells,\n",
    "                 n_latent_per_group, n_latent_scales, n_groups_per_scale, res_cells_per_group, scale_factor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
