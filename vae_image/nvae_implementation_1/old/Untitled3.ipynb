{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04812543-e240-4b9c-9947-a2fce7b55b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from functools import partial\n",
    "from util import calculate_log_p\n",
    "from common import RescaleType, Rescaler, SqueezeExcitation, Sampler\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import activations, Sequential, layers\n",
    "from tensorflow_addons.layers import SpectralNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f831aa4e-a2d4-4f9a-abe6-ad9b4cd76a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_encoder_channels = 16\n",
    "image_shape = np.array([128.0, 128.0, float(n_encoder_channels)])\n",
    "\n",
    "n_decoder_channels = 16\n",
    "\n",
    "n_preprocess_blocks = 2\n",
    "n_preprocess_cells = 3\n",
    "\n",
    "n_postprocess_blocks = 2\n",
    "n_postprocess_cells = 3\n",
    "\n",
    "mult = 1\n",
    "scale_factor = 2\n",
    "\n",
    "n_latent_per_group = 20\n",
    "res_cells_per_group = 2\n",
    "n_groups_per_scale = [2, 2]\n",
    "n_latent_scales = len(n_groups_per_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9212be84-bab2-466c-a22a-d182aedacd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape [64. 64. 32.]\n",
      "image shape [32. 32. 64.]\n",
      "Model: \"preprocess\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (None, 32, 32, 64)        122280    \n",
      "=================================================================\n",
      "Total params: 122,280\n",
      "Trainable params: 121,112\n",
      "Non-trainable params: 1,168\n",
      "_________________________________________________________________\n",
      "4\n",
      "outshape [32. 32. 64.]\n",
      "outshape (32.0, 32.0, 64.0)\n",
      "(10, 32, 32, 64)\n",
      "4\n",
      "outshape [32. 32. 64.]\n",
      "outshape (32.0, 32.0, 64.0)\n",
      "(1, 32, 32, 64)\n"
     ]
    }
   ],
   "source": [
    "class Preprocess(tf.keras.Model):\n",
    "    def __init__(self, n_encoder_channels, n_preprocess_blocks, n_preprocess_cells, scale_factor, image_shape, mult=1, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        in_shape = (int(image_shape[0]), int(image_shape[1]), 3)\n",
    "        self.pre_process = Sequential()\n",
    "        self.pre_process.add(layers.Input(shape=in_shape))\n",
    "        self.pre_process.add(SpectralNormalization(layers.Conv2D(n_encoder_channels, (3, 3), padding=\"same\")))\n",
    "        \n",
    "        for block in range(n_preprocess_blocks):\n",
    "            for cell in range(n_preprocess_cells - 1):\n",
    "                n_channels = mult * n_encoder_channels\n",
    "                self.pre_process.add(BNSwishConv(2, n_channels, stride=(1, 1)))\n",
    "                \n",
    "            # Rescale channels on final cell\n",
    "            n_channels = mult * n_encoder_channels * scale_factor\n",
    "            \n",
    "            self.pre_process.add(BNSwishConv(2, n_channels, stride=(2, 2)))\n",
    "            \n",
    "            mult *= scale_factor\n",
    "            image_shape *= np.array([1 / scale_factor, 1 / scale_factor, scale_factor])\n",
    "            print('image shape', image_shape, flush=True)\n",
    "            \n",
    "        self.mult = mult\n",
    "        self.output_shape_next = image_shape\n",
    "        self.output_shape_tup = tuple(image_shape.reshape(1, -1)[0])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # 2 * inputs - 1 in order to convert [0,1] range to [-1,1]\n",
    "        return self.pre_process(2 * inputs - 1)\n",
    "\n",
    "\n",
    "class SkipScaler(tf.keras.Model):\n",
    "    def __init__(self, n_channels, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.n_channels = n_channels\n",
    "       \n",
    "    def build(self, input_shape):\n",
    "        batch_size, h, w, c = input_shape\n",
    "        \n",
    "        # Each convolution handles a quarter of the channels\n",
    "        self.conv1 = SpectralNormalization(layers.Conv2D(self.n_channels // 4, (1, 1), strides=(2, 2), padding=\"same\", input_shape=(h, w, c)))\n",
    "        self.conv2 = SpectralNormalization(layers.Conv2D(self.n_channels // 4, (1, 1), strides=(2, 2), padding=\"same\"))\n",
    "        self.conv3 = SpectralNormalization(layers.Conv2D(self.n_channels // 4, (1, 1), strides=(2, 2), padding=\"same\"))\n",
    "        \n",
    "        # This convolotuion handles the remaining channels\n",
    "        self.conv4 = SpectralNormalization(layers.Conv2D(self.n_channels - 3 * (self.n_channels // 4), (1, 1), strides=(2, 2), padding=\"same\"))\n",
    "\n",
    "    def call(self, x):\n",
    "        out = activations.swish(x)\n",
    "        # Indexes are offset as we stride by 2x2, this way we cover all pixels\n",
    "        conv1 = self.conv1(out)\n",
    "        conv2 = self.conv2(out[:, 1:, 1:, :])\n",
    "        conv3 = self.conv3(out[:, :, 1:, :])\n",
    "        conv4 = self.conv4(out[:, 1:, :, :])\n",
    "        \n",
    "        # Combine channels\n",
    "        out = tf.concat((conv1, conv2, conv3, conv4), axis=3)\n",
    "        return out\n",
    "\n",
    "\n",
    "class BNSwishConv(tf.keras.Model):\n",
    "    def __init__(self, n_nodes, n_channels, stride, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.nodes = Sequential()\n",
    "        \n",
    "        if stride == (1, 1):\n",
    "            self.skip = tf.identity\n",
    "        elif stride == (2, 2):\n",
    "            # We have to rescale the input in order to combine it\n",
    "            self.skip = SkipScaler(n_channels)\n",
    "        \n",
    "        for i in range(n_nodes):\n",
    "            self.nodes.add(layers.BatchNormalization(momentum=0.05, epsilon=1e-5))\n",
    "            self.nodes.add(layers.Activation(activations.swish))\n",
    "\n",
    "            # Only apply rescaling on first node\n",
    "            self.nodes.add(SpectralNormalization(layers.Conv2D(n_channels, (3, 3), stride if i == 0 else (1, 1), padding=\"same\")))\n",
    "            \n",
    "        self.se = SqueezeExcitation()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        skipped = self.skip(inputs)\n",
    "        x = self.nodes(inputs)\n",
    "        x = self.se(x)\n",
    "        return skipped + 0.1 * x\n",
    "    \n",
    "\n",
    "model_preprocess = Preprocess(n_encoder_channels, n_preprocess_blocks, n_preprocess_cells, scale_factor, image_shape)\n",
    "model_preprocess.build(input_shape=(None, 128, 128, 3))\n",
    "model_preprocess.summary()\n",
    "\n",
    "for i in range(2):\n",
    "    if i == 0:\n",
    "        x = tf.random.normal([10, 128, 128, 3])\n",
    "    else:\n",
    "        x = tf.random.normal([1, 128, 128, 3])\n",
    "    y = model_preprocess(x)\n",
    "\n",
    "    print(model_preprocess.mult)\n",
    "    print('outshape', model_preprocess.output_shape_next)\n",
    "    print('outshape', model_preprocess.output_shape_tup)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5b81d01-eb5d-4731-a08a-117dce18dda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "(16, 16, 128)\n",
      "(10, 16, 16, 128)\n",
      "8\n",
      "(16, 16, 128)\n",
      "(1, 16, 16, 128)\n"
     ]
    }
   ],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "        n_encoder_channels,\n",
    "        res_cells_per_group,\n",
    "        n_latent_scales: int,\n",
    "        n_groups_per_scale: List[int],\n",
    "        mult: int,\n",
    "        scale_factor: int,\n",
    "        input_shape,\n",
    "        **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # Initialize encoder tower\n",
    "        self.groups = []\n",
    "        for scale in range(n_latent_scales):\n",
    "            n_groups = n_groups_per_scale[scale]\n",
    "            \n",
    "            for group_idx in range(n_groups):\n",
    "                output_channels = n_encoder_channels * mult\n",
    "                \n",
    "                group = Sequential()\n",
    "                for _ in range(res_cells_per_group):\n",
    "                    group.add(EncodingResidualCell(output_channels))\n",
    "                self.groups.append(group)\n",
    "                \n",
    "                if not (scale == n_latent_scales - 1 and group_idx == n_groups - 1):\n",
    "                    # We apply a convolutional between each group except the final output\n",
    "                    self.groups.append(EncoderDecoderCombiner(output_channels))\n",
    "                    \n",
    "            # We downsample in the end of each scale except last\n",
    "            if scale < n_latent_scales - 1:\n",
    "                output_channels = n_encoder_channels * mult * scale_factor\n",
    "                self.groups.append(Rescaler(output_channels, scale_factor=scale_factor, rescale_type=RescaleType.DOWN))\n",
    "                \n",
    "                mult *= scale_factor\n",
    "                input_shape *= np.array([1 / scale_factor, 1 / scale_factor, scale_factor])\n",
    "                \n",
    "        self.final_enc = Sequential([layers.ELU(),\n",
    "                                     SpectralNormalization(layers.Conv2D(n_encoder_channels * mult, (1, 1), padding=\"same\")),\n",
    "                                     layers.ELU() ])\n",
    "        self.mult = mult\n",
    "        self.output_shape_ = tuple(input_shape.astype(int).reshape(1, -1)[0])\n",
    "\n",
    "    def call(self, x):\n",
    "        enc_dec_combiners = []\n",
    "        for group in self.groups:\n",
    "            if isinstance(group, EncoderDecoderCombiner):\n",
    "                # We are stepping between groups, need to save results\n",
    "                enc_dec_combiners.append(partial(group, x))\n",
    "            else:\n",
    "                x = group(x)\n",
    "        final = self.final_enc(x)\n",
    "        return enc_dec_combiners, final\n",
    "\n",
    "\n",
    "class EncodingResidualCell(tf.keras.Model):\n",
    "    \"\"\"Encoding network residual cell in NVAE architecture\"\"\"\n",
    "    def __init__(self, output_channels, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.output_channels = output_channels\n",
    "        self.se = SqueezeExcitation()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        batch_size, h, w, c = input_shape\n",
    "        self.batch_norm1 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5, input_shape=(h, w, c))\n",
    "        self.conv1 = SpectralNormalization(layers.Conv2D(self.output_channels, (3, 3), padding=\"same\"))\n",
    "        self.batch_norm2 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "        self.conv2 = SpectralNormalization(layers.Conv2D(self.output_channels, (3, 3), padding=\"same\"))\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        x = self.batch_norm1(inputs)\n",
    "        x = activations.swish(x)\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = activations.swish(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.se(x)\n",
    "        return 0.1 * inputs + x\n",
    "    \n",
    "\n",
    "class EncoderDecoderCombiner(tf.keras.Model):\n",
    "    def __init__(self, n_channels, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.n_channels = n_channels\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        batch_size, h, w, c = input_shape\n",
    "        self.decoder_conv = SpectralNormalization(layers.Conv2D(self.n_channels, (1, 1), input_shape=(h, w, c)))\n",
    "    \n",
    "    def call(self, encoder_x, decoder_x):\n",
    "        x = self.decoder_conv(decoder_x)\n",
    "        return encoder_x + x\n",
    "    \n",
    "encoder = Encoder(n_encoder_channels = n_encoder_channels,\n",
    "                  res_cells_per_group = res_cells_per_group,\n",
    "                  n_latent_scales = n_latent_scales,\n",
    "                  n_groups_per_scale = n_groups_per_scale,\n",
    "                  mult = model_preprocess.mult,\n",
    "                  scale_factor = scale_factor,\n",
    "                  input_shape = model_preprocess.output_shape_next)\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    if i == 0:\n",
    "        x = tf.random.normal([10, 128, 128, 3])\n",
    "    else:\n",
    "        x = tf.random.normal([1, 128, 128, 3])\n",
    "        \n",
    "    x = model_preprocess(x)\n",
    "    y = encoder(x)\n",
    "    \n",
    "    print(encoder.mult)\n",
    "    print(encoder.output_shape_)\n",
    "    print(y[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fec4856-76ce-4b11-b0d2-1d855d13fc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "(16, 16, 128)\n",
      "(10, 16, 16, 128)\n",
      "(10, 32, 32, 64)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "ConcatOp : Ranks of all input tensors should match: shape[0] = [16,16,16,16] vs. shape[1] = [16,16,20] [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-100bece7552b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0menc_dec_combiners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mreconstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_dec_combiners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trial/akarsh/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-100bece7552b>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, prior, enc_dec_combiners, nll)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcombine_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trial/akarsh/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-100bece7552b>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, z)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trial/akarsh/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trial/akarsh/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1604\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[1;32m   1605\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1606\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trial/akarsh/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trial/akarsh/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trial/akarsh/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Ranks of all input tensors should match: shape[0] = [16,16,16,16] vs. shape[1] = [16,16,20] [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_decoder_channels,\n",
    "                 n_latent_per_group: int,\n",
    "                 res_cells_per_group,\n",
    "                 n_latent_scales: int,\n",
    "                 n_groups_per_scale: List[int],\n",
    "                 mult: int,\n",
    "                 scale_factor: int,\n",
    "                 input_shape,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.sampler = Sampler(n_latent_scales=n_latent_scales, \n",
    "                               n_groups_per_scale=n_groups_per_scale, \n",
    "                               n_latent_per_group=n_latent_per_group, \n",
    "                               scale_factor=scale_factor)\n",
    "        \n",
    "        self.groups = []\n",
    "        self.n_decoder_channels = n_decoder_channels\n",
    "        \n",
    "        for scale in range(n_latent_scales):\n",
    "            n_groups = n_groups_per_scale[scale]\n",
    "            \n",
    "            for group in range(n_groups):\n",
    "                output_channels = n_decoder_channels * mult\n",
    "                \n",
    "                if not (scale == 0 and group == 0):\n",
    "                    group = Sequential()\n",
    "                    \n",
    "                    for _ in range(res_cells_per_group):\n",
    "                        group.add(GenerativeResidualCell(output_channels))\n",
    "                    self.groups.append(group)\n",
    "                    \n",
    "                self.groups.append(DecoderSampleCombiner(output_channels))\n",
    "\n",
    "            if scale < n_latent_scales - 1:\n",
    "                output_channels = int(n_decoder_channels * mult / scale_factor)\n",
    "                self.groups.append(Rescaler(output_channels, scale_factor=scale_factor, rescale_type=RescaleType.UP))\n",
    "                mult /= scale_factor\n",
    "        \n",
    "        self.mult = mult\n",
    "        \n",
    "        h_shape = tf.convert_to_tensor([input_shape[0], input_shape[1], self.n_decoder_channels], dtype=tf.int32)\n",
    "        \n",
    "        self.h = tf.Variable(tf.random.uniform(h_shape, minval=0, maxval=1), trainable=True)\n",
    "\n",
    "    def call(self, prior, enc_dec_combiners: List, nll=False):\n",
    "        z_params = []\n",
    "        all_log_p = []\n",
    "        all_log_q = []\n",
    "        \n",
    "        z0, params = self.sampler(prior, z_idx=0)\n",
    "        \n",
    "        if nll:\n",
    "            all_log_q.append(calculate_log_p(z0, params.enc_mu, params.enc_sigma))\n",
    "            all_log_p.append(calculate_log_p(z0, params.dec_mu, params.dec_sigma))\n",
    "        \n",
    "        z_params.append(params)\n",
    "        h = tf.expand_dims(self.h, 0)\n",
    "        h = tf.tile(h, [tf.shape(z0)[0], 1, 1, 1])\n",
    "        x = self.groups[0](h, z0)\n",
    "\n",
    "        combine_idx = 0\n",
    "        for group in self.groups[1:]:\n",
    "            if isinstance(group, DecoderSampleCombiner):\n",
    "                enc_prior = enc_dec_combiners[combine_idx](x)\n",
    "                z_sample, params = self.sampler(x, z_idx=combine_idx + 1, enc_prior=enc_prior)\n",
    "                \n",
    "                if nll:\n",
    "                    all_log_q.append(calculate_log_p(z_sample, params.enc_mu, params.enc_sigma))\n",
    "                    all_log_p.append(calculate_log_p(z_sample, params.dec_mu, params.dec_sigma))\n",
    "                    \n",
    "                z_params.append(params)\n",
    "                x = group(x, z_sample)\n",
    "                combine_idx += 1\n",
    "            else:\n",
    "                x = group(x)\n",
    "\n",
    "        log_p = tf.zeros((tf.shape(x)[0]))\n",
    "        log_q = tf.zeros((tf.shape(x)[0]))\n",
    "        \n",
    "        if nll:\n",
    "            for p, q in zip(all_log_p, all_log_q):\n",
    "                log_p += tf.reduce_sum(p, axis=[1, 2, 3])\n",
    "                log_q += tf.reduce_sum(q, axis=[1, 2, 3])\n",
    "\n",
    "        return x, z_params, log_p, log_q\n",
    "\n",
    "\n",
    "class DecoderSampleCombiner(tf.keras.Model):\n",
    "    def __init__(self, output_channels, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.output_channels = output_channels\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        batch_size, h, w, c = input_shape\n",
    "        self.conv = SpectralNormalization(layers.Conv2D(self.output_channels, (1, 1), strides=(1, 1), padding=\"same\", input_shape=(h, w, c)))\n",
    "\n",
    "    def call(self, x, z):\n",
    "        output = tf.concat((x, z), axis=3)\n",
    "        output = self.conv(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class GenerativeResidualCell(tf.keras.Model):\n",
    "    \"\"\"Generative network residual cell in NVAE architecture\"\"\"\n",
    "    def __init__(self, output_channels, expansion_ratio=6, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.se = SqueezeExcitation()\n",
    "        self.output_channels = output_channels\n",
    "        self.expansion_ratio = expansion_ratio\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        batch_size, h, w, c = input_shape\n",
    "        self.batch_norm1 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5, input_shape=(h, w, c))\n",
    "        self.conv1 = SpectralNormalization(layers.Conv2D(self.expansion_ratio * self.output_channels, (1, 1), padding=\"same\"))\n",
    "        self.batch_norm2 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "        self.depth_conv = layers.DepthwiseConv2D((5, 5), padding=\"same\")\n",
    "        self.batch_norm3 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "        self.conv2 = SpectralNormalization(layers.Conv2D(self.output_channels, (1, 1), padding=\"same\"))\n",
    "        self.batch_norm4 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.batch_norm1(inputs)\n",
    "        x = self.conv1(x)\n",
    "        x = activations.swish(self.batch_norm2(x))\n",
    "        x = self.depth_conv(x)\n",
    "        x = activations.swish(self.batch_norm3(x))\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.se(x)\n",
    "        return 0.1 * inputs + x\n",
    "    \n",
    "    \n",
    "decoder = Decoder(n_decoder_channels=n_decoder_channels,\n",
    "                  n_latent_per_group=n_latent_per_group,\n",
    "                  res_cells_per_group=res_cells_per_group,\n",
    "                  n_latent_scales=n_latent_scales,\n",
    "                  n_groups_per_scale=list(reversed(n_groups_per_scale)),\n",
    "                  mult=encoder.mult,\n",
    "                  scale_factor=scale_factor,\n",
    "                  input_shape=encoder.output_shape_)\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    if i == 0:\n",
    "        x = tf.random.normal([10, 128, 128, 3])\n",
    "    else:\n",
    "        x = tf.random.normal([1, 128, 128, 3])\n",
    "        \n",
    "    x = model_preprocess(x)\n",
    "    enc_dec_combiners, final_x = encoder(x)\n",
    "        \n",
    "    # Flip bottom-up to top-down\n",
    "    enc_dec_combiners.reverse()\n",
    "    \n",
    "    reconstruction, z_params, log_p, log_q = decoder(final_x, enc_dec_combiners, nll=False)\n",
    "    \n",
    "    print(encoder.mult)\n",
    "    print(encoder.output_shape_)\n",
    "    print(final_x.shape)\n",
    "    print(reconstruction.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
