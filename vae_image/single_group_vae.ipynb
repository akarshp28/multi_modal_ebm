{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545022b6-9ada-4f54-a0a8-7e3bc7f14612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import activations, Sequential, layers\n",
    "from tensorflow_addons.layers import SpectralNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f503d1-c1d3-4c6d-8d5e-79e2949c8ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (128, 128, 3)\n",
    "n_encoder_channels = 16\n",
    "n_decoder_channels = 16\n",
    "\n",
    "mult = 1\n",
    "scale_factor = 2\n",
    "\n",
    "latent_dim = 128\n",
    "res_cells_per_group = 1\n",
    "n_groups_per_scale = [2] * 6\n",
    "n_latent_scales = len(n_groups_per_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306f255a-fcf3-4116-a836-463b45bf231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RescaleType(Enum):\n",
    "#     UP = auto()\n",
    "#     DOWN = auto()\n",
    "\n",
    "\n",
    "# class SqueezeExcitation(tf.keras.Model):\n",
    "#     \"\"\"Squeeze and Excitation block as defined by Hu, et al. (2019)\n",
    "#     See Also\n",
    "#     ========\n",
    "#     Source paper https://arxiv.org/pdf/1709.01507.pdf\n",
    "#     \"\"\"\n",
    "#     def __init__(self, ratio=16, **kwargs) -> None:\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.ratio = ratio\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         batch_size, h, w, c = input_shape\n",
    "#         self.gap = layers.GlobalAveragePooling2D(data_format=\"channels_last\")\n",
    "#         num_hidden = max(c / self.ratio, 4)\n",
    "#         self.dense1 = layers.Dense(units=num_hidden)\n",
    "#         self.dense2 = layers.Dense(units=c)\n",
    "    \n",
    "#     def call(self, inputs):\n",
    "#         x = self.gap(inputs)\n",
    "#         x = self.dense1(x)\n",
    "#         x = activations.relu(x)\n",
    "#         x = self.dense2(x)\n",
    "#         x = activations.sigmoid(x)\n",
    "#         x = tf.expand_dims(x, 1)\n",
    "#         x = tf.expand_dims(x, 2)\n",
    "#         return x * inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db5b0c5c-7f45-4be8-bbe3-038d9744f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EncodingResidualCell(tf.keras.Model):\n",
    "#     \"\"\"Encoding network residual cell in NVAE architecture\"\"\"\n",
    "#     def __init__(self, output_channels, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.batch_norm1 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "#         self.conv1 = SpectralNormalization(layers.Conv2D(output_channels, (3, 3), padding=\"same\"))\n",
    "#         self.batch_norm2 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "#         self.conv2 = SpectralNormalization(layers.Conv2D(output_channels, (3, 3), padding=\"same\"))\n",
    "#         self.se = SqueezeExcitation()\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         x = activations.swish(self.batch_norm1(inputs))\n",
    "#         x = self.conv1(x)\n",
    "#         x = activations.swish(self.batch_norm2(x))\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.se(x)\n",
    "#         return 0.1 * inputs + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c54b51d9-0793-4bdf-8df2-483389e9e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GenerativeResidualCell(tf.keras.Model):\n",
    "#     \"\"\"Generative network residual cell in NVAE architecture\"\"\"\n",
    "#     def __init__(self, output_channels, expansion_ratio=6, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "        \n",
    "#         self.batch_norm1 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "#         self.conv1 = SpectralNormalization(layers.Conv2D(expansion_ratio * output_channels, (1, 1), padding=\"same\"))\n",
    "#         self.batch_norm2 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "#         self.depth_conv = layers.DepthwiseConv2D((5, 5), padding=\"same\")\n",
    "#         self.batch_norm3 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "#         self.conv2 = SpectralNormalization(layers.Conv2D(output_channels, (1, 1), padding=\"same\"))\n",
    "#         self.batch_norm4 = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "#         self.se = SqueezeExcitation()\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         x = self.batch_norm1(inputs)\n",
    "#         x = self.conv1(x)\n",
    "#         x = activations.swish(self.batch_norm2(x))\n",
    "#         x = self.depth_conv(x)\n",
    "#         x = activations.swish(self.batch_norm3(x))\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.batch_norm4(x)\n",
    "#         x = self.se(x)\n",
    "#         return 0.1 * inputs + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d94f965d-26d1-4f31-85af-a2c25fca87d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Rescaler(tf.keras.Model):\n",
    "#     def __init__(self, n_channels, scale_factor, rescale_type, **kwargs) -> None:\n",
    "#         super().__init__(**kwargs)\n",
    "        \n",
    "#         self.bn = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)\n",
    "#         self.mode = rescale_type\n",
    "#         self.factor = scale_factor\n",
    "        \n",
    "#         if rescale_type == RescaleType.UP:\n",
    "#             self.conv = SpectralNormalization(layers.Conv2D(n_channels, (3, 3), strides=(1, 1), padding=\"same\"))\n",
    "            \n",
    "#         elif rescale_type == RescaleType.DOWN:\n",
    "#             self.conv = SpectralNormalization(layers.Conv2D(n_channels, (3, 3), strides=(self.factor, self.factor), padding=\"same\"))\n",
    "\n",
    "#     def call(self, input):\n",
    "#         x = self.bn(input)\n",
    "#         x = activations.swish(x)\n",
    "        \n",
    "#         if self.mode == RescaleType.UP:\n",
    "#             _, height, width, _ = x.get_shape()\n",
    "#             x = tf.image.resize(x, size=(self.factor * height, self.factor * width), method=\"nearest\")\n",
    "#         x = self.conv(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c7dfede-2eac-4860-bf4c-b4fcff1796f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_encoder_layers(n_latent_scales, n_groups_per_scale, res_cells_per_group, n_encoder_channels, scale_factor, mult=1):\n",
    "#     # create encoder layers as a list\n",
    "#     enc_layers = []\n",
    "#     for scale in range(n_latent_scales):\n",
    "#         n_groups = n_groups_per_scale[scale]\n",
    "#         print('\\nGroup: ', scale)\n",
    "\n",
    "#         for group_idx in range(n_groups):\n",
    "#             if scale == group_idx == 0:\n",
    "#                 output_channels = n_encoder_channels * mult\n",
    "#             print('Output_channels: ', output_channels)\n",
    "            \n",
    "#             for rb in range(res_cells_per_group):\n",
    "#                 enc_layers.append(EncodingResidualCell(output_channels, name='res_block_' + str(scale) + '_' + str(group_idx) + '_' + str(rb)))\n",
    "#                 print('res block')\n",
    "        \n",
    "#         # We downsample in the end of each scale except last\n",
    "#         if scale < n_latent_scales - 1:\n",
    "#             output_channels = n_encoder_channels * mult * scale_factor\n",
    "#             enc_layers.append(Rescaler(output_channels, scale_factor=scale_factor, rescale_type=RescaleType.DOWN))\n",
    "#             print('Rescaler')\n",
    "#             print('New output_channels: ', output_channels)\n",
    "#             mult *= scale_factor\n",
    "    \n",
    "#     enc_layers.append(layers.ELU())\n",
    "#     enc_layers.append(SpectralNormalization(layers.Conv2D(n_encoder_channels * mult, (1, 1), padding=\"same\")))\n",
    "#     enc_layers.append(layers.ELU())\n",
    "    \n",
    "#     return enc_layers, mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3ad435f-95a8-4d29-b712-a284528762fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_decoder_layers(encoder_mult, n_latent_scales, n_groups_per_scale, res_cells_per_group, n_decoder_channels, scale_factor):\n",
    "#     m = encoder_mult\n",
    "#     dec_layers = []\n",
    "    \n",
    "#     for scale in range(n_latent_scales):\n",
    "#         print('\\nGroup: ', scale)\n",
    "#         n_groups = n_groups_per_scale[scale]\n",
    "\n",
    "#         for group in range(n_groups):\n",
    "#             if scale == group == 0:\n",
    "#                 output_channels = int(n_decoder_channels * m)\n",
    "#             print('Output channels', output_channels)\n",
    "            \n",
    "#             for res in range(res_cells_per_group):\n",
    "#                 dec_layers.append(GenerativeResidualCell(output_channels))\n",
    "#                 print('Gen Res block', flush=True)\n",
    "\n",
    "#         if scale < n_latent_scales - 1:\n",
    "#             output_channels = int(n_decoder_channels * m / scale_factor)\n",
    "            \n",
    "#             dec_layers.append(Rescaler(output_channels, scale_factor=scale_factor, rescale_type=RescaleType.UP))\n",
    "#             print('Rescaler', flush=True)\n",
    "\n",
    "#             m /= scale_factor\n",
    "#     return dec_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "829f3afc-6418-4619-8807-6a84029dde67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Sampling(layers.Layer):\n",
    "#     def call(self, inputs):\n",
    "#         z_mean, z_log_var = inputs\n",
    "#         batch = tf.shape(z_mean)[0]\n",
    "#         dim = tf.shape(z_mean)[1]\n",
    "#         epsilon = tf.random.normal([batch, dim])\n",
    "#         return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bea8a4e-8767-4976-abe6-a22455fc6667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_in = layers.Input(shape=image_shape, name='encoder_input')\n",
    "# x = SpectralNormalization(layers.Conv2D(n_encoder_channels, (3, 3), padding=\"same\"))(x_in)\n",
    "\n",
    "# enc_layers, mult = create_encoder_layers(n_latent_scales, n_groups_per_scale, res_cells_per_group, n_encoder_channels, scale_factor)\n",
    "\n",
    "# for group in enc_layers:\n",
    "#     x = group(x)\n",
    "    \n",
    "# before_shape = x.shape[1:]\n",
    "# x = layers.GlobalAveragePooling2D()(x)\n",
    "# after_shape = x.shape[1:][0]\n",
    "\n",
    "# z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
    "# z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "# z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "# model_encoder = tf.keras.models.Model(x_in, [z_mean, z_log_var, z], name='encoder')\n",
    "# model_encoder.summary()\n",
    "\n",
    "# print(before_shape, after_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4865554-8db9-4b79-8923-d058b90fadc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_input = layers.Input(shape=(latent_dim), name='decoder_input')\n",
    "# x = layers.Dense(before_shape[0] * before_shape[1] * before_shape[2])(decoder_input)\n",
    "# x = layers.Reshape(before_shape)(x)\n",
    "\n",
    "# dec_layers = create_decoder_layers(mult, n_latent_scales, n_groups_per_scale, res_cells_per_group, n_decoder_channels, scale_factor)\n",
    "\n",
    "# for group in dec_layers:\n",
    "#     x = group(x)\n",
    "    \n",
    "# x = layers.Activation(activations.elu)(x)\n",
    "# x = SpectralNormalization(layers.Conv2D(3, kernel_size=(3, 3), padding=\"same\"))(x)\n",
    "\n",
    "# model_decoder = tf.keras.models.Model(decoder_input, x, name='decoder')\n",
    "# model_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c92df3f-ae13-4fda-a230-21984c463d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excite_block(input_x, ratio=16):\n",
    "    shp = getshape_layer()(input_x)\n",
    "    batch_size, h, w, c = shp\n",
    "    num_hidden = max(c / ratio, 4)\n",
    "    x = layers.GlobalAveragePooling2D()(input_x)\n",
    "    x = layers.Dense(units=num_hidden, activation='relu')(x)\n",
    "    x = layers.Dense(units=c, activation='sigmoid')(x)\n",
    "    x = layers.Reshape((1, 1, c))(x)\n",
    "    x = layers.Multiply()([input_x, x])\n",
    "    return x\n",
    "\n",
    "def encoding_res_block(input_x, output_channels):\n",
    "    x = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)(input_x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Conv2D(output_channels, (3, 3), padding=\"same\")(x)\n",
    "    \n",
    "    x = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Conv2D(output_channels, (3, 3), padding=\"same\")(x)\n",
    "    x = squeeze_excite_block(x)\n",
    "    \n",
    "    x = layers.Add()([0.1 * input_x, x])\n",
    "    return x\n",
    "\n",
    "def generative_res_block(input_x, output_channels, expansion_ratio=6):\n",
    "    x = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)(input_x)\n",
    "    x = layers.Conv2D(expansion_ratio * output_channels, (1, 1), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.DepthwiseConv2D((5, 5), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Conv2D(output_channels, (1, 1), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)(x)\n",
    "    x = squeeze_excite_block(x)\n",
    "    \n",
    "    x = layers.Add()([0.1 * input_x, x])\n",
    "    return x\n",
    "    \n",
    "def rescaler(input_x, n_channels, scale_factor, rescale_type):\n",
    "    x = layers.BatchNormalization(momentum=0.05, epsilon=1e-5)(input_x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    \n",
    "    if rescale_type == 'up':\n",
    "        shp = getshape_layer()(x)\n",
    "        _, height, width, _ = shp\n",
    "        x = tf.image.resize(x, size=(scale_factor * height, scale_factor * width), method=\"nearest\")\n",
    "        x = layers.Conv2D(n_channels, (3, 3), strides=(1, 1), padding=\"same\")(x)\n",
    "    else:\n",
    "        x = layers.Conv2D(n_channels, (3, 3), strides=(scale_factor, scale_factor), padding=\"same\")(x)\n",
    "    return x\n",
    "\n",
    "class getshape_layer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        return inputs.shape\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal([batch, dim])\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "#########################################################\n",
    "\n",
    "def create_encoder(mult=1):\n",
    "    x_in = layers.Input(shape=image_shape, name='encoder_input')\n",
    "    x = layers.Conv2D(n_encoder_channels, (3, 3), padding=\"same\")(x_in)\n",
    "    \n",
    "    for scale in range(n_latent_scales):\n",
    "        n_groups = n_groups_per_scale[scale]\n",
    "        print('\\nGroup: ', scale)\n",
    "\n",
    "        for group_idx in range(n_groups):\n",
    "            output_channels = n_encoder_channels * mult\n",
    "            print('Output_channels: ', output_channels)\n",
    "            \n",
    "            for rb in range(res_cells_per_group):\n",
    "                x = encoding_res_block(x, output_channels)\n",
    "                print('res block')\n",
    "        \n",
    "        # We downsample in the end of each scale except last\n",
    "        if scale < n_latent_scales - 1:\n",
    "            output_channels = n_encoder_channels * mult * scale_factor\n",
    "            x = rescaler(x, output_channels, scale_factor, 'down')\n",
    "            print('Rescaler')\n",
    "            print('New output_channels: ', output_channels)\n",
    "            mult *= scale_factor\n",
    "    \n",
    "    x = layers.ELU()(x)\n",
    "    x = layers.Conv2D(n_encoder_channels * mult, (1, 1), padding=\"same\")(x)\n",
    "    x = layers.ELU()(x)\n",
    "    \n",
    "    before_shape = x.shape[1:]\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "    model_encoder = tf.keras.models.Model(x_in, [z_mean, z_log_var, z], name='encoder')\n",
    "    model_encoder.summary()\n",
    "    return model_encoder, before_shape, mult\n",
    "\n",
    "#########################################################\n",
    "\n",
    "def create_decoder(en_mult, before_shape):\n",
    "    decoder_input = layers.Input(shape=(latent_dim), name='decoder_input')\n",
    "    x = layers.Dense(before_shape[0] * before_shape[1] * before_shape[2])(decoder_input)\n",
    "    x = layers.Reshape(before_shape)(x)\n",
    "    \n",
    "    for scale in range(n_latent_scales):\n",
    "        print('\\nGroup: ', scale)\n",
    "        n_groups = n_groups_per_scale[scale]\n",
    "\n",
    "        for group in range(n_groups):\n",
    "            output_channels = int(n_decoder_channels * en_mult)\n",
    "            print('Output channels', output_channels)\n",
    "            \n",
    "            for res in range(res_cells_per_group):\n",
    "                x = generative_res_block(x, output_channels, expansion_ratio=6)\n",
    "                print('Gen Res block', flush=True)\n",
    "\n",
    "        if scale < n_latent_scales - 1:\n",
    "            output_channels = int(n_decoder_channels * en_mult / scale_factor)\n",
    "            x = rescaler(x, output_channels, scale_factor, 'up')\n",
    "            print('Rescaler', flush=True)\n",
    "            en_mult /= scale_factor\n",
    "    \n",
    "    x = layers.Conv2D(3, kernel_size=(3, 3), padding=\"same\")(x)\n",
    "    x = layers.Activation(activations.sigmoid)(x)\n",
    "    \n",
    "    model_decoder = tf.keras.models.Model(decoder_input, x, name='decoder')\n",
    "    model_decoder.summary()\n",
    "    return model_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69404806-8804-4823-97e1-1ee23565db2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group:  0\n",
      "Output_channels:  16\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TensorShape' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b0a8c85e55bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_mult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_mult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-8f1075b7c32b>\u001b[0m in \u001b[0;36mcreate_encoder\u001b[0;34m(mult)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_cells_per_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding_res_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'res block'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-8f1075b7c32b>\u001b[0m in \u001b[0;36mencoding_res_block\u001b[0;34m(input_x, output_channels)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqueeze_excite_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-8f1075b7c32b>\u001b[0m in \u001b[0;36msqueeze_excite_block\u001b[0;34m(input_x, ratio)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msqueeze_excite_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mshp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetshape_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnum_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trial/akarsh/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    952\u001b[0m               \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             inputs, outputs = self._set_connectivity_metadata_(\n\u001b[0;32m--> 954\u001b[0;31m                 inputs, outputs, args, kwargs)\n\u001b[0m\u001b[1;32m    955\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trial/akarsh/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_set_connectivity_metadata_\u001b[0;34m(self, inputs, outputs, args, kwargs)\u001b[0m\n\u001b[1;32m   2312\u001b[0m     \u001b[0;31m# This updates the layer history of the output tensor(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m     self._add_inbound_node(\n\u001b[0;32m-> 2314\u001b[0;31m         input_tensors=inputs, output_tensors=outputs, arguments=arguments)\n\u001b[0m\u001b[1;32m   2315\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trial/akarsh/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_add_inbound_node\u001b[0;34m(self, input_tensors, output_tensors, arguments)\u001b[0m\n\u001b[1;32m   2342\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2343\u001b[0m         \u001b[0moutput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2344\u001b[0;31m         arguments=arguments)\n\u001b[0m\u001b[1;32m   2345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m     \u001b[0;31m# Update tensor history metadata.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trial/akarsh/lib/python3.7/site-packages/tensorflow/python/keras/engine/node.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, outbound_layer, inbound_layers, node_indices, tensor_indices, input_tensors, output_tensors, arguments)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m# Nested structure of shape tuples, shapes of output_tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# Optional keyword arguments to layer's `call`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trial/akarsh/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trial/akarsh/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/trial/akarsh/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mint_shape\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1201\u001b[0m   \"\"\"\n\u001b[1;32m   1202\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TensorShape' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "model_encoder, before_shape, en_mult = create_encoder()\n",
    "model_decoder = create_decoder(en_mult, before_shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
