Total data size:  414113
Total data size:  202654
616767
Found 28444 unique tokens
Shape of data tensor: (616767, 40)
15000
Found 400000 word vectors.
Null word embeddings: 0
Check Null:  False
Emb vector shape:  (15000, 300)
(414113, 40) (202654, 40)
2021-04-05 16:12:23.829334: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-04-05 16:12:23.866214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-04-05 16:12:23.867409: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-04-05 16:12:23.884716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-04-05 16:12:23.898873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-04-05 16:12:23.900310: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-04-05 16:12:23.923641: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-04-05 16:12:23.941902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-04-05 16:12:23.961890: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-04-05 16:12:23.964849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-04-05 16:12:23.965372: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2021-04-05 16:12:23.982731: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2600000000 Hz
2021-04-05 16:12:23.983288: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560a171d7590 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-04-05 16:12:23.983312: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-04-05 16:12:24.107134: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560a171ef5b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-04-05 16:12:24.107181: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2021-04-05 16:12:24.108623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-04-05 16:12:24.108691: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-04-05 16:12:24.108706: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-04-05 16:12:24.108720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-04-05 16:12:24.108733: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-04-05 16:12:24.108747: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-04-05 16:12:24.108760: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-04-05 16:12:24.108774: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-04-05 16:12:24.111051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-04-05 16:12:24.111105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-04-05 16:12:24.113008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-05 16:12:24.113023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2021-04-05 16:12:24.113035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2021-04-05 16:12:24.115388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10371 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:1a:00.0, compute capability: 6.1)
WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:From /users/apokkunu/trial/akarsh/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2021-04-05 16:12:24.151778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-04-05 16:12:24.151876: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-04-05 16:12:24.151892: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-04-05 16:12:24.151906: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-04-05 16:12:24.151919: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-04-05 16:12:24.151932: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-04-05 16:12:24.151944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-04-05 16:12:24.151958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-04-05 16:12:24.154180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-04-05 16:12:24.154216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-04-05 16:12:24.154225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2021-04-05 16:12:24.154233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2021-04-05 16:12:24.156446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10371 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:1a:00.0, compute capability: 6.1)
WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
Model: "VAE"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 40)]         0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 40, 300)      4500000     input_1[0][0]                    
__________________________________________________________________________________________________
custom_lstm (custom_lstm)       (None, 512)          1140736     embedding[0][0]                  
__________________________________________________________________________________________________
z_mean (Dense)                  (None, 128)          65664       custom_lstm[0][0]                
__________________________________________________________________________________________________
z_log_var (Dense)               (None, 128)          65664       custom_lstm[0][0]                
__________________________________________________________________________________________________
sampling (Sampling)             (None, 128)          0           z_mean[0][0]                     
                                                                 z_log_var[0][0]                  
__________________________________________________________________________________________________
custom_decoder (custom_decoder) (None, 40, 15000)    9664152     sampling[0][0]                   
__________________________________________________________________________________________________
elbo__layer (ELBO_Layer)        (None, 40)           0           custom_decoder[0][0]             
==================================================================================================
Total params: 15,436,216
Trainable params: 10,936,216
Non-trainable params: 4,500,000
__________________________________________________________________________________________________
layer 0: <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x2ab6be81ae90>
has input mask: None
has output mask: None
layer 1: <tensorflow.python.keras.layers.embeddings.Embedding object at 0x2ab6ad67b090>
has input mask: None
has output mask: Tensor("embedding/NotEqual:0", shape=(None, 40), dtype=bool)
layer 2: <__main__.custom_lstm object at 0x2ab6a9336e10>
has input mask: Tensor("embedding/NotEqual:0", shape=(None, 40), dtype=bool)
has output mask: Tensor("embedding/NotEqual:0", shape=(None, 40), dtype=bool)
layer 3: <tensorflow.python.keras.layers.core.Dense object at 0x2ab6a7721150>
has input mask: Tensor("embedding/NotEqual:0", shape=(None, 40), dtype=bool)
has output mask: Tensor("embedding/NotEqual:0", shape=(None, 40), dtype=bool)
layer 4: <tensorflow.python.keras.layers.core.Dense object at 0x2ab6addc7390>
has input mask: Tensor("embedding/NotEqual:0", shape=(None, 40), dtype=bool)
has output mask: Tensor("embedding/NotEqual:0", shape=(None, 40), dtype=bool)
layer 5: <__main__.Sampling object at 0x2ab6c12a9a50>
has input mask: [<tf.Tensor 'embedding/NotEqual:0' shape=(None, 40) dtype=bool>, <tf.Tensor 'embedding/NotEqual:0' shape=(None, 40) dtype=bool>]
has output mask: Tensor("embedding/NotEqual:0", shape=(None, 40), dtype=bool)
layer 6: <__main__.custom_decoder object at 0x2ab6cfe22710>
has input mask: Tensor("embedding/NotEqual:0", shape=(None, 40), dtype=bool)
has output mask: Tensor("embedding/NotEqual:0", shape=(None, 40), dtype=bool)
layer 7: <__main__.ELBO_Layer object at 0x2ab6cfeb4050>
has input mask: Tensor("embedding/NotEqual:0", shape=(None, 40), dtype=bool)
has output mask: Tensor("embedding/NotEqual:0", shape=(None, 40), dtype=bool)


Sent Length: 40, Vocab size: 15000, store_dir: output6
Epochs: 500, BS: 128, LR: 0.0001, EMB DIM: 300, Z_DIM: 128, INTR_DIM: 256, Dropout: 0.2, KLW: 0.01


2021-04-05 16:12:34.780724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
Train on 414113 samples, validate on 202654 samples
Epoch 1/500

Epoch 00001: val_loss improved from inf to 54.45238, saving model to /users/apokkunu/trial/text/output6/weights.01-54.45.h5
414113/414113 - 1088s - loss: 59.4933 - kl_loss: 0.3172 - val_loss: 54.4524 - val_kl_loss: 0.3320
Epoch 2/500

Epoch 00002: val_loss improved from 54.45238 to 49.53862, saving model to /users/apokkunu/trial/text/output6/weights.02-49.54.h5
414113/414113 - 1070s - loss: 52.5356 - kl_loss: 0.3902 - val_loss: 49.5386 - val_kl_loss: 0.4656
Epoch 3/500

Epoch 00003: val_loss improved from 49.53862 to 43.28059, saving model to /users/apokkunu/trial/text/output6/weights.03-43.28.h5
414113/414113 - 1063s - loss: 47.2590 - kl_loss: 0.5671 - val_loss: 43.2806 - val_kl_loss: 0.6762
Epoch 4/500

Epoch 00004: val_loss improved from 43.28059 to 36.59209, saving model to /users/apokkunu/trial/text/output6/weights.04-36.59.h5
414113/414113 - 1062s - loss: 41.0609 - kl_loss: 0.8162 - val_loss: 36.5921 - val_kl_loss: 0.9281
Epoch 5/500

Epoch 00005: val_loss improved from 36.59209 to 31.07757, saving model to /users/apokkunu/trial/text/output6/weights.05-31.08.h5
414113/414113 - 1059s - loss: 35.1948 - kl_loss: 1.0216 - val_loss: 31.0776 - val_kl_loss: 1.0824
Epoch 6/500

Epoch 00006: val_loss improved from 31.07757 to 27.20075, saving model to /users/apokkunu/trial/text/output6/weights.06-27.20.h5
414113/414113 - 1059s - loss: 30.8152 - kl_loss: 1.1595 - val_loss: 27.2008 - val_kl_loss: 1.1890
Epoch 7/500

Epoch 00007: val_loss improved from 27.20075 to 24.27834, saving model to /users/apokkunu/trial/text/output6/weights.07-24.28.h5
414113/414113 - 1057s - loss: 27.5413 - kl_loss: 1.2646 - val_loss: 24.2783 - val_kl_loss: 1.2777
Epoch 8/500

Epoch 00008: val_loss improved from 24.27834 to 21.90646, saving model to /users/apokkunu/trial/text/output6/weights.08-21.91.h5
414113/414113 - 1057s - loss: 25.0892 - kl_loss: 1.3344 - val_loss: 21.9065 - val_kl_loss: 1.3603
Epoch 9/500

Epoch 00009: val_loss improved from 21.90646 to 19.95761, saving model to /users/apokkunu/trial/text/output6/weights.09-19.96.h5
414113/414113 - 1058s - loss: 22.9964 - kl_loss: 1.3983 - val_loss: 19.9576 - val_kl_loss: 1.3947
Epoch 10/500

Epoch 00010: val_loss improved from 19.95761 to 18.34027, saving model to /users/apokkunu/trial/text/output6/weights.10-18.34.h5
414113/414113 - 1058s - loss: 21.3319 - kl_loss: 1.4421 - val_loss: 18.3403 - val_kl_loss: 1.4395
Epoch 11/500

Epoch 00011: val_loss improved from 18.34027 to 16.96431, saving model to /users/apokkunu/trial/text/output6/weights.11-16.96.h5
414113/414113 - 1058s - loss: 19.8783 - kl_loss: 1.4903 - val_loss: 16.9643 - val_kl_loss: 1.4693
Epoch 12/500

Epoch 00012: val_loss improved from 16.96431 to 15.65272, saving model to /users/apokkunu/trial/text/output6/weights.12-15.65.h5
414113/414113 - 1053s - loss: 18.5400 - kl_loss: 1.5332 - val_loss: 15.6527 - val_kl_loss: 1.5194
Epoch 13/500

Epoch 00013: val_loss improved from 15.65272 to 14.58352, saving model to /users/apokkunu/trial/text/output6/weights.13-14.58.h5
414113/414113 - 1057s - loss: 17.3812 - kl_loss: 1.5670 - val_loss: 14.5835 - val_kl_loss: 1.5480
Epoch 14/500

Epoch 00014: val_loss improved from 14.58352 to 13.60610, saving model to /users/apokkunu/trial/text/output6/weights.14-13.61.h5
414113/414113 - 1057s - loss: 16.3529 - kl_loss: 1.5982 - val_loss: 13.6061 - val_kl_loss: 1.5900
Epoch 15/500

Epoch 00015: val_loss improved from 13.60610 to 12.75660, saving model to /users/apokkunu/trial/text/output6/weights.15-12.76.h5
414113/414113 - 1053s - loss: 15.4302 - kl_loss: 1.6274 - val_loss: 12.7566 - val_kl_loss: 1.6132
Epoch 16/500

Epoch 00016: val_loss improved from 12.75660 to 12.02234, saving model to /users/apokkunu/trial/text/output6/weights.16-12.02.h5
414113/414113 - 1054s - loss: 14.6275 - kl_loss: 1.6491 - val_loss: 12.0223 - val_kl_loss: 1.6045
Epoch 17/500

Epoch 00017: val_loss improved from 12.02234 to 11.45208, saving model to /users/apokkunu/trial/text/output6/weights.17-11.45.h5
414113/414113 - 1056s - loss: 13.9110 - kl_loss: 1.6663 - val_loss: 11.4521 - val_kl_loss: 1.6462
Epoch 18/500

Epoch 00018: val_loss improved from 11.45208 to 10.77137, saving model to /users/apokkunu/trial/text/output6/weights.18-10.77.h5
414113/414113 - 1056s - loss: 13.2721 - kl_loss: 1.6764 - val_loss: 10.7714 - val_kl_loss: 1.6439
Epoch 19/500

Epoch 00019: val_loss improved from 10.77137 to 10.28798, saving model to /users/apokkunu/trial/text/output6/weights.19-10.29.h5
414113/414113 - 1056s - loss: 12.6961 - kl_loss: 1.6858 - val_loss: 10.2880 - val_kl_loss: 1.6735
Epoch 20/500

Epoch 00020: val_loss improved from 10.28798 to 9.78627, saving model to /users/apokkunu/trial/text/output6/weights.20-9.79.h5
414113/414113 - 1056s - loss: 12.1691 - kl_loss: 1.6967 - val_loss: 9.7863 - val_kl_loss: 1.6734
Epoch 21/500

Epoch 00021: val_loss improved from 9.78627 to 9.40620, saving model to /users/apokkunu/trial/text/output6/weights.21-9.41.h5
414113/414113 - 1053s - loss: 11.6857 - kl_loss: 1.7049 - val_loss: 9.4062 - val_kl_loss: 1.6722
Epoch 22/500

Epoch 00022: val_loss improved from 9.40620 to 9.02012, saving model to /users/apokkunu/trial/text/output6/weights.22-9.02.h5
414113/414113 - 1055s - loss: 11.2496 - kl_loss: 1.7076 - val_loss: 9.0201 - val_kl_loss: 1.6659
Epoch 23/500

Epoch 00023: val_loss improved from 9.02012 to 8.63984, saving model to /users/apokkunu/trial/text/output6/weights.23-8.64.h5
414113/414113 - 1055s - loss: 10.8489 - kl_loss: 1.7121 - val_loss: 8.6398 - val_kl_loss: 1.6644
Epoch 24/500

Epoch 00024: val_loss improved from 8.63984 to 8.34398, saving model to /users/apokkunu/trial/text/output6/weights.24-8.34.h5
414113/414113 - 1057s - loss: 10.4810 - kl_loss: 1.7164 - val_loss: 8.3440 - val_kl_loss: 1.6769
Epoch 25/500

Epoch 00025: val_loss improved from 8.34398 to 8.04675, saving model to /users/apokkunu/trial/text/output6/weights.25-8.05.h5
414113/414113 - 1057s - loss: 10.1464 - kl_loss: 1.7214 - val_loss: 8.0467 - val_kl_loss: 1.6651
Epoch 26/500

Epoch 00026: val_loss improved from 8.04675 to 7.78500, saving model to /users/apokkunu/trial/text/output6/weights.26-7.78.h5
414113/414113 - 1058s - loss: 9.8351 - kl_loss: 1.7229 - val_loss: 7.7850 - val_kl_loss: 1.6779
Epoch 27/500

Epoch 00027: val_loss improved from 7.78500 to 7.57257, saving model to /users/apokkunu/trial/text/output6/weights.27-7.57.h5
414113/414113 - 1058s - loss: 9.5531 - kl_loss: 1.7213 - val_loss: 7.5726 - val_kl_loss: 1.6932
Epoch 28/500

Epoch 00028: val_loss improved from 7.57257 to 7.32827, saving model to /users/apokkunu/trial/text/output6/weights.28-7.33.h5
414113/414113 - 1058s - loss: 9.2880 - kl_loss: 1.7231 - val_loss: 7.3283 - val_kl_loss: 1.6608
Epoch 29/500

Epoch 00029: val_loss improved from 7.32827 to 7.15059, saving model to /users/apokkunu/trial/text/output6/weights.29-7.15.h5
414113/414113 - 1058s - loss: 9.0458 - kl_loss: 1.7218 - val_loss: 7.1506 - val_kl_loss: 1.6677
Epoch 30/500

Epoch 00030: val_loss improved from 7.15059 to 6.96891, saving model to /users/apokkunu/trial/text/output6/weights.30-6.97.h5
414113/414113 - 1055s - loss: 8.8077 - kl_loss: 1.7228 - val_loss: 6.9689 - val_kl_loss: 1.6932
Epoch 31/500

Epoch 00031: val_loss improved from 6.96891 to 6.76399, saving model to /users/apokkunu/trial/text/output6/weights.31-6.76.h5
414113/414113 - 1059s - loss: 8.5810 - kl_loss: 1.7212 - val_loss: 6.7640 - val_kl_loss: 1.6894
Epoch 32/500

Epoch 00032: val_loss improved from 6.76399 to 6.57151, saving model to /users/apokkunu/trial/text/output6/weights.32-6.57.h5
414113/414113 - 1059s - loss: 8.3729 - kl_loss: 1.7221 - val_loss: 6.5715 - val_kl_loss: 1.6818
Epoch 33/500

Epoch 00033: val_loss improved from 6.57151 to 6.44419, saving model to /users/apokkunu/trial/text/output6/weights.33-6.44.h5
414113/414113 - 1057s - loss: 8.1736 - kl_loss: 1.7197 - val_loss: 6.4442 - val_kl_loss: 1.6788
Epoch 34/500

Epoch 00034: val_loss improved from 6.44419 to 6.31145, saving model to /users/apokkunu/trial/text/output6/weights.34-6.31.h5
414113/414113 - 1057s - loss: 7.9909 - kl_loss: 1.7199 - val_loss: 6.3115 - val_kl_loss: 1.6752
Epoch 35/500

Epoch 00035: val_loss improved from 6.31145 to 6.13379, saving model to /users/apokkunu/trial/text/output6/weights.35-6.13.h5
414113/414113 - 1056s - loss: 7.8151 - kl_loss: 1.7199 - val_loss: 6.1338 - val_kl_loss: 1.6700
Epoch 36/500

Epoch 00036: val_loss improved from 6.13379 to 6.00850, saving model to /users/apokkunu/trial/text/output6/weights.36-6.01.h5
414113/414113 - 1056s - loss: 7.6642 - kl_loss: 1.7198 - val_loss: 6.0085 - val_kl_loss: 1.6529
Epoch 37/500

Epoch 00037: val_loss improved from 6.00850 to 5.89534, saving model to /users/apokkunu/trial/text/output6/weights.37-5.90.h5
414113/414113 - 1058s - loss: 7.4985 - kl_loss: 1.7155 - val_loss: 5.8953 - val_kl_loss: 1.6601
Epoch 38/500

Epoch 00038: val_loss improved from 5.89534 to 5.83661, saving model to /users/apokkunu/trial/text/output6/weights.38-5.84.h5
414113/414113 - 1057s - loss: 7.3515 - kl_loss: 1.7179 - val_loss: 5.8366 - val_kl_loss: 1.6788
Epoch 39/500

Epoch 00039: val_loss improved from 5.83661 to 5.67774, saving model to /users/apokkunu/trial/text/output6/weights.39-5.68.h5
414113/414113 - 1058s - loss: 7.2105 - kl_loss: 1.7162 - val_loss: 5.6777 - val_kl_loss: 1.6736
Epoch 40/500

Epoch 00040: val_loss improved from 5.67774 to 5.55534, saving model to /users/apokkunu/trial/text/output6/weights.40-5.56.h5
414113/414113 - 1053s - loss: 7.0771 - kl_loss: 1.7147 - val_loss: 5.5553 - val_kl_loss: 1.6466
Epoch 41/500

Epoch 00041: val_loss improved from 5.55534 to 5.50382, saving model to /users/apokkunu/trial/text/output6/weights.41-5.50.h5
414113/414113 - 1055s - loss: 6.9553 - kl_loss: 1.7139 - val_loss: 5.5038 - val_kl_loss: 1.6817
Epoch 42/500

Epoch 00042: val_loss improved from 5.50382 to 5.40552, saving model to /users/apokkunu/trial/text/output6/weights.42-5.41.h5
414113/414113 - 1056s - loss: 6.8311 - kl_loss: 1.7119 - val_loss: 5.4055 - val_kl_loss: 1.6702
Epoch 43/500

Epoch 00043: val_loss improved from 5.40552 to 5.31969, saving model to /users/apokkunu/trial/text/output6/weights.43-5.32.h5
414113/414113 - 1057s - loss: 6.7209 - kl_loss: 1.7139 - val_loss: 5.3197 - val_kl_loss: 1.6794
Epoch 44/500

Epoch 00044: val_loss improved from 5.31969 to 5.23677, saving model to /users/apokkunu/trial/text/output6/weights.44-5.24.h5
414113/414113 - 1054s - loss: 6.6124 - kl_loss: 1.7130 - val_loss: 5.2368 - val_kl_loss: 1.6517
Epoch 45/500

Epoch 00045: val_loss improved from 5.23677 to 5.12916, saving model to /users/apokkunu/trial/text/output6/weights.45-5.13.h5
414113/414113 - 1056s - loss: 6.5080 - kl_loss: 1.7093 - val_loss: 5.1292 - val_kl_loss: 1.6631
Epoch 46/500

Epoch 00046: val_loss improved from 5.12916 to 5.05390, saving model to /users/apokkunu/trial/text/output6/weights.46-5.05.h5
414113/414113 - 1057s - loss: 6.4052 - kl_loss: 1.7088 - val_loss: 5.0539 - val_kl_loss: 1.6564
Epoch 47/500

Epoch 00047: val_loss improved from 5.05390 to 5.01413, saving model to /users/apokkunu/trial/text/output6/weights.47-5.01.h5
414113/414113 - 1058s - loss: 6.3153 - kl_loss: 1.7091 - val_loss: 5.0141 - val_kl_loss: 1.6517
Epoch 48/500

Epoch 00048: val_loss improved from 5.01413 to 4.92738, saving model to /users/apokkunu/trial/text/output6/weights.48-4.93.h5
414113/414113 - 1057s - loss: 6.2246 - kl_loss: 1.7068 - val_loss: 4.9274 - val_kl_loss: 1.6614
Epoch 49/500

Epoch 00049: val_loss improved from 4.92738 to 4.85656, saving model to /users/apokkunu/trial/text/output6/weights.49-4.86.h5
414113/414113 - 1057s - loss: 6.1322 - kl_loss: 1.7054 - val_loss: 4.8566 - val_kl_loss: 1.6536
Epoch 50/500

Epoch 00050: val_loss improved from 4.85656 to 4.79578, saving model to /users/apokkunu/trial/text/output6/weights.50-4.80.h5
414113/414113 - 1055s - loss: 6.0420 - kl_loss: 1.7059 - val_loss: 4.7958 - val_kl_loss: 1.6353
Epoch 51/500

Epoch 00051: val_loss improved from 4.79578 to 4.72999, saving model to /users/apokkunu/trial/text/output6/weights.51-4.73.h5
414113/414113 - 1056s - loss: 5.9740 - kl_loss: 1.7043 - val_loss: 4.7300 - val_kl_loss: 1.6341
Epoch 52/500

Epoch 00052: val_loss improved from 4.72999 to 4.70449, saving model to /users/apokkunu/trial/text/output6/weights.52-4.70.h5
414113/414113 - 1055s - loss: 5.8837 - kl_loss: 1.7007 - val_loss: 4.7045 - val_kl_loss: 1.6735
Epoch 53/500

Epoch 00053: val_loss improved from 4.70449 to 4.64526, saving model to /users/apokkunu/trial/text/output6/weights.53-4.65.h5
414113/414113 - 1055s - loss: 5.8147 - kl_loss: 1.7016 - val_loss: 4.6453 - val_kl_loss: 1.6663
Epoch 54/500

Epoch 00054: val_loss improved from 4.64526 to 4.56917, saving model to /users/apokkunu/trial/text/output6/weights.54-4.57.h5
414113/414113 - 1056s - loss: 5.7453 - kl_loss: 1.6989 - val_loss: 4.5692 - val_kl_loss: 1.6350
Epoch 55/500

Epoch 00055: val_loss improved from 4.56917 to 4.54152, saving model to /users/apokkunu/trial/text/output6/weights.55-4.54.h5
414113/414113 - 1055s - loss: 5.6741 - kl_loss: 1.6988 - val_loss: 4.5415 - val_kl_loss: 1.6382
Epoch 56/500

Epoch 00056: val_loss improved from 4.54152 to 4.48953, saving model to /users/apokkunu/trial/text/output6/weights.56-4.49.h5
414113/414113 - 1056s - loss: 5.6078 - kl_loss: 1.6959 - val_loss: 4.4895 - val_kl_loss: 1.6372
Epoch 57/500

Epoch 00057: val_loss improved from 4.48953 to 4.45349, saving model to /users/apokkunu/trial/text/output6/weights.57-4.45.h5
414113/414113 - 1058s - loss: 5.5455 - kl_loss: 1.6922 - val_loss: 4.4535 - val_kl_loss: 1.6482
Epoch 58/500

Epoch 00058: val_loss improved from 4.45349 to 4.40806, saving model to /users/apokkunu/trial/text/output6/weights.58-4.41.h5
414113/414113 - 1055s - loss: 5.4842 - kl_loss: 1.6918 - val_loss: 4.4081 - val_kl_loss: 1.6303
Epoch 59/500

Epoch 00059: val_loss improved from 4.40806 to 4.35075, saving model to /users/apokkunu/trial/text/output6/weights.59-4.35.h5
414113/414113 - 1057s - loss: 5.4362 - kl_loss: 1.6917 - val_loss: 4.3508 - val_kl_loss: 1.6253
Epoch 60/500

Epoch 00060: val_loss improved from 4.35075 to 4.33313, saving model to /users/apokkunu/trial/text/output6/weights.60-4.33.h5
414113/414113 - 1058s - loss: 5.3701 - kl_loss: 1.6882 - val_loss: 4.3331 - val_kl_loss: 1.6385
Epoch 61/500

Epoch 00061: val_loss improved from 4.33313 to 4.29048, saving model to /users/apokkunu/trial/text/output6/weights.61-4.29.h5
414113/414113 - 1056s - loss: 5.3234 - kl_loss: 1.6872 - val_loss: 4.2905 - val_kl_loss: 1.6193
Epoch 62/500

Epoch 00062: val_loss improved from 4.29048 to 4.23316, saving model to /users/apokkunu/trial/text/output6/weights.62-4.23.h5
414113/414113 - 1057s - loss: 5.2681 - kl_loss: 1.6858 - val_loss: 4.2332 - val_kl_loss: 1.6039
Epoch 63/500

Epoch 00063: val_loss improved from 4.23316 to 4.20541, saving model to /users/apokkunu/trial/text/output6/weights.63-4.21.h5
414113/414113 - 1056s - loss: 5.2231 - kl_loss: 1.6859 - val_loss: 4.2054 - val_kl_loss: 1.6097
Epoch 64/500

Epoch 00064: val_loss improved from 4.20541 to 4.18243, saving model to /users/apokkunu/trial/text/output6/weights.64-4.18.h5
414113/414113 - 1054s - loss: 5.1729 - kl_loss: 1.6816 - val_loss: 4.1824 - val_kl_loss: 1.6172
Epoch 65/500

Epoch 00065: val_loss improved from 4.18243 to 4.16131, saving model to /users/apokkunu/trial/text/output6/weights.65-4.16.h5
414113/414113 - 1055s - loss: 5.1191 - kl_loss: 1.6813 - val_loss: 4.1613 - val_kl_loss: 1.6202
Epoch 66/500

Epoch 00066: val_loss improved from 4.16131 to 4.11654, saving model to /users/apokkunu/trial/text/output6/weights.66-4.12.h5
414113/414113 - 1056s - loss: 5.0831 - kl_loss: 1.6793 - val_loss: 4.1165 - val_kl_loss: 1.6191
Epoch 67/500

Epoch 00067: val_loss improved from 4.11654 to 4.10326, saving model to /users/apokkunu/trial/text/output6/weights.67-4.10.h5
414113/414113 - 1055s - loss: 5.0319 - kl_loss: 1.6776 - val_loss: 4.1033 - val_kl_loss: 1.6246
Epoch 68/500

Epoch 00068: val_loss improved from 4.10326 to 4.05903, saving model to /users/apokkunu/trial/text/output6/weights.68-4.06.h5
414113/414113 - 1056s - loss: 4.9933 - kl_loss: 1.6755 - val_loss: 4.0590 - val_kl_loss: 1.6159
Epoch 69/500

Epoch 00069: val_loss improved from 4.05903 to 4.03347, saving model to /users/apokkunu/trial/text/output6/weights.69-4.03.h5
414113/414113 - 1054s - loss: 4.9534 - kl_loss: 1.6756 - val_loss: 4.0335 - val_kl_loss: 1.6072
Epoch 70/500

Epoch 00070: val_loss improved from 4.03347 to 4.01104, saving model to /users/apokkunu/trial/text/output6/weights.70-4.01.h5
414113/414113 - 1058s - loss: 4.9121 - kl_loss: 1.6728 - val_loss: 4.0110 - val_kl_loss: 1.6058
Epoch 71/500

Epoch 00071: val_loss improved from 4.01104 to 3.98001, saving model to /users/apokkunu/trial/text/output6/weights.71-3.98.h5
414113/414113 - 1056s - loss: 4.8747 - kl_loss: 1.6722 - val_loss: 3.9800 - val_kl_loss: 1.5958
Epoch 72/500

Epoch 00072: val_loss improved from 3.98001 to 3.95754, saving model to /users/apokkunu/trial/text/output6/weights.72-3.96.h5
414113/414113 - 1059s - loss: 4.8365 - kl_loss: 1.6686 - val_loss: 3.9575 - val_kl_loss: 1.6010
Epoch 73/500

Epoch 00073: val_loss improved from 3.95754 to 3.95134, saving model to /users/apokkunu/trial/text/output6/weights.73-3.95.h5
414113/414113 - 1058s - loss: 4.8059 - kl_loss: 1.6691 - val_loss: 3.9513 - val_kl_loss: 1.5951
Epoch 74/500

Epoch 00074: val_loss improved from 3.95134 to 3.90790, saving model to /users/apokkunu/trial/text/output6/weights.74-3.91.h5
414113/414113 - 1060s - loss: 4.7694 - kl_loss: 1.6679 - val_loss: 3.9079 - val_kl_loss: 1.6028
Epoch 75/500

Epoch 00075: val_loss did not improve from 3.90790
414113/414113 - 1055s - loss: 4.7293 - kl_loss: 1.6641 - val_loss: 3.9502 - val_kl_loss: 1.6238
Epoch 76/500

Epoch 00076: val_loss improved from 3.90790 to 3.90106, saving model to /users/apokkunu/trial/text/output6/weights.76-3.90.h5
414113/414113 - 1056s - loss: 4.7077 - kl_loss: 1.6669 - val_loss: 3.9011 - val_kl_loss: 1.5971
Epoch 77/500

Epoch 00077: val_loss improved from 3.90106 to 3.85783, saving model to /users/apokkunu/trial/text/output6/weights.77-3.86.h5
414113/414113 - 1059s - loss: 4.6627 - kl_loss: 1.6621 - val_loss: 3.8578 - val_kl_loss: 1.5917
Epoch 78/500

Epoch 00078: val_loss improved from 3.85783 to 3.84156, saving model to /users/apokkunu/trial/text/output6/weights.78-3.84.h5
414113/414113 - 1055s - loss: 4.6355 - kl_loss: 1.6632 - val_loss: 3.8416 - val_kl_loss: 1.5931
Epoch 79/500

Epoch 00079: val_loss improved from 3.84156 to 3.81330, saving model to /users/apokkunu/trial/text/output6/weights.79-3.81.h5
414113/414113 - 1058s - loss: 4.6084 - kl_loss: 1.6605 - val_loss: 3.8133 - val_kl_loss: 1.5967
Epoch 80/500

Epoch 00080: val_loss improved from 3.81330 to 3.80229, saving model to /users/apokkunu/trial/text/output6/weights.80-3.80.h5
414113/414113 - 1056s - loss: 4.5778 - kl_loss: 1.6582 - val_loss: 3.8023 - val_kl_loss: 1.5886
Epoch 81/500

Epoch 00081: val_loss improved from 3.80229 to 3.79371, saving model to /users/apokkunu/trial/text/output6/weights.81-3.79.h5
414113/414113 - 1057s - loss: 4.5464 - kl_loss: 1.6577 - val_loss: 3.7937 - val_kl_loss: 1.6079
Epoch 82/500

Epoch 00082: val_loss improved from 3.79371 to 3.76262, saving model to /users/apokkunu/trial/text/output6/weights.82-3.76.h5
414113/414113 - 1056s - loss: 4.5140 - kl_loss: 1.6573 - val_loss: 3.7626 - val_kl_loss: 1.5902
Epoch 83/500

Epoch 00083: val_loss did not improve from 3.76262
414113/414113 - 1058s - loss: 4.4906 - kl_loss: 1.6553 - val_loss: 3.7933 - val_kl_loss: 1.6096
Epoch 84/500

Epoch 00084: val_loss improved from 3.76262 to 3.74001, saving model to /users/apokkunu/trial/text/output6/weights.84-3.74.h5
414113/414113 - 1056s - loss: 4.4702 - kl_loss: 1.6553 - val_loss: 3.7400 - val_kl_loss: 1.5960
Epoch 85/500

Epoch 00085: val_loss improved from 3.74001 to 3.73392, saving model to /users/apokkunu/trial/text/output6/weights.85-3.73.h5
414113/414113 - 1056s - loss: 4.4409 - kl_loss: 1.6553 - val_loss: 3.7339 - val_kl_loss: 1.5835
Epoch 86/500

Epoch 00086: val_loss improved from 3.73392 to 3.70673, saving model to /users/apokkunu/trial/text/output6/weights.86-3.71.h5
414113/414113 - 1054s - loss: 4.4193 - kl_loss: 1.6520 - val_loss: 3.7067 - val_kl_loss: 1.5954
Epoch 87/500

Epoch 00087: val_loss improved from 3.70673 to 3.69441, saving model to /users/apokkunu/trial/text/output6/weights.87-3.69.h5
414113/414113 - 1054s - loss: 4.3963 - kl_loss: 1.6522 - val_loss: 3.6944 - val_kl_loss: 1.5911
Epoch 88/500

Epoch 00088: val_loss improved from 3.69441 to 3.67053, saving model to /users/apokkunu/trial/text/output6/weights.88-3.67.h5
414113/414113 - 1056s - loss: 4.3727 - kl_loss: 1.6491 - val_loss: 3.6705 - val_kl_loss: 1.5885
Epoch 89/500

Epoch 00089: val_loss improved from 3.67053 to 3.65825, saving model to /users/apokkunu/trial/text/output6/weights.89-3.66.h5
414113/414113 - 1057s - loss: 4.3490 - kl_loss: 1.6487 - val_loss: 3.6583 - val_kl_loss: 1.5714
Epoch 90/500

Epoch 00090: val_loss improved from 3.65825 to 3.65089, saving model to /users/apokkunu/trial/text/output6/weights.90-3.65.h5
414113/414113 - 1057s - loss: 4.3201 - kl_loss: 1.6485 - val_loss: 3.6509 - val_kl_loss: 1.5898
Epoch 91/500

Epoch 00091: val_loss did not improve from 3.65089
414113/414113 - 1056s - loss: 4.3043 - kl_loss: 1.6466 - val_loss: 3.6706 - val_kl_loss: 1.6059
Epoch 92/500

Epoch 00092: val_loss improved from 3.65089 to 3.61377, saving model to /users/apokkunu/trial/text/output6/weights.92-3.61.h5
414113/414113 - 1056s - loss: 4.2795 - kl_loss: 1.6452 - val_loss: 3.6138 - val_kl_loss: 1.5778
Epoch 93/500

Epoch 00093: val_loss did not improve from 3.61377
414113/414113 - 1057s - loss: 4.2515 - kl_loss: 1.6445 - val_loss: 3.6185 - val_kl_loss: 1.5900
Epoch 94/500

Epoch 00094: val_loss improved from 3.61377 to 3.60283, saving model to /users/apokkunu/trial/text/output6/weights.94-3.60.h5
414113/414113 - 1058s - loss: 4.2381 - kl_loss: 1.6432 - val_loss: 3.6028 - val_kl_loss: 1.5896
Epoch 95/500

Epoch 00095: val_loss improved from 3.60283 to 3.58986, saving model to /users/apokkunu/trial/text/output6/weights.95-3.59.h5
414113/414113 - 1056s - loss: 4.2264 - kl_loss: 1.6441 - val_loss: 3.5899 - val_kl_loss: 1.5787
Epoch 96/500

Epoch 00096: val_loss improved from 3.58986 to 3.58435, saving model to /users/apokkunu/trial/text/output6/weights.96-3.58.h5
414113/414113 - 1056s - loss: 4.1956 - kl_loss: 1.6404 - val_loss: 3.5843 - val_kl_loss: 1.5994
Epoch 97/500

Epoch 00097: val_loss did not improve from 3.58435
414113/414113 - 1057s - loss: 4.1690 - kl_loss: 1.6406 - val_loss: 3.5861 - val_kl_loss: 1.5973
Epoch 98/500

Epoch 00098: val_loss improved from 3.58435 to 3.55063, saving model to /users/apokkunu/trial/text/output6/weights.98-3.55.h5
414113/414113 - 1056s - loss: 4.1637 - kl_loss: 1.6395 - val_loss: 3.5506 - val_kl_loss: 1.5601
Epoch 99/500

Epoch 00099: val_loss did not improve from 3.55063
414113/414113 - 1058s - loss: 4.1380 - kl_loss: 1.6377 - val_loss: 3.5564 - val_kl_loss: 1.5857
Epoch 100/500

Epoch 00100: val_loss improved from 3.55063 to 3.54466, saving model to /users/apokkunu/trial/text/output6/weights.100-3.54.h5
414113/414113 - 1056s - loss: 4.1232 - kl_loss: 1.6397 - val_loss: 3.5447 - val_kl_loss: 1.5815
Epoch 101/500

Epoch 00101: val_loss improved from 3.54466 to 3.52907, saving model to /users/apokkunu/trial/text/output6/weights.101-3.53.h5
414113/414113 - 1058s - loss: 4.1051 - kl_loss: 1.6366 - val_loss: 3.5291 - val_kl_loss: 1.6010
Epoch 102/500

Epoch 00102: val_loss improved from 3.52907 to 3.50837, saving model to /users/apokkunu/trial/text/output6/weights.102-3.51.h5
414113/414113 - 1055s - loss: 4.0949 - kl_loss: 1.6382 - val_loss: 3.5084 - val_kl_loss: 1.5673
Epoch 103/500

Epoch 00103: val_loss improved from 3.50837 to 3.50170, saving model to /users/apokkunu/trial/text/output6/weights.103-3.50.h5
414113/414113 - 1056s - loss: 4.0711 - kl_loss: 1.6347 - val_loss: 3.5017 - val_kl_loss: 1.5717
Epoch 104/500

Epoch 00104: val_loss improved from 3.50170 to 3.47740, saving model to /users/apokkunu/trial/text/output6/weights.104-3.48.h5
414113/414113 - 1057s - loss: 4.0513 - kl_loss: 1.6357 - val_loss: 3.4774 - val_kl_loss: 1.5539
Epoch 105/500

Epoch 00105: val_loss did not improve from 3.47740
414113/414113 - 1058s - loss: 4.0327 - kl_loss: 1.6321 - val_loss: 3.4860 - val_kl_loss: 1.5729
Epoch 106/500

Epoch 00106: val_loss improved from 3.47740 to 3.46153, saving model to /users/apokkunu/trial/text/output6/weights.106-3.46.h5
414113/414113 - 1058s - loss: 4.0215 - kl_loss: 1.6337 - val_loss: 3.4615 - val_kl_loss: 1.5607
Epoch 107/500

Epoch 00107: val_loss did not improve from 3.46153
414113/414113 - 1057s - loss: 4.0095 - kl_loss: 1.6337 - val_loss: 3.4741 - val_kl_loss: 1.5693
Epoch 108/500

Epoch 00108: val_loss did not improve from 3.46153
414113/414113 - 1056s - loss: 3.9958 - kl_loss: 1.6302 - val_loss: 3.4718 - val_kl_loss: 1.5820
Epoch 109/500

Epoch 00109: val_loss did not improve from 3.46153
414113/414113 - 1057s - loss: 3.9719 - kl_loss: 1.6285 - val_loss: 3.4741 - val_kl_loss: 1.6065
Epoch 110/500

Epoch 00110: val_loss improved from 3.46153 to 3.43740, saving model to /users/apokkunu/trial/text/output6/weights.110-3.44.h5
414113/414113 - 1056s - loss: 3.9630 - kl_loss: 1.6312 - val_loss: 3.4374 - val_kl_loss: 1.5490
Epoch 111/500

Epoch 00111: val_loss improved from 3.43740 to 3.41313, saving model to /users/apokkunu/trial/text/output6/weights.111-3.41.h5
414113/414113 - 1058s - loss: 3.9483 - kl_loss: 1.6295 - val_loss: 3.4131 - val_kl_loss: 1.5552
Epoch 112/500

Epoch 00112: val_loss did not improve from 3.41313
414113/414113 - 1055s - loss: 3.9294 - kl_loss: 1.6269 - val_loss: 3.4310 - val_kl_loss: 1.5653
Epoch 113/500

Epoch 00113: val_loss did not improve from 3.41313
414113/414113 - 1056s - loss: 3.9213 - kl_loss: 1.6263 - val_loss: 3.4235 - val_kl_loss: 1.5664
Epoch 114/500

Epoch 00114: val_loss improved from 3.41313 to 3.40086, saving model to /users/apokkunu/trial/text/output6/weights.114-3.40.h5
414113/414113 - 1054s - loss: 3.9080 - kl_loss: 1.6272 - val_loss: 3.4009 - val_kl_loss: 1.5626
Epoch 115/500

Epoch 00115: val_loss improved from 3.40086 to 3.39071, saving model to /users/apokkunu/trial/text/output6/weights.115-3.39.h5
414113/414113 - 1056s - loss: 3.8927 - kl_loss: 1.6255 - val_loss: 3.3907 - val_kl_loss: 1.5356
Epoch 116/500

Epoch 00116: val_loss improved from 3.39071 to 3.38318, saving model to /users/apokkunu/trial/text/output6/weights.116-3.38.h5
414113/414113 - 1056s - loss: 3.8782 - kl_loss: 1.6233 - val_loss: 3.3832 - val_kl_loss: 1.5587
Epoch 117/500

Epoch 00117: val_loss did not improve from 3.38318
414113/414113 - 1054s - loss: 3.8638 - kl_loss: 1.6229 - val_loss: 3.3879 - val_kl_loss: 1.5618
Epoch 118/500

Epoch 00118: val_loss did not improve from 3.38318
414113/414113 - 1054s - loss: 3.8507 - kl_loss: 1.6222 - val_loss: 3.3917 - val_kl_loss: 1.5601
Epoch 119/500

Epoch 00119: val_loss did not improve from 3.38318
414113/414113 - 1054s - loss: 3.8397 - kl_loss: 1.6228 - val_loss: 3.3911 - val_kl_loss: 1.5561
Epoch 120/500

Epoch 00120: val_loss improved from 3.38318 to 3.36818, saving model to /users/apokkunu/trial/text/output6/weights.120-3.37.h5
414113/414113 - 1054s - loss: 3.8306 - kl_loss: 1.6226 - val_loss: 3.3682 - val_kl_loss: 1.5682
Epoch 121/500

Epoch 00121: val_loss did not improve from 3.36818
414113/414113 - 1054s - loss: 3.8164 - kl_loss: 1.6203 - val_loss: 3.3763 - val_kl_loss: 1.5627
Epoch 122/500

Epoch 00122: val_loss improved from 3.36818 to 3.35672, saving model to /users/apokkunu/trial/text/output6/weights.122-3.36.h5
414113/414113 - 1055s - loss: 3.8033 - kl_loss: 1.6197 - val_loss: 3.3567 - val_kl_loss: 1.5619
Epoch 123/500

Epoch 00123: val_loss improved from 3.35672 to 3.34365, saving model to /users/apokkunu/trial/text/output6/weights.123-3.34.h5
414113/414113 - 1056s - loss: 3.7971 - kl_loss: 1.6199 - val_loss: 3.3437 - val_kl_loss: 1.5497
Epoch 124/500

Epoch 00124: val_loss improved from 3.34365 to 3.34197, saving model to /users/apokkunu/trial/text/output6/weights.124-3.34.h5
414113/414113 - 1057s - loss: 3.7852 - kl_loss: 1.6177 - val_loss: 3.3420 - val_kl_loss: 1.5448
Epoch 125/500

Epoch 00125: val_loss improved from 3.34197 to 3.33667, saving model to /users/apokkunu/trial/text/output6/weights.125-3.34.h5
414113/414113 - 1058s - loss: 3.7730 - kl_loss: 1.6191 - val_loss: 3.3367 - val_kl_loss: 1.5485
Epoch 126/500

Epoch 00126: val_loss improved from 3.33667 to 3.32895, saving model to /users/apokkunu/trial/text/output6/weights.126-3.33.h5
414113/414113 - 1058s - loss: 3.7524 - kl_loss: 1.6157 - val_loss: 3.3290 - val_kl_loss: 1.5595
Epoch 127/500

Epoch 00127: val_loss did not improve from 3.32895
414113/414113 - 1055s - loss: 3.7486 - kl_loss: 1.6164 - val_loss: 3.3412 - val_kl_loss: 1.5689
Epoch 128/500

Epoch 00128: val_loss improved from 3.32895 to 3.31283, saving model to /users/apokkunu/trial/text/output6/weights.128-3.31.h5
414113/414113 - 1057s - loss: 3.7353 - kl_loss: 1.6139 - val_loss: 3.3128 - val_kl_loss: 1.5451
Epoch 129/500

Epoch 00129: val_loss improved from 3.31283 to 3.30524, saving model to /users/apokkunu/trial/text/output6/weights.129-3.31.h5
414113/414113 - 1054s - loss: 3.7231 - kl_loss: 1.6146 - val_loss: 3.3052 - val_kl_loss: 1.5362
Epoch 130/500

Epoch 00130: val_loss improved from 3.30524 to 3.28452, saving model to /users/apokkunu/trial/text/output6/weights.130-3.28.h5
414113/414113 - 1054s - loss: 3.7147 - kl_loss: 1.6129 - val_loss: 3.2845 - val_kl_loss: 1.5264
Epoch 131/500

Epoch 00131: val_loss did not improve from 3.28452
414113/414113 - 1055s - loss: 3.7078 - kl_loss: 1.6127 - val_loss: 3.2957 - val_kl_loss: 1.5273
Epoch 132/500

Epoch 00132: val_loss did not improve from 3.28452
414113/414113 - 1056s - loss: 3.6904 - kl_loss: 1.6110 - val_loss: 3.3026 - val_kl_loss: 1.5458
Epoch 133/500

Epoch 00133: val_loss did not improve from 3.28452
414113/414113 - 1054s - loss: 3.6879 - kl_loss: 1.6124 - val_loss: 3.3028 - val_kl_loss: 1.5536
Epoch 134/500

Epoch 00134: val_loss did not improve from 3.28452
414113/414113 - 1057s - loss: 3.6744 - kl_loss: 1.6125 - val_loss: 3.2962 - val_kl_loss: 1.5593
Epoch 135/500

Epoch 00135: val_loss did not improve from 3.28452
414113/414113 - 1055s - loss: 3.6693 - kl_loss: 1.6096 - val_loss: 3.2879 - val_kl_loss: 1.5642
Epoch 136/500

Epoch 00136: val_loss improved from 3.28452 to 3.27633, saving model to /users/apokkunu/trial/text/output6/weights.136-3.28.h5
414113/414113 - 1055s - loss: 3.6558 - kl_loss: 1.6091 - val_loss: 3.2763 - val_kl_loss: 1.5426
Epoch 137/500

Epoch 00137: val_loss improved from 3.27633 to 3.25600, saving model to /users/apokkunu/trial/text/output6/weights.137-3.26.h5
414113/414113 - 1056s - loss: 3.6491 - kl_loss: 1.6085 - val_loss: 3.2560 - val_kl_loss: 1.5324
Epoch 138/500

Epoch 00138: val_loss did not improve from 3.25600
414113/414113 - 1056s - loss: 3.6410 - kl_loss: 1.6080 - val_loss: 3.2798 - val_kl_loss: 1.5596
Epoch 139/500

Epoch 00139: val_loss improved from 3.25600 to 3.24888, saving model to /users/apokkunu/trial/text/output6/weights.139-3.25.h5
414113/414113 - 1054s - loss: 3.6270 - kl_loss: 1.6078 - val_loss: 3.2489 - val_kl_loss: 1.5394
Epoch 140/500

Epoch 00140: val_loss did not improve from 3.24888
414113/414113 - 1056s - loss: 3.6198 - kl_loss: 1.6072 - val_loss: 3.2643 - val_kl_loss: 1.5525
Epoch 141/500

Epoch 00141: val_loss did not improve from 3.24888
414113/414113 - 1055s - loss: 3.6090 - kl_loss: 1.6063 - val_loss: 3.2496 - val_kl_loss: 1.5492
Epoch 142/500

Epoch 00142: val_loss improved from 3.24888 to 3.23991, saving model to /users/apokkunu/trial/text/output6/weights.142-3.24.h5
414113/414113 - 1057s - loss: 3.6010 - kl_loss: 1.6046 - val_loss: 3.2399 - val_kl_loss: 1.5308
Epoch 143/500

Epoch 00143: val_loss improved from 3.23991 to 3.23761, saving model to /users/apokkunu/trial/text/output6/weights.143-3.24.h5
414113/414113 - 1053s - loss: 3.5964 - kl_loss: 1.6043 - val_loss: 3.2376 - val_kl_loss: 1.5433
Epoch 144/500

Epoch 00144: val_loss did not improve from 3.23761
414113/414113 - 1055s - loss: 3.5867 - kl_loss: 1.6030 - val_loss: 3.2420 - val_kl_loss: 1.5463
Epoch 145/500

Epoch 00145: val_loss improved from 3.23761 to 3.22733, saving model to /users/apokkunu/trial/text/output6/weights.145-3.23.h5
414113/414113 - 1057s - loss: 3.5730 - kl_loss: 1.6019 - val_loss: 3.2273 - val_kl_loss: 1.5298
Epoch 146/500

Epoch 00146: val_loss did not improve from 3.22733
414113/414113 - 1056s - loss: 3.5617 - kl_loss: 1.6004 - val_loss: 3.2389 - val_kl_loss: 1.5362
Epoch 147/500

Epoch 00147: val_loss did not improve from 3.22733
414113/414113 - 1057s - loss: 3.5581 - kl_loss: 1.6001 - val_loss: 3.2388 - val_kl_loss: 1.5534
Epoch 148/500

Epoch 00148: val_loss improved from 3.22733 to 3.21247, saving model to /users/apokkunu/trial/text/output6/weights.148-3.21.h5
414113/414113 - 1054s - loss: 3.5481 - kl_loss: 1.6000 - val_loss: 3.2125 - val_kl_loss: 1.5298
Epoch 149/500

Epoch 00149: val_loss did not improve from 3.21247
414113/414113 - 1056s - loss: 3.5453 - kl_loss: 1.6001 - val_loss: 3.2187 - val_kl_loss: 1.5478
Epoch 150/500

Epoch 00150: val_loss improved from 3.21247 to 3.20465, saving model to /users/apokkunu/trial/text/output6/weights.150-3.20.h5
414113/414113 - 1055s - loss: 3.5422 - kl_loss: 1.6005 - val_loss: 3.2046 - val_kl_loss: 1.5158
Epoch 151/500

Epoch 00151: val_loss did not improve from 3.20465
414113/414113 - 1055s - loss: 3.5276 - kl_loss: 1.5973 - val_loss: 3.2199 - val_kl_loss: 1.5525
Epoch 152/500

Epoch 00152: val_loss did not improve from 3.20465
414113/414113 - 1057s - loss: 3.5262 - kl_loss: 1.5983 - val_loss: 3.2282 - val_kl_loss: 1.5510
Epoch 153/500

Epoch 00153: val_loss improved from 3.20465 to 3.19241, saving model to /users/apokkunu/trial/text/output6/weights.153-3.19.h5
414113/414113 - 1056s - loss: 3.5117 - kl_loss: 1.5982 - val_loss: 3.1924 - val_kl_loss: 1.5270
Epoch 154/500

Epoch 00154: val_loss did not improve from 3.19241
414113/414113 - 1054s - loss: 3.5046 - kl_loss: 1.5961 - val_loss: 3.1979 - val_kl_loss: 1.5265
Epoch 155/500

Epoch 00155: val_loss improved from 3.19241 to 3.18927, saving model to /users/apokkunu/trial/text/output6/weights.155-3.19.h5
414113/414113 - 1055s - loss: 3.4934 - kl_loss: 1.5954 - val_loss: 3.1893 - val_kl_loss: 1.5361
Epoch 156/500

Epoch 00156: val_loss did not improve from 3.18927
414113/414113 - 1058s - loss: 3.4885 - kl_loss: 1.5953 - val_loss: 3.1991 - val_kl_loss: 1.5323
Epoch 157/500

Epoch 00157: val_loss improved from 3.18927 to 3.17587, saving model to /users/apokkunu/trial/text/output6/weights.157-3.18.h5
414113/414113 - 1056s - loss: 3.4800 - kl_loss: 1.5947 - val_loss: 3.1759 - val_kl_loss: 1.5216
Epoch 158/500

Epoch 00158: val_loss improved from 3.17587 to 3.17158, saving model to /users/apokkunu/trial/text/output6/weights.158-3.17.h5
414113/414113 - 1057s - loss: 3.4705 - kl_loss: 1.5922 - val_loss: 3.1716 - val_kl_loss: 1.5264
Epoch 159/500

Epoch 00159: val_loss did not improve from 3.17158
414113/414113 - 1054s - loss: 3.4666 - kl_loss: 1.5935 - val_loss: 3.1774 - val_kl_loss: 1.5297
Epoch 160/500

Epoch 00160: val_loss did not improve from 3.17158
414113/414113 - 1055s - loss: 3.4592 - kl_loss: 1.5930 - val_loss: 3.1804 - val_kl_loss: 1.5179
Epoch 161/500

Epoch 00161: val_loss improved from 3.17158 to 3.16588, saving model to /users/apokkunu/trial/text/output6/weights.161-3.17.h5
414113/414113 - 1054s - loss: 3.4590 - kl_loss: 1.5917 - val_loss: 3.1659 - val_kl_loss: 1.5218
Epoch 162/500

Epoch 00162: val_loss did not improve from 3.16588
414113/414113 - 1054s - loss: 3.4418 - kl_loss: 1.5894 - val_loss: 3.1774 - val_kl_loss: 1.5402
Epoch 163/500

Epoch 00163: val_loss did not improve from 3.16588
414113/414113 - 1057s - loss: 3.4325 - kl_loss: 1.5898 - val_loss: 3.1794 - val_kl_loss: 1.5502
Epoch 164/500

Epoch 00164: val_loss improved from 3.16588 to 3.15628, saving model to /users/apokkunu/trial/text/output6/weights.164-3.16.h5
414113/414113 - 1054s - loss: 3.4308 - kl_loss: 1.5883 - val_loss: 3.1563 - val_kl_loss: 1.5225
Epoch 165/500

Epoch 00165: val_loss improved from 3.15628 to 3.15430, saving model to /users/apokkunu/trial/text/output6/weights.165-3.15.h5
414113/414113 - 1058s - loss: 3.4235 - kl_loss: 1.5885 - val_loss: 3.1543 - val_kl_loss: 1.5268
Epoch 166/500

Epoch 00166: val_loss improved from 3.15430 to 3.14167, saving model to /users/apokkunu/trial/text/output6/weights.166-3.14.h5
414113/414113 - 1057s - loss: 3.4121 - kl_loss: 1.5870 - val_loss: 3.1417 - val_kl_loss: 1.5006
Epoch 167/500

Epoch 00167: val_loss did not improve from 3.14167
414113/414113 - 1056s - loss: 3.4054 - kl_loss: 1.5873 - val_loss: 3.1509 - val_kl_loss: 1.5216
Epoch 168/500

Epoch 00168: val_loss did not improve from 3.14167
414113/414113 - 1056s - loss: 3.4014 - kl_loss: 1.5870 - val_loss: 3.1561 - val_kl_loss: 1.5277
Epoch 169/500

Epoch 00169: val_loss did not improve from 3.14167
414113/414113 - 1055s - loss: 3.3949 - kl_loss: 1.5864 - val_loss: 3.1704 - val_kl_loss: 1.5569
Epoch 170/500

Epoch 00170: val_loss improved from 3.14167 to 3.13724, saving model to /users/apokkunu/trial/text/output6/weights.170-3.14.h5
414113/414113 - 1059s - loss: 3.3900 - kl_loss: 1.5849 - val_loss: 3.1372 - val_kl_loss: 1.5094
Epoch 171/500

Epoch 00171: val_loss improved from 3.13724 to 3.12503, saving model to /users/apokkunu/trial/text/output6/weights.171-3.13.h5
414113/414113 - 1057s - loss: 3.3924 - kl_loss: 1.5858 - val_loss: 3.1250 - val_kl_loss: 1.5100
Epoch 172/500

Epoch 00172: val_loss did not improve from 3.12503
414113/414113 - 1056s - loss: 3.3788 - kl_loss: 1.5824 - val_loss: 3.1374 - val_kl_loss: 1.5153
Epoch 173/500

Epoch 00173: val_loss improved from 3.12503 to 3.11838, saving model to /users/apokkunu/trial/text/output6/weights.173-3.12.h5
414113/414113 - 1056s - loss: 3.3783 - kl_loss: 1.5819 - val_loss: 3.1184 - val_kl_loss: 1.5026
Epoch 174/500

Epoch 00174: val_loss improved from 3.11838 to 3.10875, saving model to /users/apokkunu/trial/text/output6/weights.174-3.11.h5
414113/414113 - 1056s - loss: 3.3675 - kl_loss: 1.5822 - val_loss: 3.1087 - val_kl_loss: 1.5129
Epoch 175/500

Epoch 00175: val_loss did not improve from 3.10875
414113/414113 - 1058s - loss: 3.3628 - kl_loss: 1.5812 - val_loss: 3.1234 - val_kl_loss: 1.5087
Epoch 176/500

Epoch 00176: val_loss did not improve from 3.10875
414113/414113 - 1056s - loss: 3.3593 - kl_loss: 1.5840 - val_loss: 3.1291 - val_kl_loss: 1.5142
Epoch 177/500

Epoch 00177: val_loss did not improve from 3.10875
414113/414113 - 1056s - loss: 3.3466 - kl_loss: 1.5804 - val_loss: 3.1223 - val_kl_loss: 1.5238
Epoch 178/500

Epoch 00178: val_loss did not improve from 3.10875
414113/414113 - 1056s - loss: 3.3443 - kl_loss: 1.5807 - val_loss: 3.1107 - val_kl_loss: 1.5091
Epoch 179/500

Epoch 00179: val_loss did not improve from 3.10875
414113/414113 - 1057s - loss: 3.3359 - kl_loss: 1.5796 - val_loss: 3.1185 - val_kl_loss: 1.5268
Epoch 180/500

Epoch 00180: val_loss did not improve from 3.10875
414113/414113 - 1057s - loss: 3.3312 - kl_loss: 1.5790 - val_loss: 3.1265 - val_kl_loss: 1.5273
Epoch 181/500

Epoch 00181: val_loss did not improve from 3.10875
414113/414113 - 1054s - loss: 3.3272 - kl_loss: 1.5790 - val_loss: 3.1113 - val_kl_loss: 1.5110
Epoch 182/500

Epoch 00182: val_loss did not improve from 3.10875
414113/414113 - 1054s - loss: 3.3214 - kl_loss: 1.5781 - val_loss: 3.1208 - val_kl_loss: 1.5305
Epoch 183/500

Epoch 00183: val_loss improved from 3.10875 to 3.08047, saving model to /users/apokkunu/trial/text/output6/weights.183-3.08.h5
414113/414113 - 1059s - loss: 3.3146 - kl_loss: 1.5761 - val_loss: 3.0805 - val_kl_loss: 1.4856
Epoch 184/500

Epoch 00184: val_loss did not improve from 3.08047
414113/414113 - 1055s - loss: 3.3128 - kl_loss: 1.5781 - val_loss: 3.0924 - val_kl_loss: 1.5162
Epoch 185/500

Epoch 00185: val_loss did not improve from 3.08047
414113/414113 - 1056s - loss: 3.2994 - kl_loss: 1.5762 - val_loss: 3.1088 - val_kl_loss: 1.5265
Epoch 186/500

Epoch 00186: val_loss did not improve from 3.08047
414113/414113 - 1054s - loss: 3.2984 - kl_loss: 1.5754 - val_loss: 3.0845 - val_kl_loss: 1.5027
Epoch 187/500

Epoch 00187: val_loss did not improve from 3.08047
414113/414113 - 1056s - loss: 3.2944 - kl_loss: 1.5758 - val_loss: 3.1015 - val_kl_loss: 1.5179
Epoch 188/500

Epoch 00188: val_loss did not improve from 3.08047
414113/414113 - 1056s - loss: 3.2864 - kl_loss: 1.5737 - val_loss: 3.1050 - val_kl_loss: 1.5210
Epoch 189/500

Epoch 00189: val_loss did not improve from 3.08047
414113/414113 - 1056s - loss: 3.2897 - kl_loss: 1.5734 - val_loss: 3.0928 - val_kl_loss: 1.4903
Epoch 190/500

Epoch 00190: val_loss improved from 3.08047 to 3.07799, saving model to /users/apokkunu/trial/text/output6/weights.190-3.08.h5
414113/414113 - 1058s - loss: 3.2779 - kl_loss: 1.5732 - val_loss: 3.0780 - val_kl_loss: 1.5035
Epoch 191/500

Epoch 00191: val_loss improved from 3.07799 to 3.07081, saving model to /users/apokkunu/trial/text/output6/weights.191-3.07.h5
414113/414113 - 1056s - loss: 3.2740 - kl_loss: 1.5720 - val_loss: 3.0708 - val_kl_loss: 1.4988
Epoch 192/500

Epoch 00192: val_loss did not improve from 3.07081
414113/414113 - 1054s - loss: 3.2749 - kl_loss: 1.5728 - val_loss: 3.0871 - val_kl_loss: 1.5078
Epoch 193/500

Epoch 00193: val_loss did not improve from 3.07081
414113/414113 - 1055s - loss: 3.2600 - kl_loss: 1.5698 - val_loss: 3.0893 - val_kl_loss: 1.5147
Epoch 194/500

Epoch 00194: val_loss did not improve from 3.07081
414113/414113 - 1057s - loss: 3.2578 - kl_loss: 1.5714 - val_loss: 3.0769 - val_kl_loss: 1.4950
Epoch 195/500

Epoch 00195: val_loss did not improve from 3.07081
414113/414113 - 1054s - loss: 3.2573 - kl_loss: 1.5705 - val_loss: 3.0880 - val_kl_loss: 1.5134
Epoch 196/500

Epoch 00196: val_loss did not improve from 3.07081
414113/414113 - 1054s - loss: 3.2508 - kl_loss: 1.5701 - val_loss: 3.0811 - val_kl_loss: 1.5145
Epoch 197/500

Epoch 00197: val_loss did not improve from 3.07081
414113/414113 - 1055s - loss: 3.2450 - kl_loss: 1.5684 - val_loss: 3.0777 - val_kl_loss: 1.5132
Epoch 198/500

Epoch 00198: val_loss improved from 3.07081 to 3.06819, saving model to /users/apokkunu/trial/text/output6/weights.198-3.07.h5
414113/414113 - 1054s - loss: 3.2388 - kl_loss: 1.5672 - val_loss: 3.0682 - val_kl_loss: 1.4998
Epoch 199/500

Epoch 00199: val_loss improved from 3.06819 to 3.06181, saving model to /users/apokkunu/trial/text/output6/weights.199-3.06.h5
414113/414113 - 1055s - loss: 3.2339 - kl_loss: 1.5689 - val_loss: 3.0618 - val_kl_loss: 1.4985
Epoch 200/500

Epoch 00200: val_loss did not improve from 3.06181
414113/414113 - 1054s - loss: 3.2321 - kl_loss: 1.5662 - val_loss: 3.0655 - val_kl_loss: 1.5093
Epoch 201/500

Epoch 00201: val_loss did not improve from 3.06181
414113/414113 - 1056s - loss: 3.2309 - kl_loss: 1.5659 - val_loss: 3.0660 - val_kl_loss: 1.4974
Epoch 202/500

Epoch 00202: val_loss improved from 3.06181 to 3.05304, saving model to /users/apokkunu/trial/text/output6/weights.202-3.05.h5
414113/414113 - 1054s - loss: 3.2188 - kl_loss: 1.5652 - val_loss: 3.0530 - val_kl_loss: 1.4865
Epoch 203/500

Epoch 00203: val_loss did not improve from 3.05304
414113/414113 - 1056s - loss: 3.2153 - kl_loss: 1.5653 - val_loss: 3.0539 - val_kl_loss: 1.5023
Epoch 204/500

Epoch 00204: val_loss improved from 3.05304 to 3.04635, saving model to /users/apokkunu/trial/text/output6/weights.204-3.05.h5
414113/414113 - 1058s - loss: 3.2151 - kl_loss: 1.5657 - val_loss: 3.0464 - val_kl_loss: 1.4854
Epoch 205/500

Epoch 00205: val_loss did not improve from 3.04635
414113/414113 - 1058s - loss: 3.2114 - kl_loss: 1.5636 - val_loss: 3.0491 - val_kl_loss: 1.4895
Epoch 206/500

Epoch 00206: val_loss did not improve from 3.04635
414113/414113 - 1058s - loss: 3.1994 - kl_loss: 1.5629 - val_loss: 3.0485 - val_kl_loss: 1.4989
Epoch 207/500

Epoch 00207: val_loss did not improve from 3.04635
414113/414113 - 1057s - loss: 3.2014 - kl_loss: 1.5640 - val_loss: 3.0674 - val_kl_loss: 1.5142
Epoch 208/500

Epoch 00208: val_loss did not improve from 3.04635
414113/414113 - 1059s - loss: 3.1923 - kl_loss: 1.5626 - val_loss: 3.0578 - val_kl_loss: 1.5078
Epoch 209/500

Epoch 00209: val_loss did not improve from 3.04635
414113/414113 - 1057s - loss: 3.1898 - kl_loss: 1.5616 - val_loss: 3.0468 - val_kl_loss: 1.4876
Epoch 210/500

Epoch 00210: val_loss improved from 3.04635 to 3.04578, saving model to /users/apokkunu/trial/text/output6/weights.210-3.05.h5
414113/414113 - 1056s - loss: 3.1871 - kl_loss: 1.5601 - val_loss: 3.0458 - val_kl_loss: 1.5023
Epoch 211/500

Epoch 00211: val_loss did not improve from 3.04578
414113/414113 - 1057s - loss: 3.1793 - kl_loss: 1.5614 - val_loss: 3.0633 - val_kl_loss: 1.5094
Epoch 212/500

Epoch 00212: val_loss did not improve from 3.04578
414113/414113 - 1054s - loss: 3.1825 - kl_loss: 1.5620 - val_loss: 3.0582 - val_kl_loss: 1.5119
Epoch 213/500

Epoch 00213: val_loss improved from 3.04578 to 3.03060, saving model to /users/apokkunu/trial/text/output6/weights.213-3.03.h5
414113/414113 - 1056s - loss: 3.1774 - kl_loss: 1.5612 - val_loss: 3.0306 - val_kl_loss: 1.4777
Epoch 214/500

Epoch 00214: val_loss did not improve from 3.03060
414113/414113 - 1055s - loss: 3.1704 - kl_loss: 1.5587 - val_loss: 3.0471 - val_kl_loss: 1.4967
Epoch 215/500

Epoch 00215: val_loss did not improve from 3.03060
414113/414113 - 1057s - loss: 3.1648 - kl_loss: 1.5590 - val_loss: 3.0546 - val_kl_loss: 1.5129
Epoch 216/500

Epoch 00216: val_loss did not improve from 3.03060
414113/414113 - 1052s - loss: 3.1704 - kl_loss: 1.5608 - val_loss: 3.0507 - val_kl_loss: 1.5084
Epoch 217/500

Epoch 00217: val_loss did not improve from 3.03060
414113/414113 - 1055s - loss: 3.1568 - kl_loss: 1.5579 - val_loss: 3.0345 - val_kl_loss: 1.4909
Epoch 218/500

Epoch 00218: val_loss improved from 3.03060 to 3.02614, saving model to /users/apokkunu/trial/text/output6/weights.218-3.03.h5
414113/414113 - 1056s - loss: 3.1499 - kl_loss: 1.5572 - val_loss: 3.0261 - val_kl_loss: 1.4811
Epoch 219/500

Epoch 00219: val_loss did not improve from 3.02614
414113/414113 - 1056s - loss: 3.1453 - kl_loss: 1.5559 - val_loss: 3.0360 - val_kl_loss: 1.4927
Epoch 220/500

Epoch 00220: val_loss improved from 3.02614 to 3.02460, saving model to /users/apokkunu/trial/text/output6/weights.220-3.02.h5
414113/414113 - 1054s - loss: 3.1484 - kl_loss: 1.5555 - val_loss: 3.0246 - val_kl_loss: 1.4841
Epoch 221/500

Epoch 00221: val_loss improved from 3.02460 to 3.01925, saving model to /users/apokkunu/trial/text/output6/weights.221-3.02.h5
414113/414113 - 1057s - loss: 3.1373 - kl_loss: 1.5559 - val_loss: 3.0193 - val_kl_loss: 1.4837
Epoch 222/500

Epoch 00222: val_loss did not improve from 3.01925
414113/414113 - 1054s - loss: 3.1380 - kl_loss: 1.5539 - val_loss: 3.0289 - val_kl_loss: 1.4811
Epoch 223/500

Epoch 00223: val_loss did not improve from 3.01925
414113/414113 - 1053s - loss: 3.1384 - kl_loss: 1.5541 - val_loss: 3.0245 - val_kl_loss: 1.4763
Epoch 224/500

Epoch 00224: val_loss improved from 3.01925 to 3.01577, saving model to /users/apokkunu/trial/text/output6/weights.224-3.02.h5
414113/414113 - 1055s - loss: 3.1341 - kl_loss: 1.5556 - val_loss: 3.0158 - val_kl_loss: 1.4827
Epoch 225/500

Epoch 00225: val_loss did not improve from 3.01577
414113/414113 - 1057s - loss: 3.1279 - kl_loss: 1.5535 - val_loss: 3.0169 - val_kl_loss: 1.4856
Epoch 226/500

Epoch 00226: val_loss did not improve from 3.01577
414113/414113 - 1058s - loss: 3.1238 - kl_loss: 1.5546 - val_loss: 3.0247 - val_kl_loss: 1.4804
Epoch 227/500

Epoch 00227: val_loss did not improve from 3.01577
414113/414113 - 1056s - loss: 3.1212 - kl_loss: 1.5525 - val_loss: 3.0224 - val_kl_loss: 1.4897
Epoch 228/500

Epoch 00228: val_loss improved from 3.01577 to 3.01335, saving model to /users/apokkunu/trial/text/output6/weights.228-3.01.h5
414113/414113 - 1056s - loss: 3.1085 - kl_loss: 1.5526 - val_loss: 3.0133 - val_kl_loss: 1.4758
Epoch 229/500

Epoch 00229: val_loss improved from 3.01335 to 3.00706, saving model to /users/apokkunu/trial/text/output6/weights.229-3.01.h5
414113/414113 - 1057s - loss: 3.1080 - kl_loss: 1.5508 - val_loss: 3.0071 - val_kl_loss: 1.4732
Epoch 230/500

Epoch 00230: val_loss did not improve from 3.00706
414113/414113 - 1055s - loss: 3.1051 - kl_loss: 1.5509 - val_loss: 3.0100 - val_kl_loss: 1.4759
Epoch 231/500

Epoch 00231: val_loss did not improve from 3.00706
414113/414113 - 1057s - loss: 3.1133 - kl_loss: 1.5505 - val_loss: 3.0288 - val_kl_loss: 1.4989
Epoch 232/500

Epoch 00232: val_loss did not improve from 3.00706
414113/414113 - 1057s - loss: 3.1077 - kl_loss: 1.5530 - val_loss: 3.0092 - val_kl_loss: 1.4838
Epoch 233/500

Epoch 00233: val_loss improved from 3.00706 to 3.00112, saving model to /users/apokkunu/trial/text/output6/weights.233-3.00.h5
414113/414113 - 1056s - loss: 3.1002 - kl_loss: 1.5526 - val_loss: 3.0011 - val_kl_loss: 1.4693
Epoch 234/500

Epoch 00234: val_loss improved from 3.00112 to 3.00058, saving model to /users/apokkunu/trial/text/output6/weights.234-3.00.h5
414113/414113 - 1056s - loss: 3.0937 - kl_loss: 1.5491 - val_loss: 3.0006 - val_kl_loss: 1.4665
Epoch 235/500

Epoch 00235: val_loss did not improve from 3.00058
414113/414113 - 1056s - loss: 3.0914 - kl_loss: 1.5495 - val_loss: 3.0045 - val_kl_loss: 1.4848
Epoch 236/500

Epoch 00236: val_loss did not improve from 3.00058
414113/414113 - 1057s - loss: 3.0893 - kl_loss: 1.5475 - val_loss: 3.0057 - val_kl_loss: 1.4825
Epoch 237/500

Epoch 00237: val_loss improved from 3.00058 to 2.99665, saving model to /users/apokkunu/trial/text/output6/weights.237-3.00.h5
414113/414113 - 1055s - loss: 3.0847 - kl_loss: 1.5486 - val_loss: 2.9967 - val_kl_loss: 1.4598
Epoch 238/500

Epoch 00238: val_loss did not improve from 2.99665
414113/414113 - 1057s - loss: 3.0851 - kl_loss: 1.5485 - val_loss: 3.0088 - val_kl_loss: 1.4922
Epoch 239/500

Epoch 00239: val_loss improved from 2.99665 to 2.99349, saving model to /users/apokkunu/trial/text/output6/weights.239-2.99.h5
414113/414113 - 1057s - loss: 3.0767 - kl_loss: 1.5458 - val_loss: 2.9935 - val_kl_loss: 1.4806
Epoch 240/500

Epoch 00240: val_loss did not improve from 2.99349
414113/414113 - 1056s - loss: 3.0753 - kl_loss: 1.5467 - val_loss: 2.9971 - val_kl_loss: 1.4781
Epoch 241/500

Epoch 00241: val_loss did not improve from 2.99349
414113/414113 - 1056s - loss: 3.0697 - kl_loss: 1.5473 - val_loss: 2.9981 - val_kl_loss: 1.4687
Epoch 242/500

Epoch 00242: val_loss improved from 2.99349 to 2.99253, saving model to /users/apokkunu/trial/text/output6/weights.242-2.99.h5
414113/414113 - 1057s - loss: 3.0704 - kl_loss: 1.5465 - val_loss: 2.9925 - val_kl_loss: 1.4790
Epoch 243/500

Epoch 00243: val_loss did not improve from 2.99253
414113/414113 - 1058s - loss: 3.0625 - kl_loss: 1.5441 - val_loss: 2.9930 - val_kl_loss: 1.4715
Epoch 244/500

Epoch 00244: val_loss did not improve from 2.99253
414113/414113 - 1055s - loss: 3.0602 - kl_loss: 1.5447 - val_loss: 3.0090 - val_kl_loss: 1.4927
Epoch 245/500

Epoch 00245: val_loss improved from 2.99253 to 2.99079, saving model to /users/apokkunu/trial/text/output6/weights.245-2.99.h5
414113/414113 - 1058s - loss: 3.0594 - kl_loss: 1.5458 - val_loss: 2.9908 - val_kl_loss: 1.4820
slurmstepd: error: *** JOB 685414 ON str-gpu7 CANCELLED AT 2021-04-08T16:11:42 DUE TO TIME LIMIT ***
