{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "active-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import spatial\n",
    "import tensorflow_addons as tfa\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "# tf.config.experimental_run_functions_eagerly(True)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "patient-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 500\n",
    "lr = 0.0005\n",
    "batch_size = 256\n",
    "\n",
    "intr_dim = 256\n",
    "latent_dim = int(intr_dim * 0.5)\n",
    "\n",
    "droprate = 0.2\n",
    "kl_weight = 0.01\n",
    "\n",
    "max_length = 50 #time steps\n",
    "emb_dim = 300\n",
    "\n",
    "BASE_DIR = './annotations/'\n",
    "use_all_data = True\n",
    "num_sent = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "treated-workstation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data size:  414113\n",
      "Total data size:  202654\n",
      "616767\n",
      "Found 28444 unique tokens\n",
      "Shape of data tensor: (616767, 50)\n",
      "(28444, 300)\n",
      "(414113, 50) (202654, 50)\n"
     ]
    }
   ],
   "source": [
    "def load_data(dataset, use_all_data, num_sent, BASE_DIR):\n",
    "    if 'train' in dataset:\n",
    "        path = BASE_DIR + 'captions_train2014.json'\n",
    "    else:\n",
    "        path = BASE_DIR + 'captions_val2014.json'\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "\n",
    "    captions = []\n",
    "    for c in annotations['annotations']:\n",
    "        caption = f\"<start> {c['caption']} <end>\"\n",
    "        captions.append(caption)\n",
    "        \n",
    "    if use_all_data:\n",
    "        captions = captions\n",
    "        print('Total data size: ', len(captions), flush=True)\n",
    "    else:\n",
    "        captions = captions[:num_sent]\n",
    "        print('Temp data size: ', len(captions), flush=True)    \n",
    "        \n",
    "    return captions\n",
    "\n",
    "def create_emb_ind(glove_path, emb_dim):\n",
    "    total_path = glove_path + 'glove.6B.' + str(emb_dim) + 'd.txt'\n",
    "    f = open(total_path, encoding='utf8')\n",
    "    embeddings_index = {}\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Found %s word vectors.' % len(embeddings_index), flush=True)\n",
    "    return embeddings_index\n",
    "\n",
    "def make_emb_mat(embeddings_index, total_words, emb_dim, word_index, dataset, save):\n",
    "    glove_embedding_matrix = np.zeros((total_words, emb_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if i < total_words:\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                glove_embedding_matrix[i] = embedding_vector\n",
    "            else:\n",
    "                # if words not found in embedding index will be the word embedding of 'unk'\n",
    "                glove_embedding_matrix[i] = embeddings_index.get('unk')\n",
    "    \n",
    "    print('Null word embeddings: %d' % np.sum(np.sum(glove_embedding_matrix, axis=1) == 0), flush=True)\n",
    "    print('Check Null: ', np.isnan(np.sum(glove_embedding_matrix)), flush=True)\n",
    "    print('Emb vector shape: ', glove_embedding_matrix.shape, flush=True)\n",
    "    \n",
    "    if save:\n",
    "        np.save('./annotations/' + dataset + '.npy', glove_embedding_matrix)\n",
    "    return glove_embedding_matrix\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "train_captions = load_data('train', use_all_data, num_sent, BASE_DIR)\n",
    "val_captions = load_data('val', use_all_data, num_sent, BASE_DIR)\n",
    "joint_list = train_captions + val_captions\n",
    "print(len(joint_list), flush=True)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=\"unk\", filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
    "tokenizer.fit_on_texts(joint_list)\n",
    "\n",
    "tokenizer.word_index['<pad>'] = 0\n",
    "tokenizer.index_word[0] = '<pad>'\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "index2word = {v: k for k, v in word_index.items()}\n",
    "print('Found %s unique tokens' % len(word_index), flush=True)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(joint_list)\n",
    "\n",
    "data_1 = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "print('Shape of data tensor:', data_1.shape, flush=True)\n",
    "\n",
    "vocab_size = len(word_index)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "create = False\n",
    "if create:\n",
    "    embeddings_index = create_emb_ind(BASE_DIR, emb_dim)\n",
    "    glove_embedding_matrix = make_emb_mat(embeddings_index, vocab_size, emb_dim, word_index, 'train', True)\n",
    "else:\n",
    "    glove_embedding_matrix = np.load(BASE_DIR + 'train.npy')\n",
    "    print(glove_embedding_matrix.shape, flush=True)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "x_train, x_val = train_test_split(data_1, shuffle=True, test_size=len(val_captions)/len(joint_list), random_state=28) #len(val_captions)/len(joint_list)\n",
    "print(x_train.shape, x_val.shape, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cooked-times",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VAE\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 300)      8533200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "custom_lstm (custom_lstm)       (None, 512)          1140736     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 128)          65664       custom_lstm[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 128)          65664       custom_lstm[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sampling (Sampling)             (None, 128)          0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "custom_decoder (custom_decoder) (None, 50, 28444)    16560924    sampling[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elbo__layer (ELBO_Layer)        (None, 50)           0           custom_decoder[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 26,366,188\n",
      "Trainable params: 0\n",
      "Non-trainable params: 26,366,188\n",
      "__________________________________________________________________________________________________\n",
      "layer 0: <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x2b362b36de50>\n",
      "has input mask: None\n",
      "has output mask: None\n",
      "layer 1: <tensorflow.python.keras.layers.embeddings.Embedding object at 0x2b37092e5110>\n",
      "has input mask: None\n",
      "has output mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "layer 2: <__main__.custom_lstm object at 0x2b370930bed0>\n",
      "has input mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "has output mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "layer 3: <tensorflow.python.keras.layers.core.Dense object at 0x2b36fc0d8590>\n",
      "has input mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "has output mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "layer 4: <tensorflow.python.keras.layers.core.Dense object at 0x2b370b3ab450>\n",
      "has input mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "has output mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "layer 5: <__main__.Sampling object at 0x2b370b3ab590>\n",
      "has input mask: [<tf.Tensor 'embedding/NotEqual:0' shape=(None, 50) dtype=bool>, <tf.Tensor 'embedding/NotEqual:0' shape=(None, 50) dtype=bool>]\n",
      "has output mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "layer 6: <__main__.custom_decoder object at 0x2b370c457ad0>\n",
      "has input mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "has output mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "layer 7: <__main__.ELBO_Layer object at 0x2b370b3ab850>\n",
      "has input mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "has output mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "model weights loaded\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "\n",
    "class Sampling(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Sampling, self).__init__()\n",
    "        self.supports_masking = True\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        epsilon = tf.random.normal([batch, latent_dim])\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class custom_lstm(tf.keras.layers.Layer):\n",
    "    def __init__(self, intr_dim, droprate,  **kwargs):\n",
    "        self.bi_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(intr_dim, recurrent_dropout=droprate, \n",
    "                                                                          return_sequences=False), merge_mode='concat')\n",
    "        self.drop_layer = tf.keras.layers.Dropout(droprate)\n",
    "        super(custom_lstm, self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        h = self.bi_lstm(inputs)\n",
    "        h = self.drop_layer(h)\n",
    "        return h\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask\n",
    "    \n",
    "x = tf.keras.layers.Input(shape=(max_length,))\n",
    "embed_layer = tf.keras.layers.Embedding(vocab_size, emb_dim, input_length=max_length, weights=[glove_embedding_matrix], \n",
    "                                        trainable=False, mask_zero=True)\n",
    "encoder_layer = custom_lstm(intr_dim, droprate)\n",
    "\n",
    "h = embed_layer(x)\n",
    "h = encoder_layer(h)\n",
    "z_mean = tf.keras.layers.Dense(latent_dim, name='z_mean')(h)\n",
    "z_log_var = tf.keras.layers.Dense(latent_dim, name='z_log_var')(h)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "class custom_decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, intr_dim, max_length, droprate, **kwargs):\n",
    "        self.rpv = tf.keras.layers.RepeatVector(max_length)\n",
    "        self.lstm_layer_1 = tf.keras.layers.LSTM(intr_dim, return_sequences=True, recurrent_dropout=droprate)\n",
    "        self.droplayer_2 = tf.keras.layers.Dropout(droprate)\n",
    "        self.lstm_layer_2 = tf.keras.layers.LSTM(intr_dim*2, return_sequences=True, recurrent_dropout=droprate)\n",
    "        self.droplayer_3 = tf.keras.layers.Dropout(droprate)\n",
    "        self.decoded_logits = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(vocab_size, activation='linear'))\n",
    "        super(custom_decoder, self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        h = self.rpv(inputs)\n",
    "        h = self.lstm_layer_1(h)\n",
    "        h = self.droplayer_2(h)\n",
    "        h = self.lstm_layer_2(h)\n",
    "        h = self.droplayer_3(h)\n",
    "        decoded = self.decoded_logits(h)\n",
    "        return decoded\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask\n",
    "    \n",
    "decoder_layer = custom_decoder(vocab_size, intr_dim, max_length, droprate)\n",
    "decoded_logits = decoder_layer(z)\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "class ELBO_Layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ELBO_Layer, self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self, inputs, mask=None):\n",
    "        broadcast_float_mask = tf.cast(mask, \"float32\")\n",
    "        labels = tf.cast(x, tf.int32)\n",
    "        reconstruction_loss = tf.reduce_sum(tfa.seq2seq.sequence_loss(inputs, labels, \n",
    "                                                                      weights=broadcast_float_mask,\n",
    "                                                                      average_across_timesteps=False,\n",
    "                                                                      average_across_batch=False), axis=1)\n",
    "        \n",
    "        kl_loss = - 0.5 * tf.reduce_sum(1 + z_log_var - tf.math.square(z_mean) - tf.math.exp(z_log_var), axis=1)\n",
    "        total_loss = tf.reduce_mean(reconstruction_loss + kl_weight * kl_loss)\n",
    "        self.add_loss(total_loss, inputs=[x, inputs])\n",
    "        return tf.ones_like(x)\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask\n",
    "        \n",
    "elbo_layer = ELBO_Layer()\n",
    "fake_decoded_prob = elbo_layer(decoded_logits)\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "def zero_loss(y_true, y_pred):\n",
    "    return tf.zeros_like(y_pred)\n",
    "\n",
    "def kl_loss(x, fake_decoded_prob):\n",
    "    kl_loss = - 0.5 * tf.reduce_sum(1 + z_log_var - tf.math.square(z_mean) - tf.math.exp(z_log_var), axis=1)\n",
    "    kl_loss = kl_weight * kl_loss\n",
    "    return tf.reduce_mean(kl_loss)\n",
    "\n",
    "vae = tf.keras.models.Model(x, fake_decoded_prob, name='VAE', trainable=False)\n",
    "opt = tf.keras.optimizers.Adam(lr=lr)\n",
    "vae.compile(optimizer=opt, loss=[zero_loss], metrics=[kl_loss])\n",
    "vae.summary()\n",
    "vae.trainable = False\n",
    "\n",
    "for i, l in enumerate(vae.layers):\n",
    "    print(f'layer {i}: {l}', flush=True)\n",
    "    print(f'has input mask: {l.input_mask}', flush=True)\n",
    "    print(f'has output mask: {l.output_mask}', flush=True)\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "name = 'weights.207-3.54.h5'\n",
    "directory = 'output4'\n",
    "vae.load_weights('./' + directory + '/' + name)\n",
    "print('model weights loaded', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "opponent-huntington",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 300)      8533200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "custom_lstm (custom_lstm)       (None, 512)          1140736     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 128)          65664       custom_lstm[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 128)          65664       custom_lstm[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sampling (Sampling)             (None, 128)          0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 9,805,264\n",
      "Trainable params: 0\n",
      "Non-trainable params: 9,805,264\n",
      "__________________________________________________________________________________________________\n",
      "layer 0: <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x2b362b36de50>\n",
      "has input mask: None\n",
      "has output mask: None\n",
      "layer 1: <tensorflow.python.keras.layers.embeddings.Embedding object at 0x2b37092e5110>\n",
      "has input mask: None\n",
      "has output mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "layer 2: <__main__.custom_lstm object at 0x2b370930bed0>\n",
      "has input mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "has output mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "layer 3: <tensorflow.python.keras.layers.core.Dense object at 0x2b36fc0d8590>\n",
      "has input mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "has output mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "layer 4: <tensorflow.python.keras.layers.core.Dense object at 0x2b370b3ab450>\n",
      "has input mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "has output mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "layer 5: <__main__.Sampling object at 0x2b370b3ab590>\n",
      "has input mask: [<tf.Tensor 'embedding/NotEqual:0' shape=(None, 50) dtype=bool>, <tf.Tensor 'embedding/NotEqual:0' shape=(None, 50) dtype=bool>]\n",
      "has output mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# build a model to project sentences on the latent space\n",
    "encoder = tf.keras.models.Model(x, z, name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "for i, l in enumerate(encoder.layers):\n",
    "    print(f'layer {i}: {l}', flush=True)\n",
    "    print(f'has input mask: {l.input_mask}', flush=True)\n",
    "    print(f'has output mask: {l.output_mask}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "future-retail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "custom_decoder (custom_decod (None, 50, 28444)         16560924  \n",
      "=================================================================\n",
      "Total params: 16,560,924\n",
      "Trainable params: 0\n",
      "Non-trainable params: 16,560,924\n",
      "_________________________________________________________________\n",
      "layer 0: <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x2b370c740d50>\n",
      "has input mask: None\n",
      "has output mask: None\n",
      "layer 1: <__main__.custom_decoder object at 0x2b370c457ad0>\n",
      "has input mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n",
      "has output mask: Tensor(\"embedding/NotEqual:0\", shape=(None, 50), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# build a generator that can sample sentences from the learned distribution\n",
    "ins = tf.keras.layers.Input(shape=(latent_dim,))\n",
    "x_logits = decoder_layer(ins)\n",
    "generator = tf.keras.models.Model(ins, x_logits, name='decoder')\n",
    "generator.summary()\n",
    "\n",
    "for i, l in enumerate(generator.layers):\n",
    "    print(f'layer {i}: {l}', flush=True)\n",
    "    print(f'has input mask: {l.input_mask}', flush=True)\n",
    "    print(f'has output mask: {l.output_mask}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "polyphonic-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TemporalSoftmax(inputs, mask):\n",
    "    broadcast_float_mask = tf.expand_dims(tf.cast(mask, \"float32\"), -1)\n",
    "    inputs_exp = tf.math.exp(inputs) * broadcast_float_mask\n",
    "    inputs_sum = tf.reduce_sum(inputs * broadcast_float_mask, axis=1, keepdims=True)\n",
    "    out_prob = inputs_exp / inputs_sum\n",
    "    return out_prob\n",
    "\n",
    "def create_mask(inputs):\n",
    "    return tf.cast(tf.cast(inputs, tf.dtypes.bool), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sunset-finding",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig: <start> a man walks with a young girl hand and hand as she carries an umbrella <end>\n",
      "pred: <start> a man walks with a young girl hand and hand as she carries an umbrella <end>\n",
      "\n",
      "\n",
      "orig: <start> three motorcyclists and their bikes stand on the pavement <end>\n",
      "pred: <start> three motorcyclists and their bikes stand on the pavement <end>\n",
      "\n",
      "\n",
      "orig: <start> a desk with two computer monitors and a mouse <end>\n",
      "pred: <start> a desk with two computer monitors and a mouse <end>\n",
      "\n",
      "\n",
      "orig: <start> a pigeon sits on a curb on the side of a road <end>\n",
      "pred: <start> a pigeon sits on a curb on the side of a road <end>\n",
      "\n",
      "\n",
      "orig: <start> two people flying a kite over a snowy field <end>\n",
      "pred: <start> two people flying a kite over a snowy field <end>\n",
      "\n",
      "\n",
      "orig: <start> two men excited about the very large pieces of pizza they are holding <end>\n",
      "pred: <start> two men excited about the very large piece of them they are holding <end>\n",
      "\n",
      "\n",
      "orig: <start> two men on motorcycles in front of building <end>\n",
      "pred: <start> two men on motorcycles in front of building <end>\n",
      "\n",
      "\n",
      "orig: <start> a white sox baseball player walks off of a base <end>\n",
      "pred: <start> a white sox baseball player walks off of a base <end>\n",
      "\n",
      "\n",
      "orig: <start> a child is practicing his wiffle ball skills <end>\n",
      "pred: <start> a child is practicing his frisbee ball skills <end>\n",
      "\n",
      "\n",
      "orig: <start> a couple of zebra standing on top of a dirt road <end>\n",
      "pred: <start> a couple of zebra standing on top of a dirt road <end>\n",
      "\n",
      "\n",
      "orig: <start> a fridge and stove in a home kitchen <end>\n",
      "pred: <start> a fridge and stove in a home kitchen <end>\n",
      "\n",
      "\n",
      "orig: <start> a clock sits in the window on the side of a white house <end>\n",
      "pred: <start> a clock sits in the window on the side of a white house <end>\n",
      "\n",
      "\n",
      "orig: <start> the floor level view of an entertainment cubby shows a great many mostly bundled wires up against a wall behind the shelf and on the shelf itself a cd and a host of electronic devices and accessories <end>\n",
      "pred: <start> the floor level view of an interior interior shows a well well windows windows up up a a a a a a a a a a a a a a a and a a a <end>\n",
      "\n",
      "\n",
      "orig: <start> five cups full of liquid set on a table <end>\n",
      "pred: <start> five cups full of liquid set on a table <end>\n",
      "\n",
      "\n",
      "orig: <start> a room with a bunch of kids inside of it <end>\n",
      "pred: <start> a room with a bunch of kids inside of it <end>\n",
      "\n",
      "\n",
      "orig: <start> a living room filled with lots of furniture and a tv <end>\n",
      "pred: <start> a living room filled with lots of furniture and a tv <end>\n",
      "\n",
      "\n",
      "orig: <start> an elephant walks behind another by a fence <end>\n",
      "pred: <start> an elephant walks behind another by a fence <end>\n",
      "\n",
      "\n",
      "orig: <start> a man surfing the waves in the ocean <end>\n",
      "pred: <start> a man surfing the waves in the ocean <end>\n",
      "\n",
      "\n",
      "orig: <start> a man in a jacket sniffs a glass of wine <end>\n",
      "pred: <start> a man in a jacket sniffs a glass of wine <end>\n",
      "\n",
      "\n",
      "orig: <start> black bird sitting atop a building on a cloudy day <end>\n",
      "pred: <start> black bird sitting atop a building on a cloudy day <end>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test on a validation sentence\n",
    "\n",
    "for i in range(20):\n",
    "    sent_idx = i\n",
    "    \n",
    "    sent_encoded = encoder.predict(x_val[sent_idx:sent_idx+2,:])\n",
    "\n",
    "    x_test_reconstructed = tf.nn.softmax(generator.predict(sent_encoded, batch_size = 1))\n",
    "    \n",
    "    reconstructed_indexes = clean_sent(np.apply_along_axis(np.argmax, 1, x_test_reconstructed[0]), 4)\n",
    "\n",
    "    original_sent = [i for i in np.vectorize(index2word.get)(x_val[sent_idx]) if '<pad>' not in i]\n",
    "    print('orig:', ' '.join(original_sent))\n",
    "\n",
    "    word_list = list(np.vectorize(index2word.get)(reconstructed_indexes))\n",
    "    print('pred:', ' '.join(word_list))\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "improved-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_encoded = encoder.predict(x_val[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "infectious-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_parse(sentence):\n",
    "    sequence = tokenizer.texts_to_sequences(sentence)\n",
    "    padded_sent = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=max_length, padding='post')\n",
    "    return padded_sent\n",
    "\n",
    "\n",
    "# input: encoded sentence vector\n",
    "# output: encoded sentence vector in dataset with highest cosine similarity\n",
    "def find_similar_encoding(sent_vect):\n",
    "    all_cosine = []\n",
    "    for sent in sent_encoded:\n",
    "        result = 1 - spatial.distance.cosine(sent_vect, sent)\n",
    "        all_cosine.append(result)\n",
    "    data_array = np.array(all_cosine)\n",
    "    maximum = data_array.argsort()[-3:][::-1][1]\n",
    "    new_vec = sent_encoded[maximum]\n",
    "    return new_vec\n",
    "\n",
    "\n",
    "# input: two points, integer n\n",
    "# output: n equidistant points on the line between the input points (inclusive)\n",
    "def shortest_homology(point_one, point_two, num):\n",
    "    dist_vec = point_two - point_one\n",
    "    sample = np.linspace(0, 1, num, endpoint = True)\n",
    "    hom_sample = []\n",
    "    for s in sample:\n",
    "        hom_sample.append(point_one + s * dist_vec)\n",
    "    return hom_sample\n",
    "\n",
    "\n",
    "# input: original dimension sentence vector\n",
    "# output: sentence text\n",
    "def print_latent_sentence(sent_vect, name):\n",
    "    sent_vect = np.reshape(sent_vect,[1,latent_dim])\n",
    "    sent_reconstructed = tf.nn.softmax(generator.predict(sent_vect))\n",
    "    sent_reconstructed = np.reshape(sent_reconstructed, [max_length, vocab_size])\n",
    "    reconstructed_indexes = clean_sent(np.apply_along_axis(np.argmax, 1, sent_reconstructed), 4)\n",
    "    word_list = list(np.vectorize(index2word.get)(reconstructed_indexes))\n",
    "    w_list = [w for w in word_list if w not in ['<pad>']]\n",
    "    print(name, ' '.join(w_list), flush=True)\n",
    "       \n",
    "\n",
    "def new_sents_interp(sent1, sent2, n, name):\n",
    "    tok_sent1 = sent_parse(sent1)\n",
    "    tok_sent2 = sent_parse(sent2)\n",
    "    enc_sent1 = encoder.predict(tok_sent1, batch_size = 1)\n",
    "    enc_sent2 = encoder.predict(tok_sent2, batch_size = 1)\n",
    "    test_hom = shortest_homology(enc_sent1, enc_sent2, n)\n",
    "    for point in test_hom:\n",
    "        print_latent_sentence(point, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "express-integration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3 49 14  5 33  6  2 25  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]]\n",
      "example1:  <start> cat sitting on top of a table <end>\n",
      "similar sent1:  <start> a striped cat sitting on top of a table <end>\n"
     ]
    }
   ],
   "source": [
    "sentence1=['<start> cat sitting on top of a table <end>']\n",
    "mysent = sent_parse(sentence1)\n",
    "print(mysent)\n",
    "\n",
    "mysent_encoded = encoder.predict(mysent, batch_size = 1)\n",
    "print_latent_sentence(mysent_encoded, 'example1: ')\n",
    "print_latent_sentence(find_similar_encoding(mysent_encoded), 'similar sent1: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "interesting-plane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   3    2   47 1168    9    2   49    4    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "example2:  <start> a dog relaxing with a cat <end>\n",
      "similar sent2:  <start> a train stopped at a train station <end>\n"
     ]
    }
   ],
   "source": [
    "sentence2=['<start> a dog relaxing with a cat <end>']\n",
    "mysent2 = sent_parse(sentence2)\n",
    "print(mysent2)\n",
    "\n",
    "mysent_encoded2 = encoder.predict(mysent2, batch_size = 1)\n",
    "print_latent_sentence(mysent_encoded2, 'example2: ')\n",
    "print_latent_sentence(find_similar_encoding(mysent_encoded2), 'similar sent2: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "union-columbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interp:  <start> cat sitting on top of a table <end>\n",
      "interp:  <start> cat sitting on top of a table <end>\n",
      "interp:  <start> cat sitting on top of a table <end>\n",
      "interp:  <start> cat sitting on top of a table <end>\n",
      "interp:  <start> a cat sitting on a a <end>\n",
      "interp:  <start> a dog sleeping with a a <end>\n",
      "interp:  <start> a dog sleeping with a cat <end>\n",
      "interp:  <start> a dog relaxing with a cat <end>\n",
      "interp:  <start> a dog relaxing with a cat <end>\n",
      "interp:  <start> a dog relaxing with a cat <end>\n"
     ]
    }
   ],
   "source": [
    "# get shortest homology\n",
    "new_sents_interp(sentence1, sentence2, 10, 'interp: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dressed-variance",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 15, 224, 8, 213, 213, 1664, 5, 948, 5, 5, 589, 10, 589, 10, 2, 4]\n",
      "\n",
      "pred: <start> an image in being being peeking on what on on reading and reading and a <end>\n"
     ]
    }
   ],
   "source": [
    "#test on a random sentences\n",
    "random_sent = tf.random.normal([1, latent_dim,])\n",
    "x_test_reconstructed = tf.nn.softmax(generator.predict(random_sent, batch_size = 1))\n",
    "\n",
    "reconstructed_indexes = clean_sent(np.apply_along_axis(np.argmax, 1, x_test_reconstructed[0]), 4)\n",
    "print(reconstructed_indexes)\n",
    "\n",
    "print()\n",
    "\n",
    "# in case of repeating word, change distribution of the next predicted word based on the current word (restricting the predictions)\n",
    "word_list = list(np.vectorize(index2word.get)(reconstructed_indexes))\n",
    "print('pred:', ' '.join(word_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
